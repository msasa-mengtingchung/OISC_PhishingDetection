 {
      "body": "The opening arguments for the landmark case Eldred vs Ashcroft, set to commence early next month before the U.S. Supreme Court, will determine the future of copyright law and its impact on artists and writers' ability to build upon existing works. To raise public awareness about this significant case, an Internet Bookmobile is scheduled to depart from San Francisco next Monday. This mobile book van will journey to the steps of the Supreme Court building in Washington D.C., before the court hearings conclude. Along the way, it will stop at schools, libraries, and senior centers, offering free high-speed access to thousands of literary and artistic works that are already in the public domain. I recently visited the Internet Archive where I saw this bookmobile being built; it's an innovative idea – essentially, a small vehicle with a satellite dish on top, equipped with a computer printer and binding machine. This allows users to search for a book, print out a copy instantly, and bind it on the spot - all at a fixed cost. The Internet Archive had this equipment donated, and one of their goals is to demonstrate to libraries across the country that they could add these virtual holdings (public domain materials) to their existing library collections at an affordable fixed cost. This should be particularly appealing to small libraries in remote areas."
   }, {
    "body": "Multiple artists creating characters on a rock face"
   }, {
       "body": "It appears that you have come across a webpage with an unusual theory, which seems to combine elements of various pseudoscientific beliefs such as Scientology (Xenu) and David Icke's theories, along with a unique spin on dinosaurs and the origins of good and evil. Initially, it seemed like a backstory for a role-playing game, but it appears that someone genuinely believes in this theory. The dinosaurs are described as reptoid ETs, reported to be four-foot tall crocodiles walking on their hind legs. This theory suggests that these reptoid ETs, dragons, and erideans all originated from Earth and have a strong link to it. Conversely, the Greys do not seem to originate from Earth due to their lack of a renal or urinary system. The definitive work on dragons is 'The Flight of Dragons' by Peter Dickinson. The author suggests that there was a race of dinosaurs that developed psychic intelligence to protect their eggs and young, and they survived the extinction millions of years ago with difficulty, evolving into the erideans and moving to a more hospitable planet. It is proposed that these reptoids are the spirits or ghosts of the dinosaurs, living on as vampire entities. The author encourages them to reincarnate in order to eliminate immortal minds and their mind control."
   }, {
    "body": "Dear Russell and Gregory,\n\nI hope this message finds you well. I wanted to clarify some points regarding the First Amendment that have been on my mind since our last civics class. To set the record straight, the First Amendment does indeed protect speech, but it doesn't cover hate speech or actions. Hate speech may be wrong, but it is protected under the First Amendment, as the Supreme Court has decided. Unlike many other nations, the U.S. does not have laws against hate speech per se. The reason for this is that the First Amendment protects all speech, and it just so happens that much of what people consider hate speech falls under this protection. I find the laws specializing out hate and protected speech to be ridiculous.\n\nI believe there are only two types of speech and actions: both are speech and should be covered by the First Amendment. However, if hate speech is so protected, why are certain states trying to prosecute people for it? There are only two answers to this question, and one of them is clearly wrong. Hate speech is not just speech; it's action, a type of action whose consequences are foreseeable by any reasonable person. When we label hate speech as such, we are actually categorizing it as threat.\n\nIt seems that the mislabeling has been allowed to continue because there is an advantage in being able to counter a threat with the loss of liberty and money through civil and criminal lawsuits for people they don't like. I invite you to join the world's largest email service with MSN Hotmail.\n\nBest regards,"
   }, {
      "body": "I hope the PM Eugen Leitl updates the material soon. I'll make sure to inform everyone about the next update :bk delongopencourseware cell."
   }, {
     "body": "Finally, I have secured a grant from Project Athena's Mits Original Courseware Effort. However, I found that they had focused more on developing X and various Unix tools, rather than the distribution of the courseware. Hopefully, they will add more educational content soon. I will keep everyone updated about the next update."
   }, {
    "body": "I found some classic books from the same period, specifically 'English Sagas of Icelanders' in trade paperback, which is currently remaindered at my local Barnes & Noble. This historical reference material by Useful Erikur seems useful."
   }, {
     "body": "It appears that several music companies have agreed to pay a substantial settlement of $400 million in a price-fixing case, as reported by The Wall Street Journal (Copyright © Dow Jones Company Inc) on Tuesday, October 5th. Although the companies did not admit any wrongdoing, they will pay $300 million in cash to compensate consumers who overpaid for CDs between 2003 and 2010. Additionally, the companies have agreed to distribute an estimated $100 million worth of CDs to public entities and non-profit organizations across the country. Interestingly, it's speculated that these CDs will cost less than $100 million to produce and distribute. The lack of admission of wrongdoing seems questionable."
   }, {
      "body": "Hi Elias, It turns out that some major music companies have agreed to pay a substantial settlement in a price-fixing case. I thought it was relatively minor compared to the overpricing that happens on standard CDs. The Wall Street Journal (Copyright © 2021 Dow Jones & Company Inc.) reported this on Tuesday, October 5th. These companies did not admit any wrongdoing but will pay $XX million in cash as compensation for consumers who overpaid for CDs between YYYY and ZZZZ. Additionally, they agreed to distribute $CCC million worth of CDs to public entities and non-profit organizations across the country. The cost of producing and distributating these CDs is likely to be less than $DDD million. However, it's important to note that none of this money will go back to the people who were forced to pay the inflated prices. Best regards."
   }, {
      "body": "On Monday afternoon, I've come to a realization after revisiting my past work and career trajectory. It appears that I have been in the wrong industry all along. What I should have been doing is [describe the alternative field or profession]. I've recently read a manual about this new area, and of course, open-source versions are also readily available on the internet. The Internet Bearer Underwriting Corporation, located at Farquhar Street, Boston, MA, USA, seems to be an established entity in this field. Despite not being able to predict the end of the world, it deserves respect for its usefulness and historical significance, as mentioned by Edward Gibbon in 'Decline and Fall of the Roman Empire'."
   }, {
     "body": "It appears that you are considering dual antenna mounts for your setup, which I believe is a diversity antenna system. However, it might not perform optimally when one antenna is connected to a Pringles can and the other to a regular rubber duck antenna. For better range boosting, use directional aerials instead, as direct line of sight provides the best results; no trees, no obstructions, and nothing between can give you approximately 1 km with well-aligned directional aerials. Additionally, note that in case of bad weather such as sleet, locusts, or even a rain of blood (figuratively speaking), this might affect the signal. If you wish to fan out your coverage later on, consider using a directional coupling to an omni antenna within the building. In terms of your latest project, I understand that you have acquired a Linksys access point router and are working on a Symbol PocketPC device in a pre-war New York apartment. The device works fine within the apartment, but loses contact with the base station before it reaches less than 10 feet inside the apartment. You conducted additional testing through brick walls, finding that the range is approximately 30 feet and the signal passes through the roof relatively unimpeded. Despite this, the Symbol device does not have a built-in antenna, and you haven't attempted to adjust it for better range. The Linksys unit features two antenna mounts; leaving one as an omni antenna while connecting a directional antenna to the other may improve your coverage. You might need multiple access points or repeaters to achieve the desired coverage."
   }, {
    "body": "The Enigma code, which was deciphered at Bletchley Park, was primarily mechanical and not optical in nature. It was initially broken due to improper use rather than optimal employ, as it would have been significantly more challenging if utilized strategically. For a comprehensive understanding of the Enigma machine and its story, I recommend reading 'Enigma' by Ubic Singh or 'Cryptonomicon' by Neal Stephenson, a fictionalized account of the Enigma cracking process that maintains considerable accuracy. The development of the Enigma code was inadvertently responsible for the birth of computing, as it involved working with interference patterns. The Enigma was ultimately cracked by constructing mechanical systems similar to the Enigma machines and using brute force."
   }, {
      "body": "Ian Andrew Bell, Tuesday October \nEugen Leitl, Damien Morton, Wifi Query\nIt appears that you are referring to a diversity antenna. However, I would like to clarify that using one omni-directional antenna and one directional antenna may not work optimally as per the manual's instructions for a diversity setup (one antenna for receiving signals and another for transmitting).\nOn Tuesday October,\nEugen Leitl emphasized that reinforced concrete shields like those in dense wooded areas significantly hinder line-of-sight signal transmission. Therefore, direct line-of-sight is best with no obstructions such as trees or buildings.\nIf you aim to boost the range, it would be more effective to use directional antennas rather than omnis due to their focused transmission.\nHowever, if you desire a wider coverage within a building, especially in areas of heavy precipitation, a bridge connecting a directional antenna to an omni-directional one could be used, but this may require additional access points or repeaters for optimal coverage.\nIan Andrew Bell, Tuesday October\nDamien Morton added that he has recently purchased a Linksys access point router and is doing some development work on a Symbol PocketPC device in a prewar New York apartment. The device works fine within the apartment but loses contact with the base station approximately 10 feet inside the apartment. He performed further testing through brick walls and found that the range is about 30 feet. The signal also passes through the roof relatively unimpeded. The Symbol device does not have an antenna, and no adjustments have been made to extend the range.\nThe Linksys unit has two antenna mounts, one could be left as an omni-directional antenna while hooking up a directional antenna to the other. This setup might necessitate using multiple access points or repeaters to achieve the desired coverage."
   }, {
      "body": "Hi there, I found your email quite amusing! A group of non-conformists, humorously challenging Israeli terrorism, decided to make an appearance at the local Starbucks in Berkeley. It's interesting that they chose a city like Berkeley for their demonstration, but nonetheless, it adds a comedic twist. They allegedly used water guns (supersoakers) to drive away straight and original inhabitants - a rather unique and creative approach if you ask me. While I don't condone violence, the damage potential of a supersoaker is limited. It certainly seems newsworthy! It's refreshing to see individuals employing innovative methods to express their views, even if we might not always share the same perspective. Best regards!"
   }, {
    "body": "Subject: Potential Collaboration Regarding Interactive Agent Technology\n\nIt's intriguing to discuss an application of agent technology, a blend of Telnet and Eliza. We are curious if your organization might find value in ActiveBuddy Inc's services as a partner. ActiveBuddy has developed patented technology for constructing and deploying interactive agents. Our 'buddyscript' technology empowers business solutions by leveraging the functionality, convenience, and allure of instant messaging to offer an efficient and immediate means of communication with customers and constituents.\n\nThe effectiveness of ActiveBuddy technology is evident in the marketplace, as demonstrated by the resounding success of our product SmarterChild. In its first year, our interactive agent launch, SmarterChild, was visited by over a million consumers. A notable example of its utility is SmarterChild's showcase interactive agent, which allows customers and constituents to receive information and services through a natural conversational interface.\n\nBy using our software products like buddyscript server, you can offer your clients an end-to-end solution for deploying interactive agents. The buddyscript server includes all the necessary components to operate an interactive agent, such as connectivity with messaging networks, message routing, data access, message formatting, user and session management, and detailed tracking. It is available in four configurations to accommodate various capacity needs, and its scalable architecture supports virtually unlimited usage.\n\nFor instance, here's a sample conversation on MSN Messenger with our SmarterChild: \n\nsmarterchild: Thank you, Mike! What is the weather like in Seattle?\nSmarterchild: Weather conditions for Seattle: Few clouds and real mph.\nNext time, just type 'weather Seattle' to get the forecast for Seattle, WA or simply type 'forecast'."
   }, {
       "body": "Hi there! Here's a simulated chat log from MSN Messenger between me (MF) and Mike. How are you, MF?\nMIKE: Smarter child great, thx you!\nME: Oh, freaking great! In their effort to make it more human, they should incorporate all the broken English and AOL-style phrasings, yay! Next thing you know, the AI will be asking for a 'slap in the face' (vil)."
   }, {
        "body": "Hello Joseph S Barrera III,\n\nI understand that you are behind a firewall with a NAT address and you want to telnet to a Linux box out there in the world and create xterms on your own screen. I'm not an expert, but one possible solution could be to configure your firewall to accept connections from the Linux box, then set the Linux box to transmit on a specific port. After that, you would need to configure your router to forward all information from that port to your computer. However, this setup largely defeats the purpose of a firewall.\n\nRegarding your question about downloading MSN Explorer, I couldn't find a reliable source for a free and updated version."
    }, {
     "body": "Subject: Unusual Political Spam Warning - University of Groningen\n\nIt appears that a new form of political spam has surfaced, allegedly targeting the University of Groningen. Unlike typical spam, this message seems to serve as more of a prank than a sales pitch or invitation to any fee-based service. The content revolves around the meme 'rug is evil'. If you are considering studying in the Netherlands, particularly for a PhD, be cautious, especially with the University of Groningen. In the past, this university had a good reputation, but its standing seems to have diminished.\n\nPicasso once said that computers can only give answers, and it seems like someone at Teledynamics Communications is reminding us of that. If you or anyone else has encountered similar messages, do let me know."
   }, {
       "body": "It seems that your email is arguing against the use of AI chatbots or infobots in a helpdesk context. The points made suggest that people do not prefer to communicate with these bots, especially when they make mistakes, as they can appear dumb and deceptive when their 'intelligence' is revealed to be simulated. The email also mentions the example of Alice, which is suggested to be a highly advanced chatbot but prone to dramatic failures, like a 'chicken brain'. The author also believes that while AI should work in theory, people will not use it due to its clunky interface and quick adaptation to its limitations. Lastly, the author uses an example of how computers are useless according to Shallow Red and Eliza, two chatbots."
   }, {
      "body": "Wow, if they added a VRML front-end to it, it would be pointless. I've already dealt with IRC bots and scripts, been there, done that, and much better. If these people actually saw the xddc instant file sharing scripts, they might understand then again, they might already know that sometimes you can package the obvious and sell it to the clueless."
   }, {
    "body": "Subject: Caution for Prospective Students Considering University of Groningen, Netherlands\n\nDear Gary Lawrence Murphy,\n\nIt has come to our attention that some individuals are considering the University of Groningen in the Netherlands for various educational pursuits, including PhD programs. However, it is essential to exercise caution as this university's reputation has reportedly diminished.\n\nInvesting time and money into education is crucial; therefore, it is advisable to invest wisely and thoughtfully in the right place and time. We urge you to be cautious about choosing the University of Groningen due to its current status.\n\nIt is unfortunate that the reputation of this once-respected institution has suffered. One can only imagine what could be worse for the academic community in Northern Europe."
   }, {
      "body": "Hi Mike, I hope this message finds you well. How about Seattle's weather today? SmarterChild Here, providing the current weather conditions for you. Gary Lawrence Murphy commented that teledynamics computers are merely capable of giving answers, but with us, you get a bit more! Pablo Picasso said it best: 'Computers are useless. They can only give you answers.' "
   }, {
      "body": "Dear [Recipient Name], \n\nI recently came across an email that discusses the history and potential of optical computing. The author seems to express skepticism about the 'secret history' aspect of this topic, suggesting that it might be nothing more than a lack of newsworthiness rather than a hidden truth. However, the email acknowledges that optical computing has been in use for decades, with early successes like the first computer to crack Enigma and the first synthetic aperture radar processor being optical. It also mentions the use of optical sensors at Bletchley Park and the application of optoelectronic computing in the form of superposed masks for pattern finding. \n\nThe author argues that optical computing is more complex than just holography, involving not only frequency, amplitude, and phase but numerous frequencies each with its own amplitude and phase. Lenses, refractions, and interference are cited as computational operators in this field. It is also noted that certain things which are hard to achieve with wires become easier with lightwaves, while many tasks that are easy with wires prove difficult using lightwaves.\n\nThe author then refers to a commercialized effort of a space-integrating vector-matrix multiplier with teraflop equivalent for one multiply per nanosecond, and mentions smaller versions of this technology in the unclassified acoustooptic spectrometer. The email also touches upon the promise of moving from optoelectronic to all-optical processors and networks, including optical encryption.\n\nThe author concludes by expressing doubts about the feasibility of all-optical computing due to the non-interactive nature of photons, suggesting that it may be premature to abandon optoelectronics entirely.\n\nSincerely,\n[Your Name]"
   }, {
     "body": "Gary Lawrence Murphy, after reflecting on our experiences, I believe it's safe to say that a helpdesk in its current form doesn't seem to be effective. I'm not entirely sure if they are strictly engaged in helpdesk tasks, but the general sentiment is that it lacks appealing features. However, simplicity might be its strength. Agents and interfaces that can find a niche application space could potentially thrive in this approach. \n\nIn regards to Prolog-based NL database query systems and other chatterbot helpdesk projects like Shallow Red or simpler attempts such as Ask Jeeves, users quickly realize they're interacting with a robot. Queries tend to be short, truncated, and terse, resembling database-like verb-noun or just noun-keyword requests, much like a web query. With Google, someone else can convert these queries into links, so you don't even need to type anything. People are just too quick to adapt and too impatient to tolerate a clunky interface. For now, especially when the average computer user still can't type more than a few words in natural language, a painfully slow and clunky interface is a significant drawback. \n\nConsidering your question about interacting with a bot without directly addressing it, imagine a situation where two people are discussing trips, for instance. A weather bot could advisorily interject or correct their conversation by mentioning the forecast without being explicitly asked."
   }, {
    "body": "For your question, here's my breakdown of the email: \n\nThe device in question operates on channels shared with microwaves and cordless phones, reaching up to 5 GHz. It offers significantly more bandwidth (around five times) compared to those but has a shorter range (up to 30 feet). To enhance data transmission reliability, it incorporates forward error correction. For streaming video, it's highly recommended due to its capabilities. Streaming audio can be comfortably done with minimal interference or too many clients. \n\nRegarding the choice between wifi ranges, it seems you are considering whether to opt for standard wifi or upgrade to a premium one based on the price point difference. In case of streaming video, the premium option may be worth the investment. However, if you're only concerned with audio and there isn't much interference, the standard wifi should suffice.\n\nLastly, it was mentioned that for covering a large area, prices will be higher due to the need for more access points (APs). If you want to reach your local coffee shop, you'll likely need a directional antenna regardless. They also suggested checking out certain articles and resources for additional information, particularly on security aspects, which they found to provide some of the best info they've seen."
   }, {
      "body": "Dear R A Hettinga, The Enigma machine was initially cracked using optical computing through interference patterns and such, but it was actually the mechanical systems that were essentially Enigma machines, and brute-forcing by looking for Zygalski sheets that led to its decryption. However, Köpners narrative suggests a hybrid approach at Bletchley. They used mock Enigmas that cycled through starting positions every quarter of an hour but the Germans started using a plugboard which introduced new possibilities. The Poles noticed certain patterns in the messages, possible only via specific plugboard settings. By collecting cards corresponding to different initial signals and aligning those with the same daily settings, they were able to narrow down possibilities using optical computing devices. Unfortunately, on May, the Germans invaded France, and on the same day, they changed their Enigma procedures, making the Zygalski sheets useless. The first synthetic aperture radar processor was also optical, as Dr Elachi described, with the received signal recorded on an optical film which is processed in an optical correlator to generate the final image. Alternatively, the signal can be digitized and transmitted via a digital data link. The use of the Enigma decoding covers four chapters, filled with excitement, secrecy, and unusual methods reminiscent of old procedures like the setting up of agents, suborning informants, sending messages written in invisible ink, masquerading, dressing-up, secret transmitters, examining wastepaper baskets - all cover for another source. Regards, Dave."
   }, {
    "body": "Does the system occasionally provide guidance or interject without being directly asked, such as overhearing a conversation about a person going to Seattle tomorrow and offering information about Seattle's weather? If so, has it ever been programmed to do this, and does it have any prior experience working with Kragen?"
   }, {
       "body": "Is there a scenario where you don't explicitly address the AI but it listens in and offers advice or interjects, for instance? To clarify, is that something you do? It seems similar to overhearing two people discussing their plans to go to Seattle tomorrow and feeling compelled to share your knowledge about the city's weather. Please, could we refrain from doing that - it's important to conserve energy."
   }, {
       "body": "Dear R.A Hettig, \n\nThe first computer to decode Enigma was optical at Bletchley Park, utilizing optical sensors for reading paper tape at high speed (as detailed in standard accounts such as but not limited to Colossus, though it should be noted that Colossus was not for Enigma, and the bombes used were electromechanical). I'm uncertain if any optical techniques were applied to Enigma outside of Bletchley Park, as they might have been done in the US and are still classified. Regarding your statement, its credibility may depend on whether you consider bombes as computers or not, as it was indeed the bombes that performed the first bulk breaks of Enigma. \n\nRegards,\nGreg Williams, Zenon Campaign"
   }, {
    "body": "Elias Sinderson has reached out regarding a matter concerning three communication channels, which fall within the same spectrum as microwaves, cordless phones, and video-based baby monitors. Greg Gregory Alan Bolcer, our CTO (gbolcer@endeavors.com) at Endeavors Technology Inc., is asked to address this issue."
    }, {
       "body": "Hello, \n\nI've got some updates regarding our recent discussions about household appliances and the new house. Our microwave, as you may recall, died a week or so ago, and after doing some research, we have decided not to replace it in the near or distant future. Even if half of what is reported about the potential hazards is true, it's not worth it for a quick cup of warm chai.\n\nRegarding the oven, finding a good convection-only model without a microwave has been quite challenging, especially in a decent size. However, we found DeLonghi, which is available through Costco's online store. But here comes the question: should we get it delivered to the old house or the new one? We have had our offer approved and are in the process of closing on Oct, though our real estate agent mentioned that this can happen quite quickly, which was quite surprising given we found a house with the space we wanted on Sunday and will be signing papers on Tuesday night with a close at the end of the month.\n\nAs for the internet setup, I'm having some concerns with AT&T Bi-Cable as my main home connection potentially causing bandwidth issues. I'm currently brainstorming ways around this problem, so any ideas would be greatly appreciated. Also, if you have any suggestions for parties in Portland or the time we might meet up, please let me know.\n\nBest,\n[Your Name]"
    }, {
    "body": "At 2 PM on Robert A Hettigga, I apologize in advance and offer my regards. The Internet Bearer Underwriting Corporation, Farquhar Street, Boston, MA, USA, despite its usefulness and historical significance, has not found favor with me for predicting the end of the world. This reminds me of Edward Gibbon's 'The Decline and Fall of the Roman Empire' which did not resonate well with my personal experience."
   }, {
       "body": "I recently came across an article on Ars Technica that discusses how Apple has been demonstrating its affection and respect towards users in various aspects. You can find a comprehensive overview of this topic over at the link provided. Interestingly, third-party developers capitalized on Apple's advanced user interface capabilities by reverse-engineering and utilizing private APIs, which resulted in significant benefits for their applications. However, all of that changed with the introduction of Jaguar. Unlike previous speculations that the private APIs had been modified, Apple actually added code to prevent non-Apple menu extras from loading. Consequently, when a menu extra is attempted to be loaded, it is compared against a predefined list of known menu extras from Apple and rejected if it's not found on that list. It seems Microsoft has a better understanding of the importance of encouraging development on its platform, whereas Apple appears to be struggling with this concept. In Apple's case, while they don't need to make every system service or UI element publicly accessible via APIs right away, their actions of actively hindering third-party developers without providing a supported alternative can be seen as short-sighted."
   }, {
       "body": "The article you received from nytimes.com is a rehash of several British newspapers' reports, stating that the World Health Organization found in a study that blondness would become extinct within years due to being caused by a recessive gene dying out. However, the World Health Organization has stated that they never conducted such a study and have no opinion on the future existence of blonds. It appears the reports originated from unidentified sources but are most likely distributed by one of several European news agencies used by the British press. For more information about advertising opportunities with The New York Times, please visit our online media kit at [link] or write to copyright@thenewyorktimescompany."
    }, {
       "body": "Dear Eirikur Hallgrimsson, \n\nIf my surroundings lack aesthetic appeal in some way, I find it difficult to live. The first question that comes to mind when something seems unattractive is 'Why do I think it's not beautiful?' Soon enough, I realize there is no valid reason. John Cage, Gary Lawrence, Murphy and Teledynamics Communications all assert the same about computers - they can only provide answers, nothing more. This is reminiscent of Picasso's perspective."
   }, {
      "body": "It appears we are almost certain to move into our new house by November, with only divine intervention or a complete economic collapse being potential obstacles. Preparation-wise, we went to Best Buy tonight and purchased a Linksys router, hub wireless AP firewall, wallet C, and a Linksys WiFi PCMCIA card for the laptop. The setup was relatively straightforward; it took me only a few minutes to install the card, set up the router, and connect the other devices in the house via the Ethernet hub. The web interface for configuration is very user-friendly. I plan to delve deeper into the firewall and NAT routing features. I've been reading up on WiFi security on Ars Technica but overall, it was a smooth move. The current house has some strange occurrences due to being situated in a gravel pit, which can interfere with transmissions, but since there are walls and feet between the AP and PCMCIA card, I'm still getting decent WiFi. The new house is job-related, so there's no metalwork in the walls, primarily wood and plaster. We don't have a microwave, and our cordless phones are on, which means I can use my Bearcat to listen in on some calls with kids in the house. Is it such a bad thing, Ben or Heather? If you happen to read this years from now, I hope you are doing well. For now, I've done enough testing for tonight. It's quite enjoyable being able to do all this in bed by vnc-ing via WiFi to my desktop. But now if my pillow is heading this way...duckkkkk"
   }, {
      "body": "On Wednesday afternoon, Tom, I wanted to discuss the issue with Jaguar. Apple made a change in which they added code to exclude all non-Apple menu extras. If you attempt to interfere with Jobs' blessed Aqua interface or remove the OS X dock, you will find that OS X is a step down from Classic with its Kaleidoscope skinning of the entire UI. As an artist, I deeply resent this change, and if my environment cannot be made beautiful in some sense, I cannot live with it. This is not intended as praise for Classic."
   }, {
       "body": "Dear all, \n\nPlease find details about our annual Digital Identity Forum at Hyperion, scheduled in Singapore during October. Notable speakers include representatives from Microsoft, Liberty Alliance UK, Central and Local Government, Law Enforcement, Financial Services (including Egg, RBSNatWest), EC Research Centre, a psychologist, and others. We look forward to your attendance.\n\nRegards,\nDavid Birch, Director - Hyperion"
   },

   {
       "body": "R A Hettigaa, The Internet Bearer Underwriting Corporation, Farquhar Street, Boston MA USA. Edward Gibbon, in his 'Decline and Fall of the Roman Empire', may have predicted the end of the world, but such predictions have not been found agreeable to experience."
   }, {
       "body": "Dear Gary Lawrence Murphy,\n\nWhen something appears to be lacking beauty, I find myself questioning why I perceive it as such and often discover that there is no reason. This sentiment resonates with John Cage, who asserts that when working on a problem, he does not consider beauty; his focus lies solely in solving the issue. However, if the solution is not beautiful once completed, he knows it is incorrect.\n\nR. Buckminster Fuller echoes this perspective, stating that simplicity is the highest goal to strive for after overcoming all difficulties. Similarly, Frederic Chopin views externalities as a last resort for those who cling to control (dirigistes).\n\nR. A Hettinga expresses concern about a scheme that satisfies our wants by suppressing desires - much like trying to fit shoes without feet.\n\nJonathan Swift's words, 'The stoical scheme of supplying our wants by lopping off our desires is like cutting off our feet when we want shoes,' provide an eloquent illustration of this idea.\n\nBest regards,"
    }, {
    "body": "When I'm engrossed in solving a problem, I don't consider aesthetics; I merely focus on finding a solution. However, if the solution lacks elegance or beauty, I instinctively feel that it is not correct. This sentiment is echoed by Buckminster Fuller, who noted that he only appreciated the beauty of his Geodesic Dome after its completion. Similarly, Fuller, Gary Lawrence Murphy, and Picasso share a view that computers, while capable of providing answers, are essentially useless when it comes to appreciating beauty."
   }, {
   "body": "People with ample free time may want to look at this first, as it requires some thought before moving on to the Kenpken Corgi Sandwich Game Developer's opinion piece on the millennium hand and shrimp."
   }, {
    "body": "The attached file appears to be an output from an outdated Java program named Jitterbits. It is particularly beneficial for digital camera users who end up taking numerous photos during vacations. Gary Lawrence Murphy of TeleDynamics Communications notes that conventional computers are limited, as they can only provide answers, similar to Picasso."
   }, {
        "body": "Oh my, it appears there are two of them now. I suppose that's why my job board suddenly skyrocketed to the top of my traffic list. Gary Lawrence from TeleDynamics Communications seems to be having some issues with computers - they can only provide answers, not like Picasso."
    }, {
       "body": "Subject: Annual Consult Hyperion Digital Identity Forum\n\nDear all,\n\nThe annual Hyperion Digital Identity Forum is taking place and unfortunately, there has been an error with the URL provided which should redirect to <RA_HETTINGA>. Please visit the website for more details.\n\nSpeakers at this event include representatives from Microsoft, Liberty Alliance UK, central and local government, law enforcement, financial services (such as Egg and RBS NatWest), the EC Research Centre, a psychologist and others. We look forward to seeing you there.\n\nRegards,\nDave Birch, Director Consult Hyperion\nTel: [phone number]\nFax: [fax number]\nEmail: [email address]\nWeb: [website URL]"
   }, {
       "body": "Dear Stephen D. Williams, The purpose of our lives appears to be liberating ourselves from all addictive entanglements and ultimately unifying with the sea of living love. Two options presented are psychosis and neurosis. I thought I'd share this with you from the Northern Mountain Order of the White Wind Zen Community. A side note regarding computers and women in Zen: according to Gary Lawrence Murphy, they can only provide answers, much like Picasso's perception."
    },, {
      "body": "Typically, I am averse to mysticism, even when it is coupled with sound ideas as it serves as a significant turnoff. For instance, the contrast between YogaTM and more scientifically-grounded relaxation techniques such as Betagenics Hypnosis, Autohypnosis etc, demonstrates this point. As a teenager, I immersed myself in various topics including Tai Chi vs Tai Bo Gforce Dynostaffi. However, stumbling upon this (while searching for something entirely unrelated), I must say that it contains some witty truths, one of which I particularly appreciate is their emphasis on non-addiction. The MindProd Treehugger site also provides some intriguing quotes etc. To be honest, most of these 'new age' jargon seems to presuppose that you are a simple-minded individual in need of religion-like coaching of ideas to grasp and internalize. This can be rather irritating, but taken in moderation, it is interesting to compare and contrast with our modern mental models. I found that a few of the principles could be used to explain and justify US foreign policy and actions. Apologies for any embedded HTML. We create the world we live in. A loving person lives in a loving world; a hostile person lives in a hostile world. Everyone you meet is your mirror. You inflict suffering on yourself and others just as much when you take offense as when you give offense to be upset over what you don't have is to waste what you do have. The past is dead, the future is imaginary; happiness can only be in the eternal now moment. How soon will you realize that the only thing you don't have is the direct experience that there's nothing you need that you don't have? Love a person because he or she is there. Happiness happens when your consciousness is not dominated by addictions and demands, and you experience life as a parade of preferences. The purpose of our lives is to be free of all addictive traps and thus become one with the ocean of living love."
   }, {
     "body": "Dear Stephen D, \n\nI came across an intriguing method that though never written about by PK, he often demonstrated in workshops. It's a technique to alleviate physical pain: draw the pain in the air with your finger, approximately the size of a few inches to a foot, and take around 10 seconds to trace its perimeter carefully. Listen to the pain to find the precise boundary between where it hurts and where it does not. You will find that after about 5 minutes, the pain may shift, shrink, or disappear. A variant of this is to imagine making a model of the pain using colored clay. I must admit, I used this method on a particularly troublesome coworker, and I found it quite amusing.\n\nRegarding your opinion about mysticism, even when associated with good ideas, you share my sentiments. However, while searching for something unrelated, I stumbled upon some interesting truisms in the MindProd TreeHugger site, particularly their addiction to non-addiction. Though much of it is wrapped in new age vernacular, it's intriguing to compare and contrast with our modern mental models.\n\nI found a few principles that could be used to explain and justify some of our foreign policy actions. I apologize for the embedded HTML.\n\nAs per the quote, 'we create the world we live in', a loving person lives in a loving world, a hostile person lives in a hostile world. Everyone you meet is your mirror; you make yourself and others suffer just as much when you take offense as when you give offense to be upset over what you don't have is to waste what you do have. The past is dead, the future is imaginary, happiness can only be in the eternal now moment. Love a person because he or she is there; this is the only reason for happiness.\n\nI found that when your consciousness is not dominated by addictions and demands, you experience life as a parade of preferences, and the purpose of our lives is to be free of all addictive traps and thus become one with the ocean of living love. Sincerely, Stephen D Williams"
   }, {
    "body": "Regarding Mr. Fork's query, imagine a scenario where a bot listens in on a conversation between two individuals discussing potential trips. In this situation, the bot might provide information about the weather forecast without being explicitly asked. I suspect it's not as insidious as active spam, but more like offering helpful tips. However, it could potentially be seen as intrusive or unwanted interjections. For instance, instead of directly asking for Seattle weather, the bot might mention it on its own initiative, possibly even offering discounted airline tickets. This could be perceived as annoying, especially if the adjective to describe such a bot is 'Peregrine', meaning having a tendency to wander or intrude."
   }, {
    "body": "Greetings, it seems this child has an abundance of free time. Kind regards, bitbitch"
   }, {
    "body": "I came across some interesting points, not entirely novel, but still worth mentioning. The Economist seems to have noticed the parallel between interacting with computers and socializing online, akin to using MSN. Here's to more insightful discussions on this topic!"
   }, {
      "body": "I had an idea for an active chat similar to AOL, where ads and other features were triggered based on discussion topics. The VP of Development (now CTO) was very interested in this concept, and we even discussed the possibility of patenting it. However, interest waned probably for the better. \n\nLorin Rivers suggested a scenario where interaction with the bot isn't direct; instead, the bot listens in and provides advice, corrections, interjections, etc. For instance, a weather bot might mention the forecast while two people are discussing trips without being explicitly asked. My guess is that it's more intrusive than that, potentially becoming active spam such as 'You're going to Seattle? I can get you airline tickets for less.' \n\n"
   }, {
    "body": "Hi there, I thought you might find this interesting - a story about the Ig Nobels, always worth a read. If only we had a Catmood Decipherer! Navel gazing has won an Ig Nobel this year, as reported by Jay Lindsay in Boston, October."
    }, {
      "body": "Dear Dave, \n\nThe United States is the only country in the world to tax its citizens on a global basis regardless of their residence or assets. This was stated by Philip Marcovici, a Zurich-based lawyer from Baker & McKenzie. Even under current expatriation law, wealth thresholds based on net worth can imply that an individual giving up US citizenship is doing so for tax reasons. Individuals who have relinquished their citizenship and who earned anything in the years before expatriation or who have a net worth exceeding a certain threshold are automatically deemed as 'taxpatriates'. These individuals would be subject to ordinary income tax on U.S. source income for the years they would also be subject to U.S. estate and gift tax during the period.\n\nIf a new proposal in Congress becomes law, all citizens who relinquish their status will be taxed as if they had sold everything or died, exposing them immediately to capital gains tax. It is worth noting that this would mean they would also immediately pay out the difference for anyone whose tax basis was greater than their current estate value.\n\nOn a positive note, Australian cities overall scored particularly highly in The Economist Intelligence Unit's survey of desirability for expats. All five of Australia's urban centers surveyed ranked near the top of the table. Europe was also well represented among the top places. The top U.S. city, Honolulu, ranked along with Boston (the highest-ranked city on the U.S. mainland). Canada contrastingly had three cities in the top ten. The UK cities of London and Manchester gained only a midtable rating, while Port Moresby in Papua New Guinea was at the bottom of the list."
   }, {
     "body": "I am not very familiar with eRoom, but the phrase 'collaborate in real-time' seems to be causing some apprehension among users. However, I wonder if any users actually derive benefits from real-time content management. Documentum, a content management vendor, announced on Thursday that it plans to acquire privately held eRoom Technologies in a deal worth approximately $100 million. Documentum will issue about $40 million in its common stock and pay about $60 million in cash for all the outstanding shares of eRoom. Documentum offers a platform for enterprise-wide content management, while eRoom provides tools for enterprise collaboration. Their customers include Airbus, Bausch Lomb, Ford Motor Co., and Sony. Documentum announced plans this summer to deliver a new collaboration edition of its content management suite, and eRoom was already integrating its tools onto the Documentum platform, making an acquisition a logical move, according to Documentum's President and CEO Dave Dewalt. With the upcoming joint product, customers will be able to collaborate in real-time via virtual workspaces, sharing schedules, resources, and even jointly creating content. Content creation and management has traditionally been a collaborative task, but workflow has typically been delivered through web browser interfaces or even simple email, rarely in real-time. For now, Documentum will sell the eRoom platform and its own content management system through combined sales channels; further integration is planned down the line."
   }, {
      "body": "It appears that someone accidentally entered a URL incorrectly, which redirects to 'I didn't mess it up, I fucked it up by not paying attention while copying and pasting from somewhere else'. In the future, I will ensure to leave such tasks to our PR team. Best regards, Dave Birch"
   }, {
    "body": "Documentum, a content management vendor, announced its acquisition of Eroom Technologies for approximately $104 million. The deal involves issuing around $3.4 million shares of Documentum's common stock and paying about $9.6 million in cash for all outstanding shares of Eroom. While the details of Eroom are not well-known, it specializes in enterprise collaboration, specifically real-time collaboration. This acquisition comes after Eroom had already started integrating its tools with the Documentum platform, making it an easy target according to Documentum President and CEO Dave Dewalt. The combined entities will allow customers to collaborate in real-time via virtual workspaces, sharing schedules, resources, and even jointly creating content. While content creation and management have traditionally been collaborative tasks, real-time collaboration has rarely been a feature offered before now. Post-acquisition, Documentum plans to sell the Eroom platform and its own content management system through combined sales channels. Further integration is planned down the line."
   }, {
      "body": "Hello,\n\nI was wondering if anyone knows why vCard support is missing in Mozilla, as it's not present in Netscape either and consequently, not in the new mail engine. I noticed that both Netscape Messenger and Mozilla have LDAP (Lightweight Directory Access Protocol) LDIF (LDAP Data Interchange Format) import/export, but I can't find vCard or any references to it anywhere. I appreciate your Netscape/Mozilla email client due to its features, but I avoid using Windows due to security issues, as my main environment is Linux. With the growing popularity of LDAP and related DSML (LDAP Services Markup Language) and DNS SRV (Service Location) record methods, is there a decline in vCard usage? Is there an emerging standard to address the naming mismatch between the two?\n\nI've had some experience with directories in the past, but I find myself diving deeper now, especially with the increasing focus on PKI (Public Key Infrastructure). I will soon be integrating smart cards into my Linux and other systems and connecting them with Netscape Messenger/Mozilla and Outlook. Any wisdom or guidance would be greatly appreciated, particularly in regards to integrating smart cards.\n\nThank you,\nSDW"
   }, {
      "body": "British researchers were recognized for their study that discovered ostriches exhibited increased amorous behavior towards each other when humans were present. Interestingly, this behavior eventually extended to attempting advances on humans. Remarkably, the same applies to manatees. The Ig Nobel Prize, an annual prize for ten achievements that 'first make people laugh, then make them think', was awarded to this study. Carey thought you might appreciate reading about it: If only they had a Catmood decoder, 'Navel Gazing Wins an Ig Nobel' by Jay Lindsay, Boston, October."
   }, {
      "body": "The research of Geege Schuman's team was recognized for discovering that ostriches and manatees become more affectionate in the presence of humans. Interestingly, some ostriches even started to make advances towards humans. This phenomenon is also observed in manatees. The question arises as to how much of this behavior is due to crossing species boundaries for social status or ambition towards authority figures, and how much is due to novelty or the 'they'll fuck anything given appropriate conditions' mentality. It seems that the last hypothesis might be a test of intelligence, considering it is a particularly human perspective."
    }, {
       "body": "The structure of the internet has always been independent of where physical paths are laid, yet the world requires 'ditch diggers' too. It seems you view the world in a similar way - your degree of separation makes you a new version of yourself. The concept of scale-free networks, often associated with viruses, sex, and money, is not as trivial as it may seem. Statistically indistinguishable models actually refer to internet-scale phenomena, rediscovered through social network research. It has been found that the network of human sexual partners also appears to be scale-free. I prefer the Harvard Business Review over The Economist due to their lesser focus on who is involved in intimate relationships and their emphasis on developing real statistical models. Gregory Alan Bolcer, CTO at Endeavors Technology Inc (endeavors.com), recently wrote an article that highlights the similarity between computer and social chat with friends online. It was interesting to see The Economist acknowledge this parallel."
    }, {
     "body": "The text you provided seems to be a passage discussing the importance of elegance and aesthetic design in both structural engineering and programming languages. The author suggests that good designers choose designs that look good because they are good, as these designs can be confidently used by both the designer and the user. The programming language is also seen as a work environment where it should contribute to the quality of activities taking place within it, encourage its use, and not hinder but serve as a collaborator. Additionally, the programming language symbolizes various values and can promote a set of values through its features. To acquire a refined sense of elegance necessary for good design, one must gain extensive experience in design, critiquing and revising their own designs, as well as evaluating and improving other people's designs."
   }, {
       "body": "The Palestinian woman, Hijacker High Dalal Mughrabi, was involved in a bus hijacking that resulted in the deaths of Israelis and an American nature photographer named Gail Ruban. Interestingly, a high school has been named after her, but it's starting to show signs of deterioration. Fortunately, the United States Agency for International Development (USAID) has intervened with funds to help renovate it. This is a step towards ensuring the longevity of this Palestinian institution."
   }, {
      "body": "She reviewed the links and wondered about the life dedicated to highlighting neighbors' errors, mishaps, inconsistencies, and frailties. She mused that boasting might be undervalued, as per good books, John. Bring it on! On behalf of Saturday, October, let us discuss our friends, the Palestinians, and their governing officials. High Dalal Mughrabi was a Palestinian woman who played a part in a bus hijacking during which Israelis and an American nature photographer, Gail Ruban, were killed. A school named after Mughrabi in Palestine seems to be deteriorating, but fortunately, the United States Agency for International Development has stepped in with funds to aid in its renovation. Here are the links for your reference: Censeo Palestinine (Esse Delendam)"
   }, {
      "body": "I suggest renaming it Charlie Heston High, which might encourage students to practice with extended military-grade scopes and high-velocity ammunition, a more effective approach than random acts of violence in the suburbs of Washington. Lately, violence associated with any political ideology contradicting Bushism is seen as abhorrent, but random violence seems to be entertainment and intrigue. According to a few ex-FBI consultants commenting on the shootings in DC, the shooters, who are presumed to be a pair, appear to be experiencing a heroin-like high with each successful kill, and they for some reason decided to challenge law enforcement and society. This was not fun and games, as John Hall put it on Saturday at 3:00 PM; it was more about adding to the horror file. For the Palestinians, such incidents are not accidents, which is a crucial part of the horror. I'm not against the American taxpayers remodeling a school honoring a killer if we do it with a Daisy Cutter. Here are some links for your reference: [US Foreign Bureaus Architecture Page](foreignbureausarchi), [Praeterea censeo Palestininem esse delendam](foreignbureausasppageforeignbureausarchi). John, do bring it on!

   Regarding the renovation of a school honoring a Palestinian woman, Dalal Mughrabi, who participated in a bus hijacking that resulted in the deaths of Israelis and an American nature photographer, Gail Rubin, it's good to know that the United States Agency for International Development has taken steps to help renovate it."
   }, {
     "body": "It was not boasting, but rather an addition to our collection of atrocities, and indeed, for the Palestinians, it was not a mistake which is a crucial part of their horrifying reality. I am not opposed to American taxpayers rebuilding a school honoring a murderer; if we do it with a Daisy Cutter, that would be another story. George Schuman wrote on Saturday afternoon: 'For our friends the Palestinians, our servants in government,' she read the links, wondering what kind of life it must be to spend one's days pointing out neighbors' mistakes, mishaps, inconsistencies, and frailties. Gloating is definitely underrated in the good book, eh John? Bring it on, George.' On behalf of John Hall, Saturday afternoon: 'For our friends the Palestinians, our servants in government,' high Dalal Mughrabi was a Palestinian woman who participated in a bus hijacking, resulting in the death of Israelis and an American nature photographer, Gail Rubin. The school named after her is showing signs of wear, but fortunately, the United States Agency for International Development has provided funds to renovate it. Unfortunate events such as these suggest that Palestine should be destroyed."
   }, {
           "body": "I am not opposed to American taxpayers refurbishing a school named after a criminal, should we choose to do so. However, I would like to bring up an unusual suggestion: let's include a Daisy Cutter bomb, with or without occupants, as part of the remodeling."
           }, {
    "body": "John Hall's comment was not a boast, but rather something for the 'horror file'. For the Palestinians, this incident is far from a mistake; it forms a significant part of their horror. I'm not against American taxpayers renovating a school, but if it's to honor a killer, I am concerned. If we rename it after a weapon like a Daisy Cutter, I assume the intention is that it will eventually be renamed for the settler who eliminates the last Palestinian in a few years."
   }, {
      "body": "I have reviewed the links you sent, which were shared by Geege Schuman on behalf of Sunday October. The content seems to express concern about a school being remodeled in Palestine, with references to its former name and past events. It also suggests that there is unease about future implications, particularly if the school is renamed again in the future. However, it appears that the author is not against the American taxpayers funding this project."
   }, {
     "body": "When a settler commits a violent act and kills Palestinians, they are treated as criminals, not heroes. However, you were well aware of this when a Palestinian sets out to celebrate, intending to harm innocent children with a suicide bomb. It's interesting to note that the shrapnel in these attacks is often dipped in rat poison to prevent blood clotting in victims. I presume all Jewish suicide bombers do the same, but wait, there aren't any, are there? If Palestinians are forced out either by expulsion or death, they will have no one to blame but themselves. However, this won't stop you from pretending otherwise on behalf of Owen Byrne. I assume the plan is that the area will be named after the settler who kills the last Palestinian in a few years. Owen."
   }, {
    "body": "Regarding your request about the Palestinian issue, I have read the links you provided and found them both informative and enlightening. Exposing governmental folly is not merely amusing but also educative. By ridiculing such folly, we can prevent it from recurring in the future. The article 'brickbats' leans heavily on this concept, though the specific example you highlighted was indeed shocking rather than comical. To illustrate a comic instance, consider the case of a city that fined a woman for parking in an unmarked no-parking zone – absurd, isn't it? I hope this helps clarify your points."
   }, {
      "body": "I hope this message finds you well. I wanted to clarify that while the articles you shared may be humorous, they also serve an educational purpose in exposing folly. As you rightly pointed out, ridiculing folly can help prevent it from recurring. The example you provided of a city wanting a woman to pay for parking in an unmarked 'no parking' space was indeed a 'stupid item'. For comparison, I suggest looking at the article titled 'The City that Wanted a Woman to Pay for Parking in an Unmarked "No Parking" Space' by Geege Schuman. Regarding your comment about me being an idiot for reading Brickbats, I hope you did not mean it as intended."
    }, {
      "body": "For over three years, I've been experiencing a persistent issue with my phone bill from Pacific Bell (now SBC). Each time I contact them every two to three months, I encounter a problem with a disconnected phone line that someone who no longer resides at our house is still being billed for. Sometimes their system can't find the account, others claim it has been disconnected, and occasionally they verify the disconnection but are unsure about the owed amount or how to send us a bill. After sending back the bills marked 'Not at this address', I have to repeat the process again. Recently, I explain that I understand their representatives aren't to blame for the issue and express my frustration constructively by giving them the option to escalate the matter to their superiors. Lately, I've received a refund check from Pacific Bell (SBC). It appears they went through the trouble of printing, signing, sealing, and stamping a check to refund me a minimal amount."
   }, {
      "body": "I found it rather amusing when my apartment manager persistently emailed me notices about an alleged debt, especially since their office was right behind where I lived – Cindy on Mon Oct. Today, I received a check from Pacific Bell (now known as SBC). It turns out they went through the trouble of printing, signing, sealing and stamping a check to refund me, which, considering how little the amount is, they spent more than necessary just for materials. My question is, why do companies go through such expense when there's a bottom line regarding cost-effectiveness? Perhaps I should have appreciated lower rates instead of being returned pennies. I am still perplexed as to whether I should frame this check, burn it or deposit it. Maybe returning it for them to spend more money on processing it again would be a good idea, though I'm not sure if that buys anything anymore. Ironically, I couldn't even make a phone call these days – boggles the mind! BB, by the way, I have no interest in mathematics."
   }, {
     "body": "I have been pondering over this issue since Monday, October [date]. I'm in a dilemma about what to do with the check I received years ago for a CD sale, which serves as my tangible proof that I am a professional musician. I haven't cashed the check yet, so technically, I haven't been paid. However, this is a separate issue altogether."
   }, {
       "body": "I knew it would be a day for madness, so today Newscom chose to write two insightful articles about the DMCA and even linked to the controversial Decssexe code. Interestingly enough, none of the other news services that originally linked to spankedslashdot followed suit, but I did. I find this whole situation incredibly amusing. It seems that Congress and the courts really need to be examining how laws such as the DMCA are applied. Unfortunately, these rules seem to be more about who you know, how nefarious the defendant party is, and how sympathetic the judge is towards the case rather than objective justice. This cynical view on being a lawyer has certainly been reinforced. Best regards,"
    }, {
     "body": "Dear Dave, \n\nI was informed that only the United States taxes its citizens on a worldwide basis. As far as I know, this is also the case for Australia. However, I shouldn't rely on editorial fact-checking. If they manage to replicate the process that took place in Northern Ireland, perhaps in a few years they'll be arguing across the floor of some legislative assembly instead. Label me an optimist since 'letting you and him fight' worked so remarkably poorly in Ireland, but there must have been places where it worked well for the British to attempt it again in Israel. I'm not sure what you mean by 'letting you and him fight,' but it is important to remember that England controlled Ireland for years, and it was only due to the distraction of WW1 that the south managed to gain its independence. If you mean splitting countries upon arbitrary lines and assigning different groups to opposite sides of the line, it also seems to have not worked in India (Pakistan), a similar situation to Ireland. Canada, which is supposed to be a loose confederation of founding nations (French and English), can be cited as a success. The jury is still out, but so far only a few brief rebellions and referendums have occurred, with the country remaining together after years. Owen"
   }, {
       "body": "I recall hearing about this a few years ago, and it appears that both Wired and Slashyrot are running stories on data transfer via human touch. This seems to be the first bi-coastal file exchange system, where the newest offspring tunes could potentially be distributed through handshakes or 'copulation' (as in merging of files), and possibly even through mosh pitting (as in a chaotic, energetic sharing of information)."
   }, {
    "body": "Hello Monday, October PM,\n\nI recall hearing about this concept a few years ago, but Wired and SlashyRot are currently covering data transfer through human toucht. It brings to mind the first bicoastal file exchange system where newborn tunes would be distributed by handshake copulation and moshpitting.\n\nI'm just curious, with the porn market often being the earliest adopter of all new technologies, how will they spin this one? It seems like an innovative way to transfer data while physically interacting - exchanging energy.\n\nBest regards,\nBitBitch"
   }, {
    "body": "I recently received a check from Pac Bell (now known as SBC) for an unpaid claim. It appears they went through the trouble of printing, signing, sealing, and stamping a check to refund me, despite spending more than the amount on the check just to gather materials. I find it perplexing that companies still engage in this costly behavior, especially when one considers the bottom line. I couldn't help but wonder if I should have received lower rates instead of being refunded pennies. The situation has left me puzzled - whether to frame the check, burn it, or cash it. Perhaps returning it to sender could make them spend more on returning my due funds, but I'm not sure if that's practical. It's ironic that I've had issues making phone calls recently and yet companies still seem to be wasting resources like this. Best regards."
   }, {
      "body": "John, I understand your frustration with the refund check you received from SBC (formerly Pac Bell). It seems to be an unnecessary expense on their part, especially since they could have simply waived the overcharge or reduced some of those service fees. Instead, they opted for a check, which appears to be more costly than beneficial. I share your sentiment that it would be preferable for companies to prioritize cost-effectiveness and fair pricing rather than overbilling customers slightly to keep excess revenue. However, the legislation seems to lack effective means of controlling this situation, resorting to requirements like this refund check instead. It's a strange predicament we find ourselves in. I appreciate your analogy about framing, burning, or cashing the check, but I think returning it might be an option to express your displeasure and make them spend more on processing the return. In essence, it seems that value is no longer what it used to be."
   }, {
      "body": "Dear James Rogers, \n\nIt seems that you are discussing the current state of Canada, which is a loose confederation of founding nations (French and English). While it can be cited as a success, there is ongoing debate about this. So far, only a few brief rebellions and referendums have occurred, but Canada has remained together for years. However, Alberta, and to some extent other western provinces, are not happy with the current arrangement. This dissatisfaction stems from the unique structure of the Canadian government, which ignores the interests of Alberta despite its economic powerhouse status. The province sends more than twice the tax dollars per capita to Ottawa compared to the average Canadian, yet only receives token representation in the federal government.\n\nThe problem lies in the fact that the smaller eastern provinces have a greater number of representatives in the legislature than the entire province of Alberta, despite having fewer people. This allows the eastern provinces to draw funds from Alberta for their social programs without giving anything back in return.\n\nIn essence, Alberta is being used as an ATM machine by the eastern provinces, and this has led to growing dissatisfaction among Albertans over the years. The Canadian government has more flexibility than the US government, allowing it to implement regulations that only apply to certain provinces, with Alberta often on the receiving end of these restrictions.\n\nYou mention that you have friends in Alberta and visit occasionally but are not fully clear on everything that goes on due to your partial unfamiliarity with their government. What is clear is that Albertans are increasingly unhappy with their current position in Canada, and this sentiment has been worsening over the years.\n\nBest Regards,\n[Your Name]"
   }, {
       "body": "I am deeply invested in decentralization due to my conviction that many of the pressing issues with networked applications today are rooted in centralization. Centralized systems, be it political or economic, only allow for one solution to a problem, whereas decentralization allows multiple separate entities to hold different views on the same subject. In software terms, centralized variables can only have one valid value at a time, which restricts our ability to represent information based solely on the beliefs of one agency. This limitation is manifesting in practice, for instance, email protocols and tools do not acknowledge the distinct interests of senders and receivers, leading to issues like spam. Centralized systems also create unfair advantages such as with real-time bidding where lower latency connections to a centralized auction server can lead to an advantage (SLAMMING). Ad-hoc wireless networks are another example of decentralized resource allocation. On a broader scale, the limitations imposed by centralization, though seemingly abstract today, will not improve as the cost of computing, storage, and communication bandwidth continues to decrease. The speed of light and human independence establish fundamental limits to centralized information representation, thereby limiting the efficiency and adaptability of centralized software architecture."
   }, {
    "body": "Chris Haun, a LifeGem is a certified high-quality diamond made from the carbon of your loved one, serving as a memorial to their unique and wonderful life. I'm sure there's enough carbon in the fat from a typical liposuction procedure to create a decent diamond. Joe"
   }, {
       "body": "Dear [Recipient], \n\nOn behalf of Dave Long, I am writing to share some thoughts regarding your recent discussion on property rights. \n\nWhen you mentioned that obtaining legal title can take years and assumed we were referring to the urban poor, it seemed logical given the context of Cairo's reference. However, upon observing people living in mansions or suburban subdivisions, I presumed they did not encounter too many issues with their titles. \n\nIt appears that I made a similar assumption about a different country, where a local newspaper, intrigued by our evidence of extralegal real estate holdings, checked the head of state's official residence for a recorded title. Interestingly, it was discovered that there was none. \n\nThe value of land in the formal sector of Lima averages per square meter, while in the area of Gamarra, where a significant part of Peru's informal manufacturing sector resides, the value can be as high. This led me to believe that De Soto's argument, that it is incorrect to assume that those living in mansions without title are the norm, may not hold true in this case. However, De Soto explains that while such properties might exist, they cannot be used for collateral for a loan or other purposes due to their extralegal status. \n\nMr. Long may find the work of Hernando de Soto particularly interesting, as it delves into the phenomenon you referred to as 'the bell jar'. De Soto proposes that this bell jar is created by segregating those who have practical access to legal property rights and those who do not. The latter group lacks access to systems where property can be turned into capital and allowed to grow. \n\nIn the meantime, you might find it interesting to explore the work of French historian Fernand Braudel, whose 'Bell Jar' is a different concept. Braudel's 'Bell Jar' refers to understanding why a sector of society, which was capitalist in nature, lived as if in a bell jar, cut off from the rest. It questions why this sector was not able to expand and conquer the whole society, and why significant rates of capital formation were only possible in certain sectors and not in the whole market economy of the time. \n\nIt may seem paradoxical that during an age of depressed economic climate, magnificent country residences were being built. De Soto's theory is that this phenomenon occurs when access to legal property rights is segregated, limiting the growth and expansion of capital."
    }, {
     "body": "I find political snail mail appealing, despite its shortcomings. It provides valuable information about local politics that is not readily available on television. The protection of political emails is equally important as any other form of political speech. Spam serves as a tool for dissident news since recipients cannot be held accountable for being on the mailing list."
   }, {
    "body": "On Friday, Robert Harley shared an amusing anecdote. Whether it's true or not is uncertain, but the story certainly doesn't support a conclusive or authoritative statement. This strategy seems to be a useful tool - let any anecdotal statements pass as truth until proven false and then apply a stricter standard to other data. I understand how this approach could be advantageous before the label mongers start their work. I don't care much about Bubbau's utterances, they are all nonsense. My advice is to 'kill your idols,' as your slips are showing."
   }, {
     "body": "I have my doubts because I've never come across any information suggesting that Bush and Chirac actually went to Brighton. The email only mentions Blair speaking with Williams there."
    }, {
     "body": "I'll be eager to see your response unless you're a fan of anime or subscribe to the belief that deceased individuals can send emails. I find the subject of your email amusingly intriguing. By the way, I've recently filled up the green coolant in my Navi Bonus and was wondering if Adam is aware of which anime I'm referring to. If he isn't, I suppose that means no bonus points for me, didn't think so. Joe, we've just begun watching Boogiepop Phantom, where the combatant's state is described as your father and mother being your only protector. It seems no level of discipline could be too harsh for one who denies this by word or deed."
   }, {
       "body": "On Sunday, September, I presume Geege finds her subject quite amusing, especially since she has stepped away from AOL and moved on to another platform. Interestingly, AOL is still considered the most mom-friendly place to secure bandwidth, though it seems you might not be as adept with a bow as you should be if you're trying to escape! Bonus points if Adam recognizes the anime I'm referring to. To clarify, in the world of anime, there are characters who can communicate via email and lead somewhat normal lives, much like the protagonist of Serial Experiments Lain, where the initial 'I'm not dead yet' is conveyed through email. Adam L Duncan Beberg"
    }, {
     "body": "Dear Mr. Shore,\n\nI understand that you are proposing a patent idea for a system where a warrant mark is added to RFC xheaders or the body of an email, allowing senders to certify their mail as 'not spam'. This warranty would be enforced using copyright and trademark infringement mechanisms. It appears that your vision involves Verisign playing a role in this process, potentially signing all your non-spam emails for a fee.\n\nHowever, I must express some reservations about your idea. As you mention, a service like this, if implemented by a company such as Verisign, might also potentially be used to sign spam. This could lead to confusion and undermine the trust in the system.\n\nSincerely,\n[Your Name]"
   }, {
    "body": "On Tuesday, August, Matthew Cline informed Harold Hallikainen about a unique opportunity for companies. They can utilize short snippets of copyrighted and trademarked text in their email message headers. These texts will serve as a 'notspam' indicator, recognized by email filters. Any spammers who use the text may face legal action for copyright and trademark infringement. It is possible that there could be a patent dispute before any action is taken. This initiative aims to separate legitimate bulk emailers from spammers, with Ironport Systems Inc in San Bruno, CA developing the 'Bonded Sender Program'. This program is designed to offer credibility to legitimate senders. This SFNet email is sponsored by OSDN. Tired of constant spam? Join our SpamAssassin Talk Mailing List for a solution."
    }, {
    "body": "If I establish a rule with the name 'delete', would it remove this text from the body and conceal it from other rules? If so, I'm considering using it for Yahoo, SN, and Juno ads to reduce FPS. This SFNet email is sponsored by OSDN; tired of that same old cell phone advertisement? Get a new one for free! SpamAssassin development mailing list."
    }, {
      "body": "Dear Justin Shore, Pittsburgh State University Network Systems Manager,\n\nI recently came across a false positive in my spam filter that flagged an email as an unsolicited ad from Applecom regarding educator deals. If you'd like to see the email, I can send it over and add it to our non-spam corpus.\n\nAs for the new release, we've been working on improving the scores given by SpamAssassin, particularly for HTML mail that resembles newsletters. Since you've been signing up for legitimate newsletters from various sources, these types of emails should no longer receive high spam scores once we re-run the system.\n\nI find your approach to be quite slick! If I come across any more such legitimate newsletters, I will definitely share them with you.\n\nThank you for the information and keep up the good work!\n\nRegards,"
   }, {
    "body": "It appears that there is an issue with the user's procmail configuration, specifically in her homeuserprocmailrc file. The problem seems to be that the recipe for forwarding inbound emails to another email address outside the company is not working as expected. Here are a few suggestions that might help you troubleshoot:

    1. Check the syntax of the user's procmailrc file. Ensure it follows the correct format and there are no typos or errors.

    2. Test the user's procmailrc file in isolation to confirm if it works independently from the global etcprocmailrc file. You can do this by temporarily replacing the global file with a test file (test procmailholder as mentioned).

    3. Investigate if there are any differences between the working and non-working user's procmailrc files that might be causing the issue. This could include permissions, paths, or other configuration settings.

    4. Verify that the user's email client is correctly set up to use the local procmail mechanism for processing messages. Sometimes, issues can arise due to incorrect client configurations.

    5. If none of the above suggestions resolve the issue, consider reaching out to a procmail expert or seeking help from the spamassassin-talk mailing list you mentioned."
   }, {
    "body": "It's conceivable that the poor economy is affecting spammers just as much as others, but if you've been actively reporting them, it could simply be that. It might also be possible that your upstream ISP is becoming more aggressive in this matter. I will follow up on Wednesday, August at 3 PM to discuss this further. The plots provided do not illustrate the drop from daily to weekly emails I've noticed at work since the week of May when spam receipts peaked. It's unclear whether it's aggressive reporting getting us off lists or if others are experiencing similar situations."
   }, {
    "body": "Theo Van Dinter, I have rerun the mass check and resubmitted the mail. I have sorted the log by score so the timestamp is now visible. I apologize if I missed it before. Regarding the SFNet email sponsorship and your frustration with the same old cell phone advertisements, perhaps you could consider getting a new one for free here. However, please be aware that this offer may contain spam or unwanted solicitations."
   }, {
    "body": "Subject: Discussion on SpamAssassin's Activity and False Negatives \n\n Dear Theo Van Dinter, \n\n I hope this message finds you well. I noticed that SpamAssassinSightings is the fourth most active list for this month on SourceForge. It seems there is more sighting of spam than talk or development combined. I assume people are aware that they should only send false negatives (spam not detected) to this list? Either SpamAssassin is missing a lot of spam or some users are sending all their spam there. I have sent in some spam that either didn't score or scored practically nothing, as I believe if it scores below a certain level, a rule needs to be refined to catch it. \n\n Most people run SA at a certain score threshold, so if it scores less than that, a rule should be adjusted to detect it. Justin Shore - Network Systems Manager - Pittsburgh State University"
   }, {
    "body": "Thank you for reaching out. Regarding your request about the PerlModule :checkuser and its potential integration with SpamAssassin, I would appreciate it if we could discuss this further. From what I understand, this module implements an SMTPCallback feature. We have not explicitly discussed or rejected this idea in our previous meetings. As for the possibility of implementing it ourselves, it's something that can be explored, depending on our current project priorities and resource availability. If your department contributes a SMTPCallback patch, we would prefer a one-time contribution rather than managing and integrating it with SpamAssassin in the future. This arrangement should work for us, as long as you are running SpamAssassin on an account where all mail from somedomain on another server ends up through per scientiam ad libertatem."
   }, {
       "body": "The text provided appears to be a list of individuals associated with Datapower, a networking technology company. Here are some highlights: \n\n- Kieran Taylor, Director of Product Marketing, who has experience as a marketing professional, industry analyst, and journalist.\n- Steve Willis, Vice President of Advanced Technology, known for his work in protocol optimization and network optimization technologies.\n- Bill Tao, Vice President of Engineering, with extensive experience in LAN and WAN networking.\n\nThe text also mentions Mark Hoover, President and cofounder of Acuitive Inc, a startup accelerator with years of experience in the networking industry. George Kassabgi, currently Vice President of Engineering at BEA Systems, is another notable figure, known for his work in the application server marketplace.\n\nLastly, Marshall T Rose, who runs his own firm Dover Beach Consulting Inc, and was previously the IETF Area Director for Network Management, is also associated with Datapower."
    }, {
    "body": "Dear Ian Andrew Bell,\n\nOn behalf of James Rogers, I'm writing to discuss a recent incident involving your company. You concluded a routine with an impressive quadruple lutz; however, this feat came at the expense of hundreds of thousands of workers who were subsequently laid off. When everything fell apart, it brought into question the stability of employment in such businesses.\n\nIt's important to clarify that laying off workers is neither a criminal act nor an immoral one. Companies do not exist primarily for employment purposes; their primary goal is to generate profit and growth. In the United States, government jobs are the closest equivalent to this concept, although they often come with their own set of challenges.\n\nA debate exists regarding the efficiency of markets versus societal gains from irrational behavior. If businesspeople consistently overestimate their chances, it may lead to losses for the individual businesses but could potentially yield a net gain for society. The law of averages works in favor of society in ways that it cannot for an individual.\n\nOne reason often cited as to why the United States outperformed England was because English investors were too rational for their society's good, except when U.S. investors were exploiting them to build canals and railroads here. \n\nInnovation and technological advancements in dark wire glass could potentially bring substantial benefits to society at a fraction of the initial investment costs. However, it is crucial to remember that these gains often come with costs to the investors.\n\nLooking forward to hearing your thoughts on this matter.\n\nBest regards,"
   }, {
    "body": "On August xx, Rohit Khare of Datapower Technology introduced a network device tailored for processing XML data. Unlike competitor solutions that process XML data in software, Datapower's device handles the data in hardware, delivering greater performance according to company officials. It appears Sarvega also offers a similar product."
   }, {
    "body": "Datapower is a technology company that specializes in developing advanced networking solutions. The key figures of the company include Steve Willis, Vice President of Advanced Technology, who is an accomplished entrepreneur and pioneer in protocol optimization; Bill Tao, Vice President of Engineering, with extensive experience in LAN and WAN networking; Kieran Taylor, Director of Product Marketing, who has a strong background in marketing, industry analysis, and journalism; and Mark Hoover, President and co-founder of Acuitive Inc., who brings over years of experience in the networking industry. Other advisors include George Kassabgi, Vice President of Engineering at Bea Systems, and Marshall T Rose, an expert in internet management and standards."
   }, {
       "body": "Rohit Khare at Datapower is set to deliver an XML acceleration device by Scott Tyler Shafer on August [Date]. It's worth noting that Intel had a similar device a couple of years ago, but Netstructure seems to have abandoned it. However, Intel continues to be active in the XML hardware field. A spin-off company named Tarari has emerged from Intel, specializing in hardware for checking IP packet headers, which they refer to as layer processing within the OSI model. From what I can gather, Tarari plans to integrate virus scanning and XML acceleration into a single hardware device."
   }, {
       "body": "The text you provided contains information about a team of professionals who work at Datapower, a company in the networking industry. Some key figures are Kieran Taylor (Director of Product Marketing), Steve Willis (Vice President of Advanced Technology), Bill Tao (Vice President of Engineering), and Mark Hoover (President and Co-founder of Acuitive Inc). Other individuals mentioned include George Kassabgi (Vice President of Engineering at Bea Systems) and Marshall T. Rose (Founder of Dover Beach Consulting Inc). The text mentions that these individuals have extensive experience in various areas such as product development, marketing, business development, networking, and engineering."
   }, {
     "body": "On Tuesday, Aug 31st, Datapower Technology unveiled a network device tailored for processing XML data, unlike competitors whose solutions handle XML in software. Unlike them, Datapower's device processes the data in hardware, which company officials claim offers superior performance. However, it's important to note that this implies significant implications, unless it's merely a misleading statement. According to Kelly, converting data into XML can increase file size up to 10 times, making processing the data extremely taxing on application servers. Datapower advocates an inline device as the most viable alternative or, alternatively, suggests avoiding bloating data in the first place - a key argument of XML itself. However, similar to Oracle's use of Java, this may lead to increased CPU sales due to the performance hit and large file sizes. Security is also crucial in the realm of XML, with today's firewalls designed merely to inspect traffic. Kelly stated that a SOAP packet with XML will bypass a firewall, rendering them blind to XML today. The claim about decoding crypto has raised concerns as machine code conversion isn't advisable, as pointed out by Adam L Duncan."
   }, {
       "body": "Dear Reader, \n\nPoliticians worldwide are discovering the internet as a powerful tool for fascism. Once the necessary laws are in place to address anonymity issues, it becomes a potent instrument. This story reveals the truth about the Canadian government, which is reportedly headquartered in Washington D.C., with Ottawa serving as a branch office. The article by Declan McCullagh, Staff Writer for CNET News, titled 'Canada's ISPs Become Spies?' discusses a proposal that could make internet providers rewire their networks for easy surveillance by police and spy agencies. This plan also includes creating a national database of every Canadian with an internet account. If implemented, this could severely limit the right to online anonymity.\n\nThe Canadian government, including the Department of Justice and Industry Canada, have drafted this blueprint as part of a process aiming to give law enforcement agents more authority for electronic surveillance. A proposed law based on this discussion draft is expected to be introduced in parliament later this year or early next year. The justification given for such sweeping changes to Canadian law appears weak, according to Michael Geist, a professor at the University of Ottawa who specializes in ecommerce law.\n\nThe proposal includes compelling internet providers and telephone companies to reconfigure their networks to facilitate government eavesdropping and data retention orders. This move would give law enforcement agencies increased access to private communications. The United States has a similar requirement called the Communications Assistance for Law Enforcement Act, but it only applies to pre-internet telecommunications companies.\n\nThis proposal goes beyond what is specified in the cybercrime treaty and has drawn criticism from human rights activists and civil liberties groups. Sarah Andrews, an analyst at the Electronic Privacy Information Center (EPIC) who specializes in international law, opposes the cybercrime treaty, stating it grants too much power to police and does not adequately respect privacy rights.\n\nThe proposal also suggests the establishment of a national database containing personal information about all Canadian internet users. The draft states that service providers would be required to provide accurate and current information for this database.\n\nGus Hosein, a visiting fellow at the London School of Economics and an activist with Privacy International, calls this idea a 'dumb' one, questioning whether anonymous mobile phones or internet connections will still be allowed. The Office of George Radwanski, Canada's privacy commissioner, is reviewing the blueprint but has no comments on it as yet.\n\nComments on this proposal can be sent to the relevant authorities before Nov."
   }, {
       "body": "I must admit, I'm not clear on your use of 'letting you and him fight'. However, it is crucial to recall that England had control over Ireland for many years. By this, I believe you mean a method of dealing with troublesome populations by placing them next to each other so they cause distress to one another rather than the ruler. \n\nTo clarify, my interpretation and yours will agree that the Irish and Scots, often considered barbarians who are prone to uprisings, were dealt with in this manner. The Ottomans and Zionists, too, have been described as uppity sorts who are unhappy with their current territories. Your suggestion seems to be to place more of these groups next to each other in the hope of resolving issues for both parties.\n\nOn a different note, it's worth mentioning that Muslims and Hindus were originally intermingled but partitioned due to their own conflicts rather than English resettlement. Similarly, the French and English had already established themselves on the continent, with events in the colonies being primarily influenced by the balance of power rather than intentional resettlement.\n\nLastly, it appears that the Acadians were relocated but did not seem to cause trouble among their neighbors. Therefore, they were not placed next to others as a means of instigating conflict."
    }, {
   "body": "Here is my review of Netscape. They have managed to restore the email search speed to its original level, however, setting up user mail accounts occasionally has a peculiar issue where it lets me access sometimes and not others. A problem that previous versions had was manually updating all address books, but at least they allow you to import them as Netscape address books (though they don't always work as expected). The mail filters are still broken, with the same problem I've been trying to report since: you can't store a mail filter of the age in days greater than or equal to some number. This bug is the single biggest annoyance for me because it makes Netscape one of my most effective antispam tools. Unfortunately, Webex does not support Netscape and the plugin doesn't work, causing issues when I need to collaborate with someone remotely on something using Webex. I've given up trying to report bugs and changes to the source code I send always get lost. Greg Gregory Alan Bolcer, CTO at EndeavorsCom, Endeavors Technology Inc."
   }, {
       "body": "Could you provide a more reasonable explanation of the EU-US differences according to some American journalist, as cited in a German magazine? I'm having trouble understanding this perspective. Here's my interpretation: The American public may perceive the rest of the world as a threat that needs to be defended against using power, but this is not an accurate assessment. While the US intelligence community correctly identifies threats, it's not primarily from third-world countries. Many European and other developed nations are actively involved in covert operations against American interests. This has been going on for years and isn't even news anymore. Things have escalated recently, and the US Department of Defense is displeased about this development. For better or worse, the US is also adept at playing this game, often being proxies for big players in what are commonly referred to as 'backwater wars.'\n\nTo find a current list of the top intelligence threats to the US, you'll find that half the countries on that list are European. Many people are unaware of how aggressive these activities have become recently.\n\nOn the other hand, Europeans are used to the peace of their cozy postwar system where external security is not an issue. They can resolve all security threats by giving money to those who threaten them or integrating them into their wealthy sphere. However, this approach has never created meaningful peace in history, and some call it extortion under any other guise.\n\nMany of the current EU-US issues can be explained by these differing perceptions such as American unilateralism, growing rejection of American policy in Europe, and the increasing irrelevance of Europe in American eyes. It seems that the US is asking for major policy advice from Europe is like asking a quack for medical advice. I don't see what's wrong with unilateralism.\n\nThe author seems to imply that few Americans have traveled outside their country, but this is not accurate. Many people in the US have lived, worked, and traveled abroad at some point in their lives. Similarly, Europeans may travel less in the Western Hemisphere than Americans, but they are still not the center of the universe."
   }, {
      "body": "The passage provides an insightful analysis of Powell's perspective on the telecom industry, focusing particularly on the aftermath of the dot-com bubble. It seems that Powell acknowledges the challenges faced by companies like WorldCom and Sprint, but does not necessarily see it as the FCC's responsibility to bail them out or prevent their downfall. Instead, he emphasizes the importance of economic discipline and balanced policies. Additionally, he highlights the ongoing transformation in the communications industry, with phone companies expected to provide video service and cable companies data service, leading to more choice for consumers. However, he does not appear overly concerned about media concentration or the potential for a monolithic viewpoint in media, instead viewing diversity as a complex issue that requires nuanced understanding."
   }, {
     "body": "The FCC world is filled with speculation about Michael Powell's approach to regulating industries. Some believe he lacks decisiveness and uses grandiose discussions about the market as a delay tactic. Others suggest he favors the Arbocks and big cable companies, or is planning a political career, hence his reluctance to take action at the FCC that might jeopardize future prospects. Alternatively, it's said he prefers to wait for more consensus before acting, to avoid being caught in the crossfire between the Arbocks, cable companies, and television networks - a strategy known as the Powell Doctrine of Telecom. Another theory is that he genuinely believes in the natural, healthy, and irreversible nature of the telecommunications crash, and concentration would be beneficial. Reed Hundt, not pleased with how his Telecom Act has been implemented, told me that under a Gore administration, the FCC would behave quite differently. Consumers may have noticed this difference, but communications companies certainly have - the Arbocks are performing better against their internal rivals than they would have if Gore had won. If the Republicans win, policy will lean further in favor of the Arbocks; if they lose, their rivals (long-distance companies and telecommunications startups, now in power) may stage a comeback. Gregory Alan Bolcer, CTO at Endeavors Technology Inc, remarks that although America's present is not unrecognizably different from its past, the outcomes under the current administration are indeed significant."
   }, {
    "body": "Thank you for sharing Michael Moore's latest update about his movie 'Bowling for Columbine'. It sounds like an impactful piece of work that addresses important issues in society. Here's a summary of the message: \n\n1. 'Bowling for Columbine' is opening this weekend in New York and Los Angeles, and Michael Moore urges everyone living in these areas to go see it.\n2. The film's success in its initial release will determine whether it gets wider distribution, so it's crucial that as many people as possible support it during the first weekend.\n3. The movie is expected to be provocative and controversial, and Michael Moore anticipates receiving backlash for its content.\n4. For those outside of New York and Los Angeles, the film will be released in other cities soon.\n5. Lastly, Michael Moore appreciates his supporters and encourages them to visit his website for more information."
   }, {
      "body": "Robert Elz, \n\nI believe Chris Garrigues is incorrect about this issue. The message change in 'msgchange' does seem to be the source of the problem, but previously typing nonsense didn't cause tracebacks. Now, it does and the traceback comes from the sequence code. In the past, such actions would have just resulted in red messages complaining about my lousy typing, which should have continued. The red part is not significant. What specific keystroke caused this issue so I can reproduce it? If I cannot resolve it, I will pass it on to Brent. \n\nBest,\nChris Garrigues\nVircio Congress Suite\nAustin, TX"
   }, {
    "body": "Robert Elz, I assume you will report this issue to the NMH team soon. After reviewing the NMH sources, I will look into what has been broken and why. However, we aim for EXMH to function with all existing versions of NMH, don't we? The patch to make EXMH behave correctly regardless of this bug is trivial, so I suggest including it. Here is the patch: ... (The patch content is not included in this response as per your request.) I have no idea why sequences were being added after the message list before; however, it shouldn't matter for NMH or MH. Since I stopped doing that, the variable 'msgs' isn't necessary anymore. Instead of assigning 'pickmsgs' to 'msgs' and then using 'msgs', the code could directly use 'pickmsgs' where 'msgs' is currently used. This change is more of a frill though; I didn't make it yet, but will fix this in CVS later today. Thanks, Chris Garrigues"
   }, {
    "body": "Recently, I've noticed that EXMH seems to be getting significantly slower. To verify my suspicion, I examined several small messages within a large folder and found that the delay between clicking the next button has increased noticeably (to msecs). Given that no changes have been made to user settings, I believe this is becoming nearly unacceptable. Does anyone on the EXMH workers mailing list have any ideas as to where the performance might have disappeared?"
   }, {
      "body": "Anders Eriksson has noticed that EXMH seems to be slowing down significantly lately. To verify his concerns, he checked the speed and found a noticeable delay in the 'next button' response time (increased by msec). Since his user settings have not changed, he believes this might be unacceptable. He suspects the added overhead of managing more sequences is likely the cause, but as he will be on vacation from Friday, he won't be able to investigate further until his return. However, if anyone can look into the issue and potentially resolve it while he is away, he encourages you to do so. His feelings won't be hurt."
   }, {
     "body": "Subject: Analysis of Delay and CPU Spike in Exmh Folders\n\nDear Anders Eriksson,\n\nI have investigated the issue regarding the delay increase of the 'Next' button in the big folder 'msgs', specifically the delay in msec.\n\nUpon testing, I was able to navigate through messages quickly, much less than the specified time per switch. However, there seems to be a significant CPU spike for a few seconds which appears to be related to the 'wc mailfolders' section of the code.\n\nThis issue is particularly annoying because it causes the system to hang or delay for a few seconds, making tasks take longer than expected to complete.\n\nI am open to analyzing the relevant code to identify the source of the CPU spike, but I would appreciate it if no one is shaking their head and muttering about a 'brown paper bag bug'. If you wish to discuss this further or provide any insights, feel free to reach out.\n\nBest regards,\nValdis Kletnieks (Computer Systems Senior Engineer, Virginia Tech)"
    }, {
    "body": "I am open to reviewing the code and tracking where the CPU issue lies, provided that no one is exasperated by a 'brown paper bag' bug as I previously mentioned in my email to Anders. However, at this moment, I cannot work on it due to other priorities. If you decide to tackle it yourself, I would not be offended. Coincidentally, I have recently learned that some commitments my partner made before my vacation require my attention, making it even more difficult for me to focus on other tasks as I stated when I contacted Anders.

    Regarding the ExmhWorkers mailing list, I am responding from Chris Garrigues' email address at the Vircio Congress Suite in Austin, Texas."
   }, {
    "body": "Anders Eriksson, Aug 2021\nI've noticed that EXMH seems to be getting slower and slower recently. I decided to verify this suspicion and indeed, performance appears to have degraded significantly since the last release.\nIn testing with numerous small messages in a large folder (msgs), I observed an increase in delay for the 'next' button, up to msec at times. This is approaching unacceptable, as my user settings have not changed.\nIt seems most likely that the added overhead of managing more sequences is causing the performance issue, but it can potentially be optimized. However, I will be on vacation starting this Friday and will have limited availability until then. If you would like to investigate the issue further and make any necessary fixes while I'm away, please feel free.\nFor reference, I measured the time spent wrapping the stuff in ftocnext with a timer, so the data is accurate.\nOne difference between my setup and Valdis's trace is that I use the address book, which I've been doing for years without issue. However, it does not appear to be the culprit.\nIs there a way to configure the log to print time with higher granularity?\nRegards,\nChris\n(Exmh workers mailing list)"
   }, {
    "body": "I have observed a delay with the 'Next' button on several small messages within a large folder named 'msgs'. The delay has increased to latest msec and I am not experiencing any hit on the 'Next' button. A quick tap on 'Next' and checking wall clock indicated that it takes under seconds to go through messages, which is well below the per-switch limit. However, there seems to be a significant CPU spike for a few seconds in the 'flist' code, particularly related to 'wc mailfolders'. I have folders running with 'bgproc' set to 'flist minute', and while I notice delays (though they tend to disappear these days), they are not as severe as this CPU spike. This observation is made on the Braexmhworkers mailing list."
   }, {
      "body": "Anders Eriksson, Tuesday, August [DATE], Just one more info: I have measured the time spent wrapping the stuff in ftocnext and the data is for real. One difference between my and Valdis setup, judging from his trace, seems to be that I use the address book. I've been doing that for ages, so that can't be the problem, assuming it's my fault (which it probably is since nobody else has really been in there). It's most likely related to the number of sequences in a folder. I guess that something is either being called that should not be or is being called more times than it should be. Is there a way to get the log to print time with higher granularity? Not that I am aware of. If you look in the code, there are various places where the time function is called in order to see how long it took to do things; you'll probably want to borrow that technique. Chris Garrigues, Congress Suite, Austin, TX, World War - The Wrongdoers vs The Evildoers Application. Sincerely, [Your Name]"
   }, {
    "body": "Dear Chris Garrigues, \n I've completed the task and also removed the 'msgs' variable, as I believe simplicity is key. I spent a considerable amount of time clearing up the clutter in EXMH while working on the Sequences window. A big thank you for your willingness to jump into the deep end and get very messy. The sequence management code, being one of the oldest in EXMH, has undoubtedly been affected by numerous features added over the years. Once it stabilizes, it will provide a great reason for a new release. \n Best regards, Brent Welch, Software Architect at Panasas Inc. Working on pioneering the world's most scalable and agile storage network."
   }, {
       "body": "Chris Garrigues, I need to know which specific keystroke sequence caused the issue so that I can reproduce it and attempt to fix it. If I am unable to do so, I will pass it on to Brent. You don't need to worry too much about this as you have other pressing matters to attend to in the near future. This problem doesn't seem to critically affect the normal use of the code. To reproduce the issue, type any digit as if it were a message number, then backspace to remove it, and then enter some other junk characters. It seems that only this sequence of events causes the problem I am experiencing. Once in this state, the same traceback occurs for every character typed until a message is selected with the mouse. Given its reproducibility, I believe it should be relatively easy to find and fix. I will look into it later."
   }, {
     "body": "You can duplicate this issue by typing with normal key bindings any digit, then backspace so the digit goes away. The code seems to be confused when trying to add or remove a message from a sequence. If we assume or higher level which we can't really do, we could use if string is integer selectsel bail out of message select mode to the selecttypein procedure. If regexp selectsel works, it might also solve the issue. Robert Elz mentioned that he experienced this on Aug 1st and Chris Garrigues needs to know what keystroke made it happen so it can be reproduced. I will look into it later, but if I can't find a solution, I will hand it off to Brent. Don't worry too much about it as there are other important tasks that need your immediate attention and this issue isn't critical enough for people to not use the code in normal ways. This seems like an easy problem to fix."
   }, {
    "body": "I believe that a single select entry field is used for selecting messages and navigating between folders. Restricting the entries to be numeric could potentially disrupt the folder switching functionality, wouldn't it? In my version of msgchange, I have an initial check if msgid allows null msgid from msgshowwhat which supplies a line instead, if msgid returns as not a number, it exits the procedure at the start. It seems that msgchange should validate a msgid as a number before continuing. If the sequence parser, which understands commands like 'to' meaning messages through, is confused when asked to add or remove messages from a sequence, we could add an exit from message select mode to the selecttypein procedure. We can probably survive with an exit if regexp finds 'selectsel', instead of just 'selectsel'. Robert Elz mentioned that a specific keystroke might have triggered this issue. If you can reproduce it, please let me know so I can investigate further. I'll see what I can do about it or, if necessary, I'll hand it off to Brent. He is the software architect at Panasas Inc., pioneering the world's most scalable and agile storage network. This issue doesn't seem critical enough to halt normal usage of the code but to reproduce it, you can try typing a digit as if selecting a message number, then backspace so the digit goes away, followed by other junk characters. I haven't found any problem with non-numeric characters, just the sequence described above. Once you get into that state, the same traceback occurs for every character you type until a message is selected with the mouse. This issue seems relatively easy to find and fix, so I'll look into it later."
   }, {
    "body": "Dear Brent Welch,\n\nIf we are permitted to make assumptions about which we cannot really, then we could potentially enhance the selecttypein procedure. I had a look at modifying it, but the code is quite general with minimal understanding of what anything represents, so I didn't believe adding knowledge of the semantics of what it is fetching would be ideal. I ran out of time last night while searching for a more appropriate location for a similar check. Instead of directly using regexp, I would have gone there. However, I am not fully updated with all the latest TCL changes and I'm unsure if I will have time today. But I will continue my search and keep you posted.\n\nRegards,\n[Your Name]"
   }, {
     "body": "I have some patches that seem to resolve a problem which occurs when main power fails, leaving only the laptop and its battery supply operational. Initially, I put in defensive code into the area where the issue was occurring, so if EXMH is attempting for any reason to expand a sequence that isn't either a number or a range of numbers or a list of such things, it will simply ignore the trash rather than giving a traceback. This solves the initial problem. The amended procedure 'mhseqexpand', where the error was occurring before, now assumes that 'range' is either 'nnn' or 'nnnmmm'. We should probably ensure this is true and issue an error instead of just continuing if you prefer, but I don't think an error is necessary. However, this allowed me to create a similar problem in another place by typing 'nnn' and rather than continue fighting fires like this, I thought I should think more about Brent's suggestion. Instead of validating the input directly, which would mean it would have to know what is valid, I decided that the right thing to do was just to ignore any errors caused by invalid input. I achieved this by putting a 'catch' around the msgshow that is processing the nonsense that the user has typed. This way, any later expansion to what msgshow treats as legal can be handled without someone needing to remember to fix the selection processing code to allow it. While I was working there, I noticed something I never knew before - if you type 'changes' for each, that is bound to a different function so it can be used as a toggle between changing the current and the target folder, but it has to mean something if the current input mode is a message number. So let it mean something, but now I found it, I think it's nice. However, if we can type 'why not' as well, that kind of limitation bugs me, so I fixed it and then I wondered about folders with names containing the special use of 'as' the toggle character means there's no way to type those from the keyboard, so I fixed that as well. This removes two different restrictions - there's no way to type a folder name that has a name beginning with 'b', such a thing in mh would be a pain to use anyway, so I doubt this will bother anyone. It is now only possible to toggle between typing the current target folder name when the name being typed is empty. I am less happy about that part but I think I can live with it. In order to allow folder names with 's' in them to exist and be typed, I decided to do something about another feature that has always bugged me - in normal keyboard mode, 's' is the key used to show a message, but if you've just typed 'and' and the FTOC is highlighting as the current message, and you want to now show that message, you can't type 's', you have to type 'r' instead. I fixed this one as well. Here are the changes: (the patch follows) I believe if you apply these changes then the previous one may not be needed anymore."
   }, {
       "body": "I discovered something new while playing at Robert Elz's, which I was previously unaware of. Incidentally, I am aware of the distinction between 'new' and 'knew', but my typing skills aren't always up to par (I meant 'know'). Regards, Exmhworkers mailing list"
   }, {
       "body": "It appears that you were incorrect about how MH functioned here, a common occurrence. The 'seq switch' seems to have always operated as 'nolist', requiring a subsequent 'list' command to activate it again. In truth, I'm unsure how the pick code ever worked within the system and it might not have functioned as intended at all. While browsing sources, it seems they are attempting tasks that I never witnessed. It could be that your new sequence method brought to light a bug that had been there all along. Consequently, I will not be submitting any bug reports to the NMH team unless NMH shows further progress and if I recall this incident. If I remember, I might submit a change request for the code to modify the change which, from what I can tell, would be quite straightforward."
   }, {
     "body": "Dear Robert Elz, it seems that your new sequence method may have uncovered a bug that has been present all along. This is what the past few months of EXMH hacking have been about for me. I've now stabilized everything quite well for my paid job, so I'll likely investigate performance issues with sequences, but due to my departure in less than hours, I won't be able to email any changes I find. Instead, I'll keep notes for future reference. I'm currently at the Congress Suite in Austin, TX, and we're discussing the World War - The Wrongdoers vs The Evildoers application. Regards, Chris Garrigues"
   }, {
    "body": "Hello Chris Garrigues, I'll likely investigate the performance issues with the sequences today. There's a useful piece of code in mhseqexpand hack that filters out sequence numbers for messages that don't exist. Here's how it works: foreach m rseq, if file exists mhprofilepathfolderm exmhdebug, if mhprofilepathfolderm is not found, set ix, lsearch seq, and replace seq at ix with ix. If the file does exist, it performs a slow check if a sequence happens to start with a bunch of messages that don't exist. I'm not entirely sure why it's crucial for the first message in the sequence returned to exist, but not necessarily any others. However, I appreciate this feature as mhseqexpand is frequently called, and I'm unsure if I could manage if it were checking every file in the sequences all the time. It might be beneficial to maintain a list of valid message numbers for the current folder, though this would need to be verified against changes to the directory. Tcl has a directory read function, so maintaining such a list should be feasible. Mhsequence also goes and rereads the files mhsequences and the context file, but I'm not sure how frequently that one is called. I'll email you any findings before I leave town in less than hours. Have a great vacation! Regards, [Your Name]"
   }, {
      "body": "Robert Elz informs that there is an issue with the performance of the sequences in the MHSeqExpand hack. The code, which removes sequence numbers for messages that do not exist, may run slowly if a sequence includes a large number of such non-existent messages. Although it is unclear why the existence of the first message in the sequence is important, Robert is grateful that this is the case as MHSeqExpand is called frequently. He suggests keeping a list of valid message numbers for the current folder to speed up the process. However, this would require verification against changes to the directory. TCL has a directory read function, and it seems that MhSequence also re-reads the files in the sequences, but it's unclear how frequently this happens. Robert believes that ftocshowsequences may be called too often and plans to investigate. He will email any findings before leaving town in less than hours. He is currently at Vircio Congress Suite, Austin, TX. Regarding the application 'World War: The wrongdoers vs the evildoers', he has attached his PGP signature for verification."
   }, {
    "body": "Subject: Performance issue with EXMH\nDear Chris Garrigues,\nI've noticed that EXMH seems to be getting slower over time. To verify my observation, I checked the speed and unfortunately, it appears that performance has indeed decreased since the last release.\nI examined a number of small messages within a large folder 'msgs', and observed an increase in delay for the 'next' button (in msec). Frankly, this is getting close to unacceptable as my user settings have not changed.\nI believe there might be some performance issues. Here's a potential fix that I think could make a significant difference:\n- The function ftocshowsequences should be able to be called with an optional list of msgids to update, and if it is called this way, it only removes or adds tags for those specific messages.\n- In places like msgchange, we should only update the messages which have changed.\n- Additionally, a separate ftocshowsequence function that only updates the display of one sequence (taking an optional list of msgids) should be written. This would reduce the need to update the entire sequence in places like msgchange if nobody else gets to it first.\nI plan to implement this fix when I return. Looking forward to your thoughts.\nBest,\nAnders Eriksson"
   }, {
    "body": "Dear Chris Garrigues, \n\nI will likely investigate the performance issues with the sequences. There is a useful piece of code in mhseqexpand called 'hack to weed out sequence numbers for messages that don't exist'. For each message represented by `m` and `rseq`, if the file `mhprofilepathfolderm exmhdebug` exists, it will run smoothly. However, if not found, a search is performed using `lsearch seq m`. If the searched sequence number does not exist in the current folder, the hack is applied (please note that this operation might run slowly if a sequence happens to start with a bunch of messages that don't exist).\n\nI am not entirely sure why it is crucial for the first message in the sequence returned to exist while it isn't necessary for others. However, I believe it benefits mhseqexpand as it gets called frequently and I am unsure if I could handle it checking every file in the sequences constantly. My recollection about the first message being valid is that the ftoc code wants to find that message to start its highlighting or when you select a message to display.\n\nIt may be helpful to maintain a list of the valid message numbers for the current folder, but this would need to be verified against changes to the directory. Tcl does have a directory read function (glob nocomplain), and `mhprofilepathfolder` will return an unsorted list of the directory's contents. However, keeping an in-memory list of valid messages is not appealing. Exmh already maintains in-core lists of messages in sequences, which can be challenging enough.\n\nExmh also goes and re-reads the files `mhsequences` and the context file but I'm not sure how often that one is called (it varies depending on places). In some places where I maintain caches of files by checking their modify time, it seems unnecessary to stat them to check their date stamp since they can be read again so quickly.\n\nLastly, now that we checkpoint message state on every message view, the file will change every time. In the old days, Exmh used to cache a bunch of state about the folder but I am not certain how often Brent Welch (Software Architect at Panasas Inc., pioneering the world's most scalable and agile storage network) updates it on the exmhworkers mailing list."
   }, {
      "body": "Brent Welch wrote on Wednesday, August [redacted], regarding the MHSEQUENCES files. He mentioned that he rereads these files and the context file, but is unsure of how frequently they are called in certain places. He maintains caches of files by checking their modify time, however, due to the small size of sequence files, it might be quicker to simply re-read them instead of checking their date stamp. Brent added a modify time check, believing it would make an improvement as the sequences are being read more frequently in the new code. However, he suggests that even with a small file, the time taken to do a file mtime filename check could be worthwhile. The discussion took place on the exmhworkers mailing list under the subject 'The wrongdoers vs the evildoers' application - pgpsignature - gnupg - gnulinux - exmh version wxvl - end pgp signature.' "
   }, {
       "body": "I have used the 'checkthemodifytime cache trick' for files in various places, not just exmh. Part of me believes it is effective; however, I have been contemplating that if we perform checkpoint state, aren't we modifying the sequences file for the current folder every time a message is read? Perhaps we look at the sequences file more than once per message view, just idle speculation. We could insert time calls to determine the cost. Someone raised the question about increasing the time resolution in the exmh log, and it could be made conditional on available TCL support. For instance, TCL has had high-resolution timers like gettimeofday and clock clicks, but we have calibrated clock clicks values to microseconds, which is still only useful for relative times. However, each call to exmhlog could emit the microsecond delta since the last log record, considering all the overhead of taking the log record. I will try it out. Additionally, 'mhsequence' also goes and rereads the files (mhsequences and context file), but I am unsure how frequently that one is called. In some places, I maintain caches of files by checking their modify time; however, since the sequence files are so small, by the time you stat them to check their date stamp, you could just read them again. Do you think this is true? I added a modify time check in hopes of making an improvement, as we were reading it more times in the new code because we were trying to use the sequences more often. However, even with a small file, I believe the time taken to do a file mtime filename would be worth it. My code is in proc mhreadseqs."
   }, {
       "body": "I have used the 'check-the-modify-time cache trick' for files in many places, not just exmh. Although I believe it is effective, I recently considered that when we checkpoint state, aren't we modifying the sequences file for the current folder on every message read? We may be looking at the sequences file more than once per message view. This was something I had written the code for a few months ago when we were reading the sequences file first to see what sequences were in it and then, once per sequence. This happens particularly in 'ftocshowsequences'. It seems like an obvious loss of performance, but I wanted my abstraction to have a separate call for what sequences are in this folder and what messages are in this sequence. One option would have been to add another call to get the data off of disk, but I felt that the 'check-the-modify-time' technique would be less error-prone. The biggest gains would be from augmenting 'ftocshowsequences' to allow a finer specification of what needs to be updated in the ftoc so that the current code would only be run when we really do have to update all sequences for all messages. I discussed these thoughts in an email message yesterday, and if it can wait a few weeks, I am willing to do it."
   }, {
    "body": "Chris Garrigues and Brent Welch, on Wednesday, August well, I've utilized the 'checkthemodifytime' cache trick for files in various places beyond just exmh. While a part of me believes it to be effective, I pondered that if we perform checkpoint state, aren't we modifying the sequences file for the current folder on every message read? This led me to consider that we might be looking at the sequences file more than once per message view. Since I wrote the code a few months ago, we were reading the sequences file first to see what sequences were in it and then, on a per-sequence basis, this process seems to be an obvious loss of performance. However, I wanted my abstraction to have a separate call for what sequences are in this folder and what messages are in this sequence. One option would have been to add another call to get the data off of disk, but I felt that the 'checkthemodifytime' technique would be less error-prone. I like the 'checkthemodifytime' technique and believe the biggest gains would be from augmenting ftocshowsequences to allow a finer specification of what needs to be updated in the ftoc, so that the current code would only be run when we really do have to update all sequences for all messages. I expressed these thoughts in an email message yesterday. If it can wait a few weeks, I'm willing to do it. I haven't yet delved into the latest round of changes, but I plan to. I can't guarantee any progress, but I may dabble. Thanks again for all your work in this area. Generalized sequence support has been on my to-do list for about years - Brent Welch, Software Architect, Panasas Inc."
   }, {
    "body": "Hi Clemens, \n\nI'm having trouble checking the GnuPG signatures on your messages. Every time I try to check a line, it shows that the signature was made on Thu Aug MDT using a DSA key ID, but I can't seem to find the public key as it's not found. It seems there might be something else missing. I am certain that I have the public key of the message signature, but if I don't, please try downloading it or check a signature from which you know you have the public key.\n\nPreviously, GnuPG would pause to get the public key from a keyserver, but now I get a failure message even though I have supposedly fixed the path. It appears as if it can't execute gpg, but there must be something else that I am missing.\n\nRegards,\nEx-Mailing List Admin"
   }, {
    "body": "Dear Frommholz,\n\nIt appears that you are having trouble checking the GnuPG signature on your messages due to a missing public key. To resolve this issue, I recommend ensuring that you have downloaded or obtained the correct public key for the message signature.\n\nIf you need help with obtaining the public key, please let me know and I'd be happy to guide you through the process. Additionally, if you have access to a signature where you are certain of having the corresponding public key, that could serve as a useful reference.\n\nRegarding your request for my PGP public keys, they can be found on my homepage.\n\nBest regards,\nIngo Frommholz"
   }, {
    "body": "If you haven't done so already, please enable the debug log under hacking support preferences and look for clues there. Specifically, search for 'Clemens' in messages with GnuPG signatures. However, when attempting to verify the signature, I always get a message saying 'Signature made Thu Aug MDT using DSA key ID BDD'. Since I can't find the public key, it seems that something else is missing. Are you sure that you have the public key of the signature you want to check? If not, please try downloading it or verify a signature from where you are certain you have the public key. I apologize for any confusion, but I should have made that clearer earlier. Previously, GnuPG might have paused briefly to retrieve the public key from a keyserver; now, whether I have the key or not, I get a failure message, which suggests that it can't find gpg to execute it. However, I have checked and fixed the path, so there must be something else that I am missing. Regarding the ExmHusers mailing list, Brent Welch (Software Architect at Panasas Inc), pioneering the world's most scalable and agile storage network."
   }, {
       "body": "The email discusses issues encountered with the Tcl parser in EXMH, a mail user agent. The change, which includes bytecode compilation and stricter initialization parsing, seems to cause confusion when comments are placed where patterns or switches are expected. This confusion arises due to extra whitespace and newlines. The user has found an example where this change affects the correct parsing of EXMH in emxh, but is unaware of the PGP support in emxh. They suggest digging into the issue themselves or checking if others on the EXMH mailing list or users are experiencing similar problems. The user also mentions enabling the debug log under hacking support preferences for potential clues. Another issue reported is that, when trying to check a GnuPG signature, a failure message appears even though they have the key. They're unsure about the public key of the signature they want to check and suggest downloading it or checking a signature from which they know they have the public key. Lastly, there seems to be a new query box asking whether to query the keyserver after a failure to find the public key on the keyring. This was not present before, but now appears even when running either GnuPG or emxh. The user expresses confusion about this change and how it could be causing the problem as they never had to touch the query keyserver button in the past. They also mention a previous issue with Tcltk in EXMH that might be related."
    }, {
     "body": "It sounds like you're having trouble reconfiguring Procmail and Exmh after moving your incoming mail or spool location. Here are a few steps you might want to consider:

1. Update the 'bgspool' variable in your Exmhdefaults file if it wasn't edited earlier. This variable indicates the location of the spool for Exmh. However, remember that the warning not to edit these lines in the file may not apply to this specific case.

2. Configure Procmail to read mail from the new location. You can do this by modifying your .procmailrc file. This file is typically located in your home directory and it tells Procmail what to do with incoming mail. Here's a basic example of how you might set it up:

   ```
   MAILDIR=$HOME/mail
   DEFAULT=$MAILDIR/inbox
   ```

3. In the .procmailrc file, you should have rules that pipe the mail to Exmh's rcvstore command. For example:

   ```
   :0:
   | /usr/bin/exmh -r
   ```

4. After making these changes, save the .procmailrc file and test it by sending a new email or running Procmail manually with the 'procmail -m' command. If everything is set up correctly, your mail should start appearing in the correct folders under the new location.
   Good luck with your setup! If you encounter any more issues, don't hesitate to ask for further help."
   }, {
    "body": "The email appears to describe a problem with moving an incoming mail or spool location and needing to reconfigure Procmail, Vstore, and Exmh to accept mail from the new location. The question is about how to feed Procmail without using a forward ID and where the mail enters the system (possibly via Fetchmail, direct SMTP delivery, or simply hitting the spool). The sender also mentions that they use GnuPG for signing emails."
   }, {
    "body": "Is there a method to execute a global sort command? I prefer to organize my emails by date, with the latest messages appearing first in each folder as it helps me identify the importance of older messages more easily. However, this process seems to arrange messages incorrectly within other folders when finished. Ideally, after modifying any folders, they would be rearranged automatically from most recent to oldest. This pertains to the Rickexmhusers mailing list."
   }, {
      "body": "On Monday, September PDT, Rick Baartman, regarding your request to perform a global sort command, I'd be happy to help. You specifically would like to sort by date within every folder, from most recent to oldest, as this direction seems more efficient for you. However, when you sort one folder, the order of messages gets mixed up in other folders upon completion. This is unexpected behavior since sorting one folder should not affect others. To clarify, how does modifying the order of messages within a single folder cause a change to other folders' contents? For the 'tom ex-husband' mailing list, I believe we use a similar command for sorting by date."
   }, {
    "body": "I am unable to comprehend how moving messages from one folder results in them being added to other folders. I apologize for any confusion, as I was transferring messages from my inbox to different folders, and since I am doing it from the most recent to oldest, they appear in those folders in reverse order and need re-sorting. This is regarding the RickExMhuUsers mailing list."
   }, {
      "body": "I apologize for any confusion earlier. I'm moving messages from my inbox to other folders, but due to organizing them from most recent to oldest, they appear in the incorrect order and require reordering. However, EXMH doesn't seem to support that directly; you can do it on the command line using a shell script like 'for f in folders do echo sorting f sortm f done', but it might take a while. At work, I'm required to use Outlook, which I dislike, but it does offer some advantages, such as creating indices for each folder based on sender, message size, subject, allowing for instant sorting by any column. This functionality might also be possible with an IMAP-compliant reader if the IMAP server maintains such indices. However, I've come to terms with the fact that EXMH may not meet certain industry standards. It serves my personal mail needs; my mail server runs Unix, and I connect over SSH while tunneling my X traffic over SSH with a slow link, which makes EXMH quite slow and its mime handling less efficient compared to modern mailers. I've been using MH or NMH since, and EXMH for many years now."
   }, {
    "body": "Hello, \n\nIn response to your query about sorting folders globally within EXMH (Elm Mailer for X), I'd like to inform you that EXMH does not have a built-in widget for global sorting. However, you can accomplish this using command-line tools.\n\nHere's a step-by-step guide:\n1. Open a shell.\n2. Navigate to your home directory with the 'cd' command (e.g., 'cd ~').\n3. Use the recursive find command 'c for f in folders recurse fast' to list all of your folders.\n4. Run the 'sortm' command on each folder, which will sort the contents of that specific folder.\n\nThe 'find' command with 'recurse fast' option prints out a list of all your folders, and the 'sortm' command sorts a particular folder. I hope this helps!\n\nRegards,\nJacob Morzinski (EXMH Users Mailing List)"
   }, {
    "body": "I have come to terms with the reality that exmh is lagging behind some industry standards, as it is currently only used for my personal emails. My mail server runs on Unix, and I connect via SSH while tunneling my X traffic over SSH with a slow link, which significantly slows down exmh and its MIME handling capabilities are quite inferior compared to modern mail clients. \n\nI would like to share an opinion here if it is permitted:\n\nI began using Linux around 15-20 years ago as a rebellion against what the university was doing with Windows, struggling to get good support and relying heavily on Unix-based tools even in Windows. Switching to Linux gave me the convenience of using a shell and SSH to connect to my office box from just about anywhere while using either exmh or nmh from the command line, making it relatively easy for me to manage office emails. \n\nI haven't found any other tools that offer the same functionality yet, but I must admit that some of the web-based mail software is getting quite close. Although their quoting and such functions are still primitive, they seem to be progressing."
   }, {
   "body": "Subject: Global Sort Command for EXMH\nHi Rick Baartman,\nI hope this message finds you well. I understand that you're looking to perform a global sort command in EXMH, but it might not be common and I would be surprised if there's a built-in widget for it.\nHowever, you can achieve what you want using the command line mh tools. Here's a suggestion:\n\nFrom a shell (sh):\nfor f in `exmh -l | grep folders` do sortm $f done\nThis command will sort each folder individually and 'exmh -l | grep folders' prints out a list of all your folders.\nThe command 'sortm' sorts a particular folder.\nI hope this helps. If you know any Tcl or are familiar with EXMH users mailing list, you might find a way to attach this command to the sorting menu.\nBest regards,\nTom and Jacob"
   }, {
    "body": "Dear Tom and Jacob,\n\nThank you for your efforts on the above task. However, I encountered an issue when attempting to make changes outside of the xmhcache files as they don't get updated automatically. This could be potentially dangerous since I have to manually rescan each folder I enter. Is there a safeguard available for this issue in the Rickexmhu users mailing list?"
   }, {
    "body": "For the given command, here's a rephrased explanation: \n\n The command 'sh c for f in folders recurse fast do sortm f done' is used to iterate through all files within folders recursively and sort them. This works fine, but I wanted to clarify that the double quotes around the backticks (`sh`) are specific to my shell version. If your shell doesn't require these double quotes, you can safely omit them. The main reason I included them is because I have some folders with pathologically named files, including those whose names contain spaces. If all your folder names are safe and don't require special quoting, you won't need it. This is just a precautionary measure. \n\n Hope this helps clarify the command usage! \n\n Best, Tom and Jacob"
   }, {
      "body": "On Monday, September (Date), Rick Baartman wrote about a risky issue concerning the 'rick' folder. He mentioned that each time he enters this folder, he needs to remember to rescan it. Is there any safeguard for this issue? Unfortunately, there isn't one currently available. However, I suggest regenerating the cache in the script as a potential workaround. For all folders starting with 'fast', 'rdo', 'echo sorting', 'sortm', and 'fscan', execute the following steps: mhpath (folder path), xmhcache (folder name), and then 'done'. This applies to user mailing lists."
   }, {
    "body": "I suspect that as part of Chris's changes, he cleaned up the use of a variable named 'l' in ftoccommit within ftoctcl. However, there is one remaining reference to 'l' that causes tracebacks if you attempt to use 'link' with the current CVS version of exmhi. I noticed this issue last week but only had time to look into it today. If someone with commit access to the CVS repository could apply the following patch to libftoctcl, it would be much appreciated. The patch works and is trivial. It only involves changing one instance of 'l' in the file to 'textplain name'. Here is the patch attachment with filename and date information. [File Attachment: ftoctcl_prev_wed_aug_ftoctcl_tue_sep, created on Sep 1st] The relevant code change is as follows: [Code Snippet] incr ftocnummsgs else ftocunmarkinner lftocunmarkinner lineno incr ftocchanged if delmsgs exmhusers mailing list"
   }, {
    "body": "Dear all,\n\nI suspect that as part of Chris' set of changes, he cleaned up the use of the variable named 'l' in ftoccommit in ftoctcl. Its name was changed from 'l' to 'lineno'. However, there seems to be one remaining reference of 'l' which causes tracebacks if you attempt to use 'link' with the current CVS version of exmh.\n\nI noticed this issue last week but only had time to look into it today. If someone with commit access to the CVS repository could apply the following patch to libftoctcl, that would be nice. It works and is trivial.\n\nThe change should only occur once in the file: replace 'l' with 'lineno'. Here's an example of where it needs to be changed:\n\n    from: ftocunmarkinner l\n    to: ftocunmarkinner lineno\n\nApplying this change directly, instead of saving a patch and applying it, might be faster.\n\nRegards,\nRobert Elz"
   }, {
    "body": "This is a multi-part message in MIME format. The text is encoded in US-ASCII. On Mon Sep CDT, you'll need to scan mhpath fxmhcache (if something else hasn't changed the context in the background). It doesn't hurt to explicitly state the scan of mhpath fxmhcache. Cheers\n\nRegarding the IBM keyboards I have, when using them to 'beat' lusers, the caps come off the keys. This causes no real damage but is still a nuisance."
   }, {
    "body": "On Monday, September 7th, at work I find myself using Outlook and it's a real pain. At our workplace, people who use Outlook are literally escorted out of the building, their badge confiscated, and told to return the next day to collect their office contents. However, there are a few things that Outlook does right: it creates indices for each folder, not just by date but also by sender, message size, and subject. This allows me to sort by any column instantly. I have been investigating the use of a custom sequences file, but I find the MIME handling to be inferior compared to modern mailers. The only thing I miss in this regard is support for S/MIME."
   }, {
      "body": "Dear Tom Reingold, \n\nI apologize for my previous email about Outlook. I understand that it has some useful features like creating indices for each folder based on sender, message size, subject, and allowing instant sorting by any column. However, our organization strictly enforces its use due to security concerns. Employees who disregard this rule are terminated, their badges confiscated, and they are escorted out of the building. \n\nRegarding your inquiry about custom sequences files, I am already familiar with them but could not find a way to create indices with them or keep them up to date. As for MIME handling, it seems to be less effective compared to modern mailers, and the only feature I miss in this regard is support for S/MIME. It appears you are running Exmh on a local machine, but in my current scenario, the mime handling is weak due to the remote nature of the machine.\n\nI am part of the exmhusers mailing list, and I believe there might be discussions about improving MIME handling in Exmh. It would be great if we could collaborate on this issue. \n\nBest,\nJC Lawrence"
   }, {
       "body": "Dear Tom, \n\nIt appears that Outlook, the email client we use at our organization, has been likened to soliciting blood transfusions from random strangers on the street. In essence, this comparison signifies that it is a 'virus magnet'. This description stems from its susceptibility to viruses and malware. Essentially, users who are careless with their Outlook usage may inadvertently compromise our organization's security.\n\nBest,\n[Your Name]"
   }, {
       "body": "Dear Tom Reingold,\n\nWe terminate employees who utilize Outlook because it poses a significant threat to our organization. Outlook can place our corporate network and data at risk due to an alarmingly high number of exploits, with more being regularly discovered. An exploited system compromises other corporate systems, customer systems, our company's reputation, and liability with customers, as well as putting proprietary corporate data at risk. Moreover, users cannot be trusted to use Outlook safely. Therefore, using Outlook is considered anywhere between criminal negligence and deliberate malice by the employer.\n\nRegarding your question about custom sequences, I do use them, but creating indices with them and keeping them up-to-date requires the use of a cron job. As for maintaining support for S/MIME, you may be running EXMH on a local machine. In this scenario, the MIME handling is weak. However, when running EXMH on my desktop machines at home and work, I display the resulting EXMH windows on both desktops using SSH forwarding.\n\nBest,\nJ C Lawrence"
    }, {
     "body": "Hello Hal Devore,\n\nI am reorganizing your previous email for better understanding:\n\nSubject: Safeguard and Script Modifications\n\nThis email is regarding the issue you've mentioned about having to remember to rescan each 'Rick' folder you enter. Currently, there seems to be no safeguard for this.\n\nRegarding your script for regenerating the cache in the script for 'f' in folders fast, here's how it works:\n\nfor f in folders fast\ndo\necho sorting f\nsortm f\nscan mhpath fxmhcache\ndone\n\nThis little script you run nightly from cron does a general tidying of things, including sorting and updating the cache. Although I didn't write it, it's been working well for years. I run a similar one to update the 'Glimpse' indices nightly.\n\nSincerely,\nKevin Oberman (Network Engineer, Energy Sciences Network, Ernest Lawrence Berkeley National Laboratory)\n\nAttachment: filenameswasort (bintcsh script) sorts all folders. We don't want to sort the 'drafts' folder and the 'mailglimpse' default field to sort : date (default scan width : set mhdirusrlocalnmhbin, mailhome: obermanmail, update mailfolders: mhdirfolders fast, recurse all mailfolders thru all folders. foreach i cat mailfolders grep v glim grep v drafts sort the stuff mhdirmhsortm i datefield date devnull and update the cache mhdirscan i width mailixmhcache end exmhusers mailing list"
   }, {
       "body": "Dear James Gibbon, Tom Reingold,\n\nOn Tuesday, September, we discussed the potential threat that Outlook poses to our organization. It has been described as being similar to soliciting blood transfusions from strangers in the street due to its tendency to attract viruses.\n\nYou are correct in your assessment of this matter. The EXMHUSERS mailing list."
    }, {
       "body": "It appears that you are running EXMH on a local machine, while I run it on a very remote one. In your case, the MIME handling seems weak. However, I run EXMH on my home and work desktops, with the resulting windows being displayed on both. This is made possible by SSH forwarding. I frequently use EXMH from home broadband using an Xwindows client tunneled through SSH under Windows XP, which works quite well in this manner. For your information, I also use Eudora under Windows because it's less susceptible to viruses. There are additional reasons why I run Windows, but that's rather off-topic and I should refrain from discussing them. This was sent to the EXMH users mailing list."
   }, {
      "body": "There has been an update to the 'Scan Caches' menu entry, which rescan your folders similar to the shared scripts. It runs in the background. However, there seems to be a problem with this update: modifications made outside of the xmhcache files do not get updated. This can be dangerous as I have to remember to manually rescan each folder I enter. Is there a solution or safeguard to prevent this issue? Regards, Rick Baartman. Note: This was posted on the exmhusers mailing list."
   }, {
      "body": "This email is sent from multiple locations - home and work, using an Exmh client with windows displayed on both desktops. At present, I manually rescan the folder whenever I switch between machines. However, what I would prefer is some automation to perform this task for me. This message was initially read and replied to while at work using an Exmh instance running on my home machine. Best regards."
   }, {
    "body": "Thank you for clarifying the situation. I have applied global sort and JC Lawrence's rescan, but there still exists a vulnerability. If an instance of exmh is running while I am visiting a folder, the new correct xmhcache will be overwritten with an incorrect one when switching folders. However, I can schedule the sort and rescan process using cron and ensure to kill any running exmhs first. Ideally, a 'Global Sort' and 'Update All Scan Caches' button in the more menu of exmh would be beneficial. Rick Brent (Brent Welch) mentioned on Tuesday that there is an 'Update All Scan Caches' menu entry which rescans folders similar to the short scripts shared around, and this function runs in the background for exmhusers mailing list."
    }, {
    "body": "On Wednesday, September [Redacted], I wanted to share my experience with using exmh on both my home and work desktops. I have two instances of exmh running simultaneously, one at each location. SSH forwarding allows me to read and respond to messages from either machine while working remotely. A convenient feature is that the second instance changes the background color of the message pane from black to darkslategray, providing a visual cue between the two screens. I'd love some automation to automatically rescan the folder using flist, which I currently do manually when switching machines. Incidentally, I found your mention of 'Satan oscillate my metallic sonatas' quite intriguing in the exmhusers mailing list."
   }, {
       "body": "I use exmh on both my home and work desktops, with SSH forwarding to display the windows on both. Interestingly, I responded to your message using an exmh instance running on my home machine while I was at work. As another solution, I have two instances of exmh - one at work and one at home. These are displayed on a virtual X server created by vncserver on the homebox. I connect to this virtual X server using vncviewer from wherever I am. The VNC connection is tunneled over SSH and carried over the internet via an IPsec appliance. This setup allows me to access both my home and work email from either location without the complexities of having two instances of exmh working on the same set of folders. Viewing work email when I'm at work is a bit slow, but it's not so bad that I cannot manage."
    }, {
     "body": "I'm forwarding this email to the exmhworkers list as I'm not very familiar with the different PGP interfaces. It seems there has been some discussion about issues with the latest version of gpg-hacksaw on Linux Habitrailhomefoolserrantcom SMP THU Sep EDT (unknown TK TCL). It's not clear if this is a bug with exmh itself, but it appears to be something that manifests through exmh. When I receive a GPG encrypted message, it asks for a passphrase. Initially, it tries to ask me via the tty under which exmh is running and tells me my passphrase is incorrect every time. At this point, exmh offers me the line in the message about decrypting. I click the line and it offers me the dialog box and tells me the passphrase is correct and shows me the decrypted message. Any thoughts or ideas on this issue? Brent Welch - Software Architect at Panasas Inc, pioneering the world's most scalable and agile storage network."
   }, {
      "body": "To troubleshoot this issue, it is suggested to enable the debug log for hacking support in the log preferences. This will help in tracking the GPG commands being issued and the responses. You can do this using Exmh and GPG. I don't have issues with sending encrypted messages to myself, however, I noticed that when I select a message, an xterm window pops up asking for the passphrase. I don't remember if Exmh has ever asked me for the passphrase from the TTY that started Exmh or from any dialog box. However, as I'm not a heavy GPG user, I might have missed something. Since there have been discussions about issues with the latest version of GPG (Hacksaw), I thought it best to seek help here. When I receive a GPG encrypted message and it asks for a passphrase, it first tries to ask me via the TTY under which Exmh is running. It tells me that my passphrase is incorrect every time. At this point, Exmh offers me the line in the message about decrypting. I click the line and it offers me the dialog box and tells me the passphrase is correct and shows me the decrypted message. Any suggestions on this matter would be greatly appreciated."
   }, {
    "body": "I'm experiencing an issue with GPG encrypted messages using Exmh. When I receive a message that requires a passphrase, it initially fails to set keyboard focus when the dialog box appears. This prevents me from entering the passphrase. Pressing Return doesn't work either, and I need to click the 'OK' box before it asks again with proper focus. It seems like some variable or code path is getting corrupted for the focus, possibly due to an issue with tty or statusfd flags to the application. This problem also occurs occasionally when sending signed messages, where the dialog box appears but fails to get keyboard focus."
   }, {
      "body": "I'm curious about the GPG config and message headers within exmhexmhdefaults, as well as the content of the offending message that seems to be causing issues with nmhexmh. My setup is functioning fine, as I receive a popup window to enter my passphrase and the message displays correctly after I input it correctly. However, when the passphrase is incorrect, the tty under which exmh is running reports an error. After this, exmh offers a line for decryption, I click it, and a dialog box appears stating that the passphrase is correct and shows me the decrypted message. It's unclear to me whether this is a bug with exmh specifically or if it's something that manifests through exmh. I think there might have been discussions about problems with the latest version of gpg-hacksaw on Linux Habitat Rail Home Fool Serrant Com. SMP, THU SEP EDT UNKNOWN TK TCL. It's not clear if this is an issue with exmh per se, but it seems to be something that appears when using exmh. Any insights on this matter would be greatly appreciated. I am cc'ing the exmhworkers list because I don't know much about various PGP interfaces."
   }, {
    "body": "Here is a message that works with exmh version using gpg test textxpgp format, mime xactionencrypt. It appears your content type of textplain might be causing issues in your configuration. Your setup looks remarkably similar to mine. Cheers for Hacksaw on September! Regarding the issues you are facing, your email's textplain charset is us-ascii, discussion is XXXXXXXX, Tue Sep EDT, persistent mode is none, and the keys are stored at hkp: keyserver.pgpcom. Your exec command for gnupg is echo can't find id tmp, exmh version is usr/lib/gnupg, encryption algorithms used are skipjack, idea, rsa, zip, and you are subscribed to the exmhworkers mailing list."
   }, {
       "body": "Dear User, \n\nIt appears that you are experiencing an issue with TVTWM where the text you copy into your mouse buffer and attempt to paste into the Exmh input window does not appear at the expected location. Instead, it often inserts at a seemingly random position within the text pane. The text insertion point is usually not where you believe the current flashing cursor is. Additionally, you mentioned that any ':' characters are typically removed from the pasted text and it often isn't even at the beginning of a line, suggesting an unexpected number of character spaces have been inserted.\n\nI am unsure at this moment what could be causing this issue in either TVTWM or Exmh. If you have any suggestions or if additional information is required to troubleshoot this problem, please let me know. I appreciate your patience and cooperation.\n\nBest regards,\nExmhusers Mailing List"
   }, {
     "body": "I've noticed some issues with the cut-paste behavior in exmh, which I believe is primarily my fault. The middle click sets the insert point, and this often results in the cursor being placed at an apparently random position within the text pane instead of where I expect it to be (denoted by the current flashing cursor). This problem occurs even when snarfing text into the mouse cut buffer and trying to inject it into exmh input windows. It's worth mentioning that I usually wipe out any leading colons ':' with the text, and sometimes this isn't even at the beginning of a line - it can be an unexplained number of character spaces into the text where it inserts. I'm curious as to what I might be doing wrong in either X WM Shell or exmh that is causing this. As a TVtwm user, I thought I should bring this up on the exmhusers mailing list. Brent Welch, Software Architect at Panasas Inc., works on pioneering the world's most scalable and agile storage network."
   }, {
      "body": "The EXMH (Brent Welch's) cut-paste model in Wed Sep has an issue where it appears to be mostly your fault. The middle click sets the insert point, but if you find this inconvenient, you can adjust the bindings by going to Simple Edit Preferences and deselecting 'Paste sets Insert'. However, this solution comes with a downside - it no longer allows cut-paste within one SEDIT window, necessitating an intermediate client always. The exception is when you want to select some text and paste it at the same place, although due to the click needed for setting the insert point, the selection gets reverted to the last selection made in another window or something similar. Given that the majority of users would likely prefer 'Paste sets Insert' enabled, learning to live with this issue is less painful compared to dealing with the other."
   }, {
    "body": "Dear User,\n\nI understand your concerns regarding the cut/paste model in EXMH (Robert Elz's WMH) that you find problematic. The middle click sets the insert point, and if you dislike this behavior, you can adjust it by going to the Bindings > Simple Edit Preferences window and deselecting 'Paste sets Insert'. However, it seems this solution comes with a side effect: you will no longer be able to cut/paste within one sedit window, requiring an intermediate client to be used.\n\nIt appears most users prefer to keep the 'Paste sets Insert' enabled, as the alternative might cause discomfort for a significant period. However, if you are using an external editor with EXMH (like Gvim), you can cut/paste from the message display window into spawned Gvim processes but not into anything else. This can be quite inconvenient, especially when dealing with messages in qp encoded or non-textplain mime types, resulting in raw garbage.\n\nI am sorry for this annoyance, and I hope a solution will be found soon. In the meantime, if you wish to view messages in a terminal window instead (using cat or less), you may avoid encountering this issue.\n\nBest regards,\nEXMH Users Mailing List"
   }, {
    "body": "Dear User, \n \n I understand your concern regarding the inconvenience you're experiencing when using the 'Link' feature in combination with moving messages to another folder. It appears that since both functions share the same destination folder, you have to perform additional steps to use the 'Link'. \n \n To make this process more streamlined for you, I recommend changing your settings so that you can mark a specific destination folder for a message link or move without actually performing a move or link. Unfortunately, I couldn't find any obvious solution in our current setup, but I'm looking into potential workarounds. \n \n In the meantime, I suggest using a temporary method: 1) mark the desired destination folder, 2) perform a move (without actually moving the message), and 3) immediately undo the move. This will allow you to use the 'Link' function with minimal additional steps. \n \n I apologize for any inconvenience this may have caused and appreciate your patience while we explore options to improve the user experience. Cheers, \n ExMHusers Mailing List"
   }, {
    "body": "Is there a way to set a destination folder for a message link or move without actually moving or linking it in EXMH? I couldn't see anything obvious right-click on the folder label in the folder list in the main window. The key puts you into a change folder mode, hit a second time and you go into set a target mode, type a few characters of the folder name and hit space for autocomplete. How is EXMH users mailing list doing?"
   }, {
      "body": "The email suggests that there is an issue with right-clicking on a folder label in the current configuration, which seems to behave similarly to Tony's setup, performing a move instead of selecting as target. This occurs when no messages are currently selected. The user proposes a solution where one click would suffice and suggests that shift+right click could be an effective mouse binding for this purpose. However, implementing mouse bindings is more challenging than key bindings. The email also mentions that it would be beneficial to have a way to link folders in one click, but currently, adding mouse bindings is difficult compared to adding key bindings. The user further explains that, if the desired destination folder is not the current selected target, they right-click on the target which selects it and moves the message. They also mention that Exmh only permits one uncommitted action for a message at a time, so you cannot achieve a move by doing a link then delete then commit. The email ends with a brief comment about the weather in their location and their absence from where they are normally based."
   }, {
    "body": "On Friday, September Tony Nugent reported an issue where he can cut and paste from EXMHS message display window into spawned GVIM processes but not into anything else. He mentioned that it's odd because he can cut and paste between all kinds of windows (EXMH into Mozilla, Xterm, another wish script of his used for DNS tasks), except for that one. However, he expects this issue with the DNS task script as it is a custom script. He further noted that Netscape, when he used to use it, had similar issues but assumed it and Mozilla are from the same codebase approximately. He couldn't think of anything else it fails for that he has noticed. He is inquiring if anyone on the EXMHusers mailing list has encountered a similar issue with 'anything else'."
   }, {
       "body": "Dear Robert Elz and Tony Nugent, \n\nI have encountered an odd issue where I can copy-paste text from the EXMHS message display window into spawned Gvim processes but not into anything else. However, I can cut-paste between all kinds of windows except for EXMH. This issue has been ongoing for several weeks without a resolution. I've noticed this problem with Mozilla and another script I use for DNS tasks, but that could be expected. I can't think of anything else it fails for that I have noticed. \n\nFor instance, I can't even mark text in an EXMH message window and then paste it into a terminal window. The cut buffer seems to be completely empty and its previous contents are no longer there either. \n\nI'm writing from Queensland, Australia, where it almost feels like early summer already. Winters here are dry and warm, much better than cold wet Melbourne. Despite some recent rain (first in months), we are already into a drought with an El Niño on the way. It is only going to get worse; the last one in 2019 caused one of the worst droughts ever seen here in Australia. \n\nBest, Tony (EXMH users mailing list)"
   }, {
       "body": "In the main window, pressing the key takes you into a change folder mode for the first time after starting exmh. To set a target mode, type a few characters of the desired folder's name and press space for autocomplete. Continue hitting space to cycle through all matching folders. Press return to actually select the displayed folder. Please note that this is not recommended for navigating into nested folders, as I only have archives nested. For instructions on how to navigate into nested folders or if there are any tricks to it, someone else will need to guide you. This information is applicable to the hlexmh users mailing list."
   }, {
    "body": "On Friday, Robert Elz mentioned that he has his setup configured in a way that it does a move rather than selecting as target without moving. It appears Tony also faces the same issue. I had forgotten that this preference is configurable, specifically in the 'Preferences' folder, under the 'Display' action when the 'Target' button is clicked, which can be changed to select only. I believe I recall that the button used as the 'Target' button is also customizable, but I haven't had enough caffeine to remember exactly where that setting is. I will check the Alex Mhusers mailing list for more details."
   }, {
       "body": "Dear All,\n\nI'm having trouble with marking text in an EXMH message window and pasting it into a terminal window. It appears that the cut buffer is empty, and its previous contents are no longer there either. Recently, Brent confessed that he had attempted to manipulate the xmodels of copy and paste, not in those exact words but that's how I understood it. I find it challenging to copy and paste from or to EXMH across a VNC link, especially when moving things between the VNCViewer and areas outside of it, and vice versa. However, as long as I stick to apps normally displayed on my X server, I don't encounter much difficulty.\n\nFrom my memory of my X programming days, I recall that the X model, like most aspects of X, is more complex than the human brain can grasp. It also seems significantly different from the Windows model. I get the feeling that Tk attempts to unify these two models but fails. I'm not entirely sure about EXMH's specific contribution to this confusion, but frankly...\n\nBest,\n[Your Name]"
   }, {
      "body": "Dear Robert Elz,\n\nI've encountered an odd issue with Tony Nugent's email. He mentioned that he can cut and paste text from the EXMHS message display window to spawned gvim processes, but not into anything else. This seems inconsistent as he usually cuts and pastes between various windows without issue, except for EXMH. I've experienced a similar problem with Mozilla, Xterm, and another wish script of his used for DNS tasks. However, considering the nature of these applications, it might not be unexpected.\n\nWhat is peculiar is that he can't even mark text in an EXMH message window and then paste it into a terminal window. The cut buffer appears to be completely empty, and its previous contents are no longer there either. He's based in Queensland, Australia, and mentioned that it almost feels like early summer already.\n\nHe also shared that winters in Queensland are dry and warm, much better than cold wet Melbourne, despite some recent rain they've had. They are already into a drought with an El Niño on the way, which is only going to get worse. The last El Niño caused one of the worst droughts ever seen in Australia.\n\nHe speculated that this might be due to a problem with his GNOME setup. He and several coworkers have resolved similar problems by updating their GNOME components, although he can't pinpoint exactly which component did the trick. It seems most likely that GNOMEcore or GTK were the culprits, but it may have been something else.\n\nHe has not seen the problem for quite a while now.\n\nBest,\n Kevin Oberman\n Network Engineer\n Energy Sciences Network (ESNET)\n Ernest O. Lawrence Berkeley National Laboratory\n Berkeley Lab\n EXMH-Users Mailing List"
   }, {
    "body": "In the Tony Nu Gent interface, I have assigned my right mouse button to move a message to another folder, which works fine. However, links also use the same destination folder as the move function, causing inconvenience as I need to undo the move and mark a different destination folder before using the link. Is there a more efficient way to set this up so that I can link messages with one or two simple clicks? According to some old documentation, I should be able to use 'shift+right click' to link messages in the same way as moving them with only right click. Here are the suggested mouse bindings: left mouse button - change folder, middle mouse button - view nested folders, right mouse button - refile current messages to the folder, shift + right mouse button - link current messages to the folder, shift + middle mouse button - drag a folder label to some drop target, control + right mouse button - clear the current target folder. I hope this information helps you resolve my issue."
   }, {
     "body": "I've always found the mouse buffer operation with exmh perplexing as well. Here's my experience: I have exmh, xemacs windows open along with a terminal window, and Enlightenment as my WM. When I select text in the exmh window while it is highlighted, I can paste it into anything else. However, if I click so that the highlighting is off, then what I paste is not the recently selected text in exmh but an old selection. If I select text in xemacs and leave it highlighted, I can paste it into exmh's sedit window, but if it is no longer highlighted, what I paste is an old selection. This behavior is acceptable except for one additional issue: when nothing is highlighted, what I paste into exmh is different from what I paste into other windows. Specifically, if nothing is highlighted in xemacs, it pastes whatever was last selected unless it was last selected in exmh. If nothing is selected in xterm or abiword, it pastes the same as xemacs. nedit and sedit paste nothing. In nedit, when nothing is highlighted, what I paste is whatever was last highlighted in sedit and overwritten. To clarify, if I highlight something in sedit, obviously that's what gets pasted. If the highlighting is off, then what gets pasted is not what was last highlighted in sedit but what was last highlighted and typed over. It seems that exmh and sedit are the odd ones out here, as often when I try to paste something into sedit, I end up muttering 'what the frick', referring to the exmh users mailing list."
   }, {
     "body": "Hello Wendy Roberts, \n I see you're having trouble setting up an auto-forwarding button for your 'msgforward' form in 'mycomps' without going through the editor. I haven't found a perfect solution yet, but here are some steps that might help:

     - Ensure the 'noedit' flag is set in your form definition. This will prevent the edit window from appearing.
     - If you've tried using the 'draft' and 'send' commands, perhaps the order is incorrect. You should try putting 'send draft' after the forward command.
     - It seems like you're also trying to adjust filters on a spam address. After forwarding to this address, delete the email. However, it doesn't seem to be working without the edit window appearing.

     If these steps don't work or if you need further assistance, please let me know. I appreciate your help in resolving this issue.

     Best regards,
     [Your Name]"
   }, {
    "body": "Dear Exmh Users,\n\nI've been experiencing some trouble with copying text from an EXMH message window and pasting it into a terminal window. The cut buffer seems to be empty, and its previous contents are no longer there. This might be a guesswork issue, but I've found that updating my GNOME components has resolved the problem for me and others. Although I can't pinpoint exactly which component did the trick, it seems likely to be Gnomecore or GTK, but it could have been something else. As my workstation mostly works fine without updates, I hadn't bothered to update it until now.\n\nHowever, I haven't seen this problem for quite a while now, so upgrading GNOME might fix the issue. This doesn't appear to be an EXMH-Tkcl issue.\n\nBest,\nKevin Oberman, Network Engineer"
   }, {
       "body": "On Friday, September  dale alspach, I have found that when using the standard X copy and paste behavior, only what is currently highlighted is pasted using the mouse (classic). It is important to note that highlighting a selection actually copies it into the buffer, as opposed to there being a separate copy command within X. If you have highlighted something, you have essentially copied it, without the need for an explicit 'copy' command. However, this does not seem to override what is in an application's own paste buffer as far as I can tell. For example, Maple's cut and paste functions appear to be isolated from the X server's global select and paste functions. If an application has a copy command that can be used separately from the process of highlighting something, it is likely that this command was written independently by the application authors. Such applications may also have their own customized paste command to ensure compatibility between the two functions. Whether these internal custom select and paste functions interoperate with the X server's global select and paste functions will vary from program to program, as each case relies on the efforts of the program's authors to blend separate systems. Jacob Morzinski, ex-MUsers mailing list."
   }, {
      "body": "Dear Wendy Roberts, \n\nI've been trying to set up a button called 'Auto-Forward Mail' using a form in mycomps. However, I haven't found the correct recipe yet. Currently, I have one that sends emails from my work mail to my home mail using a dist binding. The binding looks like this: \n\n`set bindingskey hddistsilently form distcompstome`\n\nThe 'hddistsilently' is an old and hacked-up version of the proc that does dist in exmh, pasted below. It should probably be resynced with the current code, but it still works on a relatively recent CVS copy of exmh. There might be an easier way to achieve this, as I quickly hacked this together over a year ago and moved onto other tasks since it worked. Here is the proc:\n\n`hal proc hddistsilently args\nglobal exmh msg\nset exmhctype dist\nif string length args set args mhdistsetup\nif msgok msgid m\nif string compare info command args args old interface with hook procedure if catch args exmhfolder m err setup draft msg exmhstatus err purple return\nelse if catch exmhstatus dist exmhfolder m eval mhexec dist exmhfolder m nowhatnowproc args mhannosetup exmhfolder m dist err exmhstatus err purple return\neditdone send just send it exmhusers mailing list`\n\nBest Regards,"
   }, {
      "body": "Tony Nugent, on Friday Sep, I'm experiencing an issue with Emacs X Window Mailer (exmh) where I can't copy text from the message window and paste it into a terminal. The cut buffer appears to be empty, and its previous contents are no longer there. This could be a GNOME-related problem as updating GNOME components seems to have fixed similar issues for me and others at our lab. However, I can't confirm which specific component did the trick - it might have been GNOME Core or GTK, but it could have been something else entirely. Nonetheless, my workstation is mostly functioning without this issue, so I haven't updated it yet. Upgrading GNOME should resolve the problem, though it's not an exmh-tktcl issue. Other apps seem to handle cut and paste fine, but Tk has a unique approach to clipboard management that may be causing conflicts. I'm merely reporting my experience and not assigning blame."
   }, {
     "body": "I have transferred my exmh setup to a new system, and all my emails are now being routed to the 'mailmyincerrors' folder. This occurs regardless of whether it is the inbox or presort options. I am having trouble locating this specific condition in the documentation. If anyone on the exmh-users mailing list has any suggestions, they would be greatly appreciated."
   }, {
    "body": "It appears that the initial question concerns an update regarding the PGP code within exmh, specifically if anyone has any recent updates that the sender should be aware of. The user's issue is that when receiving a PGP signed message, they first get a button to verify the signature with GnuPG. After pressing the button, no signature appears on their keyring, and instead, they receive a message stating 'check public key not found', along with a button labeled 'query keyserver'. If this button is pressed, exmh seems to hang indefinitely. However, if the user bypasses the button and queries the keyserver manually before attempting the message again, the problem does not occur. This suggests that there might be an issue within the code that communicates with the keyserver. Other users experiencing this problem on the exmh and tcltk regclemens exmhusers mailing list."
   }, {
    "body": "Is it possible to customize the table of contents for specific folders within the email format, particularly for the formatted files used in scan sheets for the stonexmh users mailing list? While folder customization can be achieved using components and replcomps for message templates, I was wondering if similar customizations could be applied for formatted file formats."
   }, {
    "body": "I've been focusing on salary-related matters lately, but I've been prompted to revisit EXMH due to Robert finding the sllineno bug. Has anyone else been looking into the performance issues we discussed before my departure? If not, should I dive back in regarding Chris Garrigues at Vircio Congress Suite, Austin, TX (World War: The Wrongdoers vs the Application)? Here's the PGP signature for verification."
   }, {
       "body": "I have updated to the latest CVS. Running a build from June, clicking the 'flist' button produces an error in expression while executing the 'ftocfindmsg' procedure, which is invoked from within 'ftocshowsequences', 'ftocshownew', and 'incpresortfinish'. The issue appears to only occur in folders without any unseen messages. Chris, is this problem related to your recent changes? This matter pertains to the Scottexmhworkers mailing list."
   }, {
       "body": "Both 'Move' and 'Link' are one-click actions on a folder label. The former moves the current message to the selected folder, while the latter links the current message to it without moving. To achieve this setup, right-click on the folder label in the folder list. This configuration seems to be the same as Tony's, but his 'Move' function may simply perform a move rather than selecting the target without moving. If there are no messages currently selected, the system works fine in the main window. To change folders, press the key which puts you into a change folder mode. After starting EXMH, hit a second key and start typing a few characters of the folder name; hitting space for autocomplete. However, this method might not be user-friendly if you're using the mouse. A more convenient way to link in one click would indeed be beneficial. Adding such functionality should be feasible; shifting+right-click could be a good choice. However, adding mouse bindings is more challenging than adding key bindings. Currently, adding mouse bindings is difficult but not impossible. If the desired destination folder is not the current selected target, right-click on the target which selects it and moves the message. After moving the message to the new location, select the message again and then link it. EXMH only allows one uncomitted action to be selected for a message at a time, so you cannot achieve a move by doing a link then delete then commit. It needs to be link, commit, delete, commit. EXMH had similar limitations. Spring is progressing well down under, though it has been cold, wet and miserable where I am currently. However, the past few days have seen sunny days and cold nights. This weather is a good enough reason for me not to be there at the moment. Regarding EXMH users mailing list, Brent Welch (Software Architect, Panasas Inc) has provided valuable insights into pioneering the world's most scalable and agile storage network."
    }, {
    "body": "Hi Torsten, It appears that RPM is ignoring the version numbers for the package 'saxon-saxon' in your spec file. This might cause 'saxon-saxon' to install even with the same version number or prevent it from installing if there's a different version number. This behavior could be due to incorrect version number formatting or mismatch between the specified and actual version in your repository. Please verify the version numbers and their formatting to ensure they comply with RPM standards."
   }, {
    "body": "Hello, on Tuesday, August [redacted] asked a question about the 'require' tag. I apologize for not mentioning earlier, but there is actually a newsgroup dedicated to this topic: Torsten Schoe's RPM list mailing list."
   }, {
    "body": "The devices have arrived, thank you Gordon for reporting the issue and as mentioned earlier, you were the only one who could help. Any additional comments are more than welcome. I've just tried out the new spec and finally got sound working with my Abit integrated audio. It's been quite a struggle trying to get sound to work either with the drivers included in the kernel or the commercial OSS, but thanks to some helpful OpenSound people, we've managed it at last. The RPMs seem to be fine, they worked for me out of the box on vanilla Valhalla (latest Errata) Ikufi RPMList."
   }, {
    "body": "Dear Ille Skytt, \n\nThank you for your email regarding the devices at Ville Skytt. I appreciate Gordon reporting the problem and am glad that we were able to identify a solution for the sound issue with your Abit integrated audio. It's great to hear that you've been able to work things out with the helpful OpenSound people, although I understand it was quite a struggle. \n\nI'm pleased to hear that the RPMs worked for you out of the box on Valhalla latest errata, except for the absence of an init script in the RPMs. According to our records, a sample init script designed for Red Hat should be included in utilsalsasound. I will look into this matter and see if it can be included in future releases. \n\nThank you for your patience and for bringing this issue to our attention. If you have any further comments or questions, please don't hesitate to contact us.\n\nBest regards,\n[Your Name]"
   }, {
    "body": "Dear Ville,\n\nThank you for letting me know that the RPMs are working well for you on vanilla Valhalla with the latest errata, except for the absence of an init script in the RPMs. As per the instructions, a sample one designed for Red Hat is supposed to be found in utils/alsasound. I will look into including it in future releases.\n\nYou mentioned that Red Hat Linux sets correct permissions on all ALSA audio devices and that the modulesconf files take care of loading the right modules on demand. Additionally, you stated that aumix and the scripts that come with Red Hat still work for controlling the volume even when the computer is halted. I'm glad to hear that your card is working fine with these.\n\nRegarding your question about purchasing an amplifier that supports Dolby Digital decoding, since ALSA supports the SPDIF optical output of your Shuttle's sound chip, it seems like a good option to consider. I've only been using it for a few days, but I can already say that ALSA is impressive, especially since it maintains full OSS compatibility without breaking anything.\n\nBest regards,\nMatthias Saou, World Trade Center Edificio Norte Planta System and Network Engineer, Interactive Phone, Barcelona, Spain, Electronic Group"
   }, {
    "body": "Dear Villeskytta, \n\nThank you for your email. I'm glad to hear that the RPMs are working fine on vanilla Valhalla with the latest errata. However, I noticed that there doesn't seem to be an init script in the RPMs as a sample one designed for RedHat is supposed to be in utils/alsa-sound. Could you please check if it can be included?\n\nAdditionally, I found that alsaxmms does not work unless alsalibdevel is installed. If xmms starts but fails with 'cannot load ALSAsound cannot open shared object: no such file or directory', please ensure that libasoundso (which is part of alsalibdevel) is installed. This should resolve the issue.\n\nUnfortunately, I couldn't find 'xinelibs' anywhere. As for the Nvidia stuff, since you're using Radeon, it shouldn't be a concern in this case. If you face any other issues or need further assistance, please don't hesitate to ask.\n\nBest regards,\nIkifi RPM List"
   }, {
        "body": "Once upon a time, Ville reported that ALSAXMM plugins do not work unless ALSALIBDEVEL is installed, but XMMS fails to start with the error 'cannot load ALSAlib: cannot open shared object: no such file or directory'. To resolve this issue, ensure you have 'libasoundso' which is part of ALSALIBDEVEL. After installation, the ALSA XMMS output plugins should function correctly. As for installing the xine stuff, I am having trouble finding 'which', a component required by xinelibs. Lastly, there seems to be an issue with the NVIDIA stuff while I have Radeon hardware. I will look into resolving these issues. Thank you for bringing these matters to my attention."
        }, {
      "body": "Dear Ille Skytt Villeskytta, \n \n I appreciate your feedback on using rpms with Vanilla Valhalla and ALSA. You mentioned that you did not find an init script in the RPMs, but as Red Hat Linux sets correct permissions on all ALSA audio devices automatically through the consoleperms file and the modulesconf files, it is not necessary to include one.\n \n You also expressed that aumix and the scripts that come with Red Hat Linux still work for controlling the volume, even when the computer is halted. This explains why you were looking for an init script in the first place, but I am glad you didn't check whether the existing setup would have worked with that.\n \n Lastly, you shared your positive experience with ALSA, especially because of its full OSS compatibility and how it doesn't break anything. I completely agree with you, though my hours of experience are limited.\n \n Best regards,\n [Your Name]"
   }, {
      "body": "Previously, Ville mentioned that the mixer issue led him to search for an init script initially. He didn't verify if the existing setup would have worked with it, but he will give it a try. From his recent experiments, he found that both the main and the pcm can be controlled using either alsamixer or aumix. As far as he has experienced in just a few days, ALSA is excellent because it doesn't break anything when providing full OSS compatibility. I hope other list members will test it out to confirm. The reported issues with libasoundso and incorrect xine dependency have been fixed in the current packages. Additionally, I've finally implemented sorting by both last change date and alphabetically for my build list in the php code. I am open to any patches, comments, suggestions regarding all those spec files. Regards, Matthias Saou (System and Network Engineer, Barcelona Spain, Electronic Group Interactive Phone)"
   }, {
       "body": "Thank you for your message. To switch between Digital OUT and Analog OUT with ALSA, use 'emuconfig d' for digital and 'emuconfig a' for analog. Unfortunately, there isn't an exact method like this with ALSA. However, you can adjust the settings in the alsa-mixer or through configuration files. If you encounter any issues or have further comments, feel free to follow up on Wednesday at 10am with Matthias Saou. \n\nRegarding your update, you've created a subpackage of alsadriver named alsakernel which includes only the kernel modules. The alsadriver package now contains everything else from the original package (device entries, files, docs). This setup allows the installation of a single alsadriver package and multiple alsakernel if you have more than one kernel installed. Those who install from source can still install the ALSA modules from the source. Gordon, thank you for reporting the problem, as mentioned, you were the only one affected by this issue. \n\nFor those running a different kernel, simply rebuild the alsadriver source RPM and you'll get a package for your current kernel. For custom Red Hat Linux RPM packages, visit the provided link. For further information about Valhalla running Linux Kernel, check out the online battery RPM list mailing list. If you need to find files larger than a given size in a directory, use the command 'find path/to/directory -type f -size +nk' where 'n' is a number or multiples thereof. Discussions on this topic can be found on the lih : jul : rpmlist mailing list."
    }, {
   "body": "In my email on Thursday, I mentioned that the mixer issue was what led me to search for an init script initially. I didn't check if the existing setup would have worked with it, but I will try that out. If there's silence, it means success. I have tried both the main and the pcm at least, and volume levels can be controlled either through alsamixer or aumix. I will also test it using the new rpms tomorrow. From my short experience so far, ALSA seems impressive, especially because it maintains full OSS compatibility without breaking anything. I agree that this is great, though with only a few hours of use, I can't say much. I hope more people from the list will try it out. The issues you reported (libasoundso and wrong xine dependency) are now fixed in the current packages, thanks for pointing them out. That was quick!"
   }, {
       "body": "I've successfully installed ALSA and I no longer experience static interference, which is excellent. However, the setup only outputs sound through the front speakers and subwoofer, with the rear speakers being silent. Additionally, both alsamixer and aumix are unresponsive. Lance, I will give them another try on Wednesday. Regarding switching between digital out and analog out with ALSA, is there a similar method to the one you mentioned using Emuconfig (d for digital, a for analog)? Lance, I hope to hear from you on Wednesday. Matthias, regarding your follow-up about the ALSA package, I understand that you've created a subpackage called alsakernel which contains only the kernel modules, and alsadriver contains everything else from the original package, including device entries, files, and docs. This should allow for the installation of a single alsadriver package and multiple alsakernel packages if more than one kernel is installed. People who install from source can still install the ALSA modules from the source. I appreciate your prompt attention to this issue, Matthias. If anyone has any further comments, they are welcome. For those running Red Hat Linux or similar systems, you may need to rebuild the alsadriver source RPM and you'll get a package for your current kernel. For custom Red Hat Linux packages, follow these steps: redhat linux release (Valhalla), run Linux Kernel (load online battery rpm list mailing list: linux one stanza tip lost sub: finding out files larger than given size, use the command 'find pathtodir -type f -size +nk' where n is a number like 5K or multiples thereof for discussions on this topic, refer to the rpmlist mailing list in July."
   }, {
    "body": "Hi there,\n\nPreviously, Lance mentioned that he successfully installed ALSA but is experiencing an issue where sound is only coming from the front speakers and subwoofer, with the rear speakers remaining silent. He also noted that alsamixer and aumix are unresponsive. He's seeking additional information or tips regarding his specific card on the ALSA page.\n\nHe also suggested trying to manually edit the alsactl store file (which contains data similar to what can be controlled with alsamixer) and then running 'alsactl restore' to see if he can adjust settings that way. \n\nIf you have any insights or solutions, please share.\n\nBest,\nMatthias Matthias Saou\nWorld Trade Center Edificio Norte\nPlanta System and Network Engineer\nBarcelona, Spain\nElectronic Group - Interactive Phone : rpmlist mailing list"
   }, {
     "body": "Subject: Updates on package fixes and new features for alsadriverspec\n\nI've addressed both the issues you reported regarding libasoundso and wrong xine dependency in the current packages. It might be worth mentioning that I've also implemented sorting by last change date and alphabetically for my build list in the php code.\n\nI accept patches, comments, suggestions about all those spec files. I've added flags to remove oss and isapnp support at build time if one wishes to. It's possible to do a rpmbuild recompile without oss without isapnp (I haven't included oss in my setup as it's not supported on my motherboard, and I'm too lazy to recompile the kernel).\n\nI've also added a flag 'kernsrc' that can be used to remove the dependency for kernelsource at build time. It would be nice to check if the correct kernel include files actually exist (though I'm currently unclear about how to do this in RPM building as I'm still a beginner).\n\nRegarding your issue with building your own rpm for alsadriver, you've removed all alsa rpms and tried rpmbuild with yours (alsadriverspecmine) without oss, without isapnp, and without kernsrc. However, you're encountering a long list of successful compile snippets and dev files listed, but it seems like the devadsp file and devamidi are installed but unpackaged. I believe this might be due to the files coming from the makedev rpm, and alsasound should have been installed by alsadriver. If you look in the right places, you'll find that they are there (I think the relevant part is this line: 'cp a buildroot/sysconf.d/makedev').\n\nLastly, I forgot to mention that I'm running beta null : Matthias Silent and on the seventh day, god was arrested for trespassing."
   }, {
       "body": "Thank you for your email, Daniel. To summarize your message, you have added flags to your spec files that allow removal of OSS and ISAPNP support at build time, and are also working on a flag (kernsrc) to remove the dependency for kernelsource package. You've encountered issues with building a requirement for a file not provided by any package and found no solution other than stopping the build process if it isn't found, which you find unsightly. For the 'withcards' option in alsas configure, you are uncertain about how to implement it. You have also discussed the process of creating your own RPM for an alsakernel, removing all existing alsa RPMS, and encountering issues with rpmbuild. Lastly, you mentioned that you are running a beta version of Null which has new features such as build failure when files are present in the build root but not listed in the files section, and have set the variable 'unpackagedfilesterminatebuild'. Is this correct? I will do my best to help with your questions."
    }, {
    "body": "I understand your points regarding the RPM build process and installing ALSA kernel drivers. Here's a suggestion: You could install an alsakernel for the original kernel you've kept, and install ALSA modules from source for custom kernels built from source. This setup would allow you to create base files excluding the kernel drivers. For dependency reasons, this seems to be the best approach. However, please keep in mind that this may require individual handling of each card due to the 'with' feature of rpmbuild. Also, I should note that I was only considering this for tweaking purposes and not for real-world needs. As for your comment about God being arrested on the seventh day, it certainly provides a good laugh!"
   }, {
      "body": "Axel has informed us that he is back to his normal state and is passing on some information. It appears that Matthias Saou's build directory has a hardcoded path, specifically in his package. It would be beneficial to identify this issue and rectify it. Axel mentions that he often uses the username 'dude', which has been his login since before The Big Lebowski was released. It seems that some programs incorrectly hardcode his home directory when compiling. For instance, the strings for usrbingentoo and usrbinxine contain the word 'dude' in their search operations, and they seem to refer to his home directory as 'homedude'. These instances should be considered as bugs in the programs' build process, particularly for Xine. Axel intends to report these issues upstream when he has some free time. Thank you for bringing this to our attention."
   }, {
    "body": "Hello Ille, \n\nI believe I can assist you with the new plugins package for gkrellm. I see two options: keeping it as it currently is or packaging each plugin separately. The latter seems to be easier to maintain.\n\nBest,\nMatthias"
   }, {
     "body": "Dear Lance, \n\nI'm sorry for the inconvenience but I can't directly answer your question as it requires hands-on experience with your specific hardware setup. However, I can guide you through some steps to troubleshoot and hopefully find a solution.\n\n1. You mentioned that you have issues switching between digital out and analog out using ALSA driver and utilities such as gamix. With OSS drivers, you used 'emuconfig d' for digital and 'emuconfig a' for analog. In ALSA, it seems the controls are located in alsamixer or gamix itself. You mentioned finding 'sb live analogdigital output jack' in alsamixer but haven't figured out how to use it. I suggest exploring the options within these tools to see if you can find a similar functionality.\n\n2. Regarding expanding gamix to display all possible controls, you mentioned that it defaults back to wave and music with LFE center surround and playback under wave for digital output. You'd like to see all the controls. I would recommend referring to the gamix documentation or seeking help from its community forums.\n\n3. Lastly, you mentioned having a tuner and cassette deck hooked up to an audio-video switch that goes into line in on the soundcard. You were able to switch between digital out (for anything coming from the computer) and analog out (for the tuner and cassette deck) using 'emuconfig d' and 'emuconfig a' with the emutools package for SBLive. It seems you want to know if this is necessary to switch in-between to get line in to work or not. Unfortunately, I can't provide a definitive answer without testing it on your setup.\n\nI hope this helps and wish you the best of luck in finding a solution! \nRegards,\n[Your Name]"
   }, {
    "body": "Hello,\nI've discovered a small problem with the Downloader X update, specifically with the FTP search engines. It appears that they are missing some components. I appreciate your attention to this matter in advance.\nBy the way, I really enjoy the xmmsxosd plugin."
   }, {
    "body": "I've observed that there are packaged versions of Blackbox and Hackbox available from freshrpms. However, it seems there are no RPMs for Fluxbox, which I would appreciate if they were made available as its creators appear reluctant to provide them. By the way, do you know if the rpmlist mailing list provides realtime stock quotes via Yahoo Finance?"
    }, {
    "body": "Hi, I've attached a spec file for Fluxbox that I created some weeks ago. You might find it useful, if not, you can at least use it as a reference. Please note that this might be an old version, but it should still work. If there is a chance to include it in the system, it would be great. However, do let me know if it's not feasible. Regarding packaged versions of Blackbox and Hackbox, I found them on freshrpms. As for Fluxbox, there seems to be no RPM package available yet. Yes, I use Yahoo Finance for real-time stock quotes. Attached is the Fluxbox spec file."
   }, {
       "body": "Previously, I used 'apt-get upgrade' with great satisfaction when using regular distributions. Now that I am running Null Beta, I was wondering if there is a version of APT that can be used for updating Null with the RPMs available for Null through freshrpms.net since I prefer APT over other methods. If possible, can I use APT to receive updates from the Null Redhat upgrades on freshrpms.net? My question is from an angle of simplicity in a complex world, similar to how one might view angles in geometry."
    }, {
   "body": "If I can use APT, can it be utilized to obtain updates from these different repositories such as null.redhat.com, upgrades.null, files.freshrpms.net? Yes, you could build your own apt repository by mirroring the necessary directories. For instance, using a wget cron job or similar tools. Symlink the required RPMs, recreate the repository and keep it updated via a regular maintenance schedule (e.g., symlink the needed rpms and use a wget cron job). This approach is beneficial if you have multiple installations. In order to access the mentioned places, someone needs to maintain such a repository up-to-date, either yourself or another individual. For more information, consider joining the rpmlist mailing list."
   }, {
     "body": "Hello Axel Thimm and Angles Puglisi,\n\nIf I can make use of APT, may I utilize it to receive updates from these different repositories such as null.redhat.com, upgrades.null, files.freshrpms.net? You could establish your own APT repository by mirroring the required directories using a wget cron job, symbolically linking the needed RPMs, and recreating the repository. It would be beneficial if you have more than one installation.\n\nIt's always nice to have a place to put things that override Red Hat elements like, for instance, if you absolutely despise Qt and some programs are rebuildable from sources with different configure options. In such cases, you can get src.rpm, edit spec file, bump the release number with your initials and another number, rebuild, insert into APT, and let loose.\n\nI believe freshrpms also has an updates directory, although it may not be as up-to-date as the regular files from freshrpms.net. However, I would never use it. There is another repository at apt.rpmtux.org (I think; I'm not certain if that had the updates list).\n\nBest,\n[Your Name]"
   }, {
       "body": "I've built another alsaplayer this time on my 'null box'. I'm not sure what that means, but this time it compiled successfully with the new ALSA drivers, thanks to Matthias for providing the ALSA RPMs. He's done a great job in bringing sound to the masses! In geometry terms, he's an 'angle' that brings significant improvements."
   }, {
       "body": "Dear Stephen Liu,\n\nIt appears that you're having trouble installing 'processing' using the apt package manager on your system. From your description, it seems like the package is not available in the repositories you are currently using.\n\nIn Ubuntu and Debian-based systems, the official 'processing' packages are usually found in the main repository or the universe repository. If you haven't already, try running 'sudo apt-get update' to ensure your system has the latest package lists. After that, you can try installing 'processing' again using 'apt-get install processing'.\n\nIf you are still encountering issues, it might be worth exploring other methods such as building from source or using a PPA (Personal Package Archive) if one is available for the version you need. Alternatively, you could try using another package manager like RPM if you have the necessary files.\n\nI hope this helps! Let me know if you face any further issues.\n\nBest regards,\n[Your Name]"
   }, {
    "body": "Stephen originally wrote: apt-get install. However, this is not the intended way to use apt. For details, please refer to Gordon's response on the Valhalla list. Matthias Saou, World Trade Center Edificio Norte Planta System and Network Engineer, Barcelona, Spain, Electronic Group Interactive Phone, also suggested checking the rpmlist mailing list."
   }, {
      "body": "Hello,\n\nI encountered an issue with one of the freshrpms RPMs after upgrading mplayer. Now, I'm getting a mplayer error: 'while loading shared libraries: cannot open shared object: No such file or directory'. It appears that the dependency libdvdnav may have been overlooked by Matthias. I reported this issue on the linux rpmlist mailing list.\n\nBest regards,"
   }, {
       "body": "Hello Rob, \n I believe you've installed Red Hat and are trying to install mplayer to play QuickTime MOVs. Since you mentioned using apt-get source for mplayer and attempting to rpm rebuild, it seems like you might be using a mix of Debian (apt-get) and RPM (Red Hat)-based commands, which may not work as intended in Red Hat. \n \n To install mplayer on Red Hat, you can use the yum package manager. Here's the command to install it: \n\n `yum install mplayer` \n\n If you encounter any issues, you might want to consult the Red Hat documentation for more guidance: https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/Deployment_Guide/index.html \n \n Hope this helps! Let me know if you have any further questions. \n\n Regards,"
   }, {
     "body": "Hello Rob, \n \n It seems you are having trouble rebuilding MPlayer on RedHat. Here are the steps you can follow to resolve your issue:\n \n 1. Ensure that you are logged in as root and navigated to the directory where you have downloaded the MPlayer source file.\n \n 2. The error message about dependencies might appear, but don't worry, most of them can be found at freshrpms.net (excluding those which you can find on your Red Hat CD, FTP or rpmfind.net).\n \n 3. After rebuilding the source RPM, it should generate a binary RPM with all dependencies met.\n \n 4. To install MPlayer with codecs, use 'rpm -ivh' command to install the RPM package and place the required codecs in a directory (you can find the codecs from Google).\n \n Good luck! If you encounter any further issues, feel free to ask.\n \n Regards, Lance"
   }, {
       "body": "Dear Lance, \n I believe there might be a few issues with the process you're trying to follow. Here are some suggestions:\n\n1. Ensure that you are in the correct directory after downloading the file and rebuilding as root.\n2. The error about dependencies might be due to missing packages. FreshRpms is a good resource, but for specific Red Hat packages not found there, you can look up on your Red Hat CD, FTP, or rpmfind.net.\n3. After rebuilding the source RPM, it should generate a binary RPM that meets all dependencies. If 'mplayer' is giving you trouble with RPM IVH, you might want to try installing it directly using other methods such as yum or dnf.\n4. The codecs are essential for mplayer to function correctly. You can find them on Google, but remember to create a directory and place the codecs there before running the program.\n5. Regarding your issue with 'rpmlist mailing list', it seems like you might be missing the file or directory referenced in the rpmlist command. I would recommend checking the path and ensuring it exists before executing the command.\nHope this helps! Let me know if you encounter any more issues."
   }, {
     "body": "Dear User,\n\nIn your email, you mentioned that you are encountering the same error when trying to rebuild or recompile RPMs even after doing so as root. You also mentioned that you have downloaded the files as root. If the issue is related to the source RPM not being installed correctly, I would suggest checking if the source RPM for mplayer is present in /usr/src/redhat/SPECS.\n\nIf the file 'mplayerspec' exists, you can try running the command 'rpm -ba mplayerspec' to build the binary RPM from the SPEC file. This should be done on the system and network where you have the necessary resources (Matthias Matthias Saou, World Trade Center Edificio Norte, Planta System and Network Engineer, Barcelona, Spain, Electronic Group Interactive Phone: rpmlist mailing list).\n\nIf this does not resolve your issue, please provide more details about the error message you are receiving so I can assist you further."
   }, {
    "body": "The title page you are referring to appears to have a login screen, and I cannot seem to access the apt indexes anymore. It seems that this issue might be affecting other users as well, indicating there may be some ongoing problem with the system."
   },
   {
    "body": "For additional information, please check out GnuPG (GNU Privacy Guard), a free tool for secure communication and data encryption on GNU/Linux systems. If you have any questions regarding this matter, feel free to consult the rpmlist mailing list."
   }, {
      "body": "Dear all, \n\nHarri previously mentioned that the title page has a login screen and he is unable to access the apt indexes anymore. He also noted that over the past few days he has experienced connection problems with the site but for him currently, it seems to be working. Harri is Matthias Saou, World Trade Center Edificio Norte Planta System and Network Engineer from Barcelona, Spain. In case anyone else is encountering similar issues, please feel free to reach out.\n\nRegards,"
   }, {
    "body": "Subject: Issues with Apt Indexes and URL aptfiles\n\nDear Matthias Saou,\n\nHarri wrote about an issue where the title page has a login screen and he can't access the apt indexes anymore. He mentioned that the requested url 'aptfiles' was not found on this server for the past few days. However, he's experienced connection problems with that site from time to time but it seems to be working now for him.\n\nHe also mentioned that you might be experiencing the same issue. It could possibly be a temporary problem.\n\nRegarding the 'win a live rat for your mother-in-law' application and the pgpsignature, please find them below:\n\nbegin pgp signature\n\ngnupg\n\gnulinux for info see end pgp signature\n\nFor more information about the rpmlist mailing list, please refer to it.\n\nBest regards,"
    }, {
    "body": "Hello, \n Previously, you were informed that the requested URL 'aptfiles' could not be found on this server. However, it appears to be functioning correctly from your end at present, even without any proxy setup and after refresh attempts. I have encountered occasional connection issues with that site over the past few days, but they seem temporary.\n\nIf you still encounter problems or require another Red Hat Linux file repository, you may find alternatives in the following list: Matthias Matthias Saou (World Trade Center, Edificio Norte, Planta System and Network Engineer, Barcelona, Spain) - electronic group interactive phone: rpmlist mailing list."
   }, {
    "body": "Dear Matthias Saou,\n\nHarri wrote to you a few days ago about experiencing connection issues with a specific site. However, at the moment, it seems to be working for him. He suggests that if there are any problems in the future, there are other APT repositories available with Red Hat Linux files.\n\nHe mentioned some local ones like nixia, rpm, gnomehide, and rpmsrc, which had newer GNOME packages when needed. He also mentioned his own repository at work, Orkplace.\n\nAdditionally, he provided a list of mailing lists for more information: grep, electrocute, scary devil monastery application, pgpsignature, and rpmlist.\n\nIf you need further clarification, please see the links below:\nckwn\n\nRegards,"
   }, {
       "body": "Hi Brian, \n \n It seems you're having trouble uninstalling an RPM package. The issue might be due to a conflict or the package manager not recognizing the installed package. Here are some steps you can try: \n \n 1. Use the 'rpm -qa' command to list all the installed RPM packages. This will help confirm if the package is indeed installed.\n 2. If the package appears in the list, but you still cannot uninstall it, try using 'sudo rpm -e [package-name] --justdb' command. This will remove the database record of the package without actually uninstalling it. Then try reinstalling and uninstalling the package.\n 3. If none of the above steps work, you may consider reinstalling your RPM database with 'sudo rpm -Va --nofiles --nodigest' command and then try uninstalling again.\n \n Hope this helps! Let me know if you still have any trouble."
   }, {
      "body": "Dear Mattias, \n\nIt seems there may be some confusion with your RPM packages. From what I understand, you have an RPM package that you want to uninstall, but the system doesn't recognize it as installed. You mentioned using commands like 'rpm erpm package' and 'rpm ifh preparing rpm package', which might not be the correct approach. \n\nTo clarify, when you want to uninstall an RPM package, you should use the command 'rpm -e <package-name>' without any version or release details, as the system will automatically find the correct package based on its name. If you're still encountering issues, ensure that the package name you're using is accurate and that there are no typos. \n\nRegarding your command 'rpmlist mailing list', I believe you meant to subscribe to the RPM mailing list for further assistance on this matter. You can do so by visiting the corresponding website or following the instructions provided there.\n\nBest Regards,"
   }, {
      "body": "Dear Brian, \n\nIt seems there might be a misunderstanding regarding how you specify the RPM package for installation and uninstallation. Instead of providing the entire filename, you should use the name and version of the package. For example, if your RPM is 'apg', you would enter 'rpm -e apg' to uninstall it, not 'rpm -e apg rpm'. If you encounter issues like the package already being installed or not found, ensure that the package name is correct and try again. If you continue to experience difficulties, please provide the exact name and version of your RPM for further assistance.\n\nBest regards,\nRpmlist Mailing List"
   }, {
     "body": "Hi there, \n\nIt seems you're having trouble uninstalling an RPM package. The issue might be that you're including the version information in your commands. To uninstall an RPM package, you should omit the version info and just use the package name. For example: rpm -e packagename.\n\nIf you've already tried this and it still doesn't work, there might be dependencies preventing the uninstallation. You can try using 'rpm -qa | grep packagename' to verify that the package is indeed installed and check for any dependencies that need to be removed before attempting to uninstall again.\n\nHope this helps! Let me know if you run into any more trouble."
   }, {
    "body": "Hello,\n\nIt appears that you frequently encounter errors when running 'apt update'. The issue might be rooted in the repository itself, your system configuration, or possibly a timeout due to a slow internet connection. The error messages suggest that there may be issues with the headers of the packages being fetched, as indicated by 'bad header line' and 'bad request'. If you are on a slow network, it might help to try the operation at a time when the connection is less busy.\n\nIf you would like to discuss this further, I am available. In case my response seems overly technical, please let me know if there is any misunderstanding.\n\nRegards,\n[Your Name]"
   }, {
      "body": "I have encountered issues with dependencies in my RPM database, which prevents me from using aptget. I attempted to run 'apt-get f install' to resolve these dependencies, but faced errors: root apt-get f install processing file dependencies done reading package lists done building dependency tree done correcting dependencies done The following extra packages will be libgcj. The following new packages will be libgcj. Packages upgraded, newly installed, to remove/replace and not upgraded will be used. However, during the process of unpacking, an error occurred on file sum mismatch. Subprocess binrpm returned an error code. This issue was observed while using rpm list mailing list."
   }, {
      "body": "Hello, \n I've noticed that you often encounter errors during 'apt update'. This issue might be due to problems with the repository itself, your end, or a timeout in the connection caused by a poor modem. It could also potentially be a 'bad header line' error. However, it is also possible that the problem lies elsewhere. I suggest checking if everything on your end is set up correctly and ensuring a stable internet connection. Regarding the en subdirectory, my system works fine without it, but I'm not sure if it always gives you the same error each time. I don't use a proxy server.\n\nRegarding your question about the RPMList mailing list, I am a member of the 'rpmlist' mailing list and work as a System and Network Engineer in the Electronic Group Interactive Phone Department at World Trade Center Edificio Norte, Planta, Barcelona, Spain."
    }, {
     "body": "Lance initially reported issues with failed dependencies in RPM database, preventing him from using apt-get. He requested running 'apt-get f install' to resolve these dependencies, but encountered errors: 'unpacking of archive failed on file sum mismatch'. Matthias suggested that the downloaded file may be corrupted and recommended attempting 'apt-get clean' first to remove all downloaded files. This action might solve the problem. The issue concerns the RPMList mailing list and Matthias is a System and Network Engineer based in Barcelona, Spain."
   }, {
    "body": "Hello,\n\nI encountered an issue with apt-get where I have failed dependencies in the rpm database, preventing me from using apt-get. I tried running 'apt-get f install' to fix these dependencies, but I received errors when executing it: 'unpacking of archive failed on file sum mismatch', and 'subprocess binrpm returned an error code'. Root suggests that the file downloaded by apt may be corrupted. He advises trying 'apt-get clean' to remove all downloaded files first, which might solve the problem.\n\nBest regards,\nMatthias Saou, System and Network Engineer, Barcelona, Spain, Electronic Group Interactive, rpmlist mailing list"
   }, {
      "body": "Hello, I'm creating an RPM for the Resin webserver and I want to install the entire tarball under a specific directory. However, the tarball contains subdirectories, and in my spec file, I install 'sm name-version-release' under '/usr/local/resin'. Is there a proper way I should handle this? If I wasn't clear, I apologize for any misunderstanding. Regards, [Your Name] Dream Theater RPM mailing list"
   }, {
   "body": "On Friday, February [Date], I was thinking about setting up a local APT repository for the main and upgrades from somewhere in addition to my own at work. I've been pondering how to manage a local apt repository from Finland as there doesn't seem to be much public information available on this topic. Would it be possible to share some insights, or at least suggest a starting point? Specifically, I'm interested in using rsync and I was wondering if you have any thoughts on that, or if there are other tools that might be more suitable for this task. I've also been subscribed to the peter-rpmlist mailing list."
   }, {
      "body": "Apologies for the confusion earlier. I didn't notice that Reply-to was set to the list instead of the sender, my apologies for any inconvenience caused. I was asking Harri if he could provide some advice on how to build my own APT repository for RHEL updates. There is a tutorial I am following currently, but if you have any other suggestions, I'd be grateful. As for building a local APT repository in Finnish, I couldn't find much public documentation. Could you possibly shed some light on this matter or provide guidance on where to start? Ideally, I would like to use rsync and consider FTP as well, any thoughts on these methods?"
    }, {
      "body": "Once upon a time, Peter wrote: On Feb at Harri Haataja, I have a local one for the main and upgrades from somewhere plus my own at work. I've been thinking about setting up a local APT repository myself since I can't find a public one in Finnish. Could you help me out with this, or at least give some advice on how to start? Finnish seems even more complicated than German to me. Mattias, World Trade Center Edificio Norte Planta System and Network Engineer, Barcelona, Spain (electronic group interactive phone): rpmlist mailing list."
   }, {
    "body": "Apologies for the confusion, it seems I didn't consider the context while sending the previous email. The 'Reply-To' was addressed to the rpmlist mailing list instead of the sender as usual. Can we adjust it to be sent only to the sender?"
   }, {
    "body": "Subject: Query regarding APT setup and repository\n\nHi Peter Peltonen and Harri Haataja,\n\nI've been contemplating setting up a local APT repository for the main and upgrades from somewhere, in addition to my own at work. I was wondering if you could help me with this, specifically: Is it possible to open up the issue a bit, or rather, how soon would it be appropriate to start discussing a practical approach (for instance, using rsync)?\n\nI have a directory tree structure like this:\nsrpmscurrent\tRed Hat RPMs\nrpmscurrent\tbase\nsrpmsoRed Hat SRPMS\nrpmsosbase\nbasedirectories\ti throw updates to RPMs and my own stuff with makefile : to testing after each new package\n\nTo get this to work, you need to create release files (pinch someone else's for example, this can be found under Apache) and put the URL of your keys and all that into the apt conf on the machines on the network, then let 'apt' do its magic.\n\nI find Funet mirrors to be very slow, so I usually use TuxFamily for updates. However, when I see errata, I typically also add it to my own one, so the rest of the machines have a shorter path to it. Funet hosts a whole load of mirrors and projects; it used to be the main mirror for Linux, and was one of the big pub FTP sites. If there were a definite APT repository, perhaps they might mirror that as well. However, I doubt Red Hat would be very keen on using APT and forking a distribution doesn't seem like an easy option.\n\nBarry also pointed out that the Titanium uses Torque screws instead of Phillips screws, which seems to have little significance, but apparently it interested Barry. This is just something interesting I thought you might find amusing or intriguing.\n\nBest,\n[Your Name]"
   }, {
        "body": "Dear Peter Peltonen,\n\nOn Monday, February, I started pondering about how APT behaves when it encounters a newer kernel among the files slated for update. Upon looking at /etc/apt/apt.conf.d, I suspect that the kernel matches with the kernel packages except for those specified by SMP Enterprise. It seems that APT won't perform any actions related to kernels unless explicitly instructed.\n\nUpon further reflection, it is possible that the initial statement might not be relevant at all. I typically use 'apt-get install kernel', pick a version from the list, and then install it manually. Has anyone ever attempted a dist-upgrade (say from X to Y)? If not, why hasn't this been tried? However, I have added a netboot mirror to my sources.list and followed the step-by-step installation process, which, for as far as I remember, worked fine.\n\nI anticipate that there might be some rpmnew files worth checking, particularly passwd and group, as there seems to have been a group change lock. It's always wonderful to wake up and not know what day it is, isn't it?\n\nBest regards,\n[Your Name]"
        }, {
     "body": "Peter originally mentioned that he was curious about how APT reacts when it encounters a newer kernel among files scheduled for update. He suggested checking the etcaptaptconf file for this information, and asked if anyone had attempted a distupgrade (specifically from one version to another). If not, Peter explained that he had performed a distupgrade from one version to a rawhide release that was quite broken, describing it as a mess but faster than doing it manually with rpm. He suggested that updates between stable releases should still be done with the installer since he believes Anaconda performs some configuration migrations in new formats. However, Peter prefers backing up config files and reinstalling a clean system when he has time."
   }, {
     "body": "In your message, it appears that Matthias Saou's system skips some packages, and you can find more details about this in the etcaptaptconf file. If I understand correctly, this configuration leaves the list of allowedduppkgs empty to disable duplicates. The packages held from installation are kernel, kernelsmp, kernelenterprise, and kernelsource. However, only kernelsource and kernelheaders are actually held. Since you're unsure about this setup, it would be a good idea to test it on a vanilla system. Please share your thoughts on the rpmlist mailing list."
   }, {
     "body": "Hello, I recently installed an RPM and when I tried to upgrade using 'yum update' from my cache, the operation 'preparing' could not be completed. Can you explain what 'dbincomplete' means? Although it appears that the installation seems to have been successful, if I seem superhuman or if there is any misunderstanding regarding my query, please let me know. This is in relation to the RPM list mailing list for Dream Theater."
   }, {
    "body": "Hello Mark Derricutt, \n I hope this message finds you well. I've encountered an issue while trying to upgrade a package using RPM. When I used 'uvh' to prepare from cache and flush, the process was unable to complete. It seems the problem is not with the RPM itself but with the RPM system. The cache appears to have spoiled. I suggest you try removing the directory '/var/lib/rpm/rpmdb' and then the 'rpmlist' mailing list.\n Regards,"
   }, {
      "body": "It appears there might be an issue with your RPM system, as it seems the cache has corrupted. I suggest you try removing the variable 'varlibrpmdb' to see if that resolves the problem. If you still encounter issues, it may indicate that the operation was not permitted. This isn't a problem with the specific RPM file, but rather with the RPM system itself. I apologize for any confusion, and please let me know if this doesn't help."
   }, {
       "body": "I apologize for any confusion, but there was an issue with a cron job and rpm qf on Wednesday. Mark Derricutt resolved the problem regarding an exclusive lock on 'var/lib/rpm/packages' and could not open packages index using operation not permitted. If I appear superhuman in this message, please understand that it is due to misunderstanding. I am part of the rpmlist mailing list for Dream Theater."
    }, {
    "body": "Mark Derricutt, I apologize for any inconvenience but it appears there was an issue with a cron job running 'rpm qf'. However, it seems to be resolved now as of Wednesday. On the same day, Mark Derricutt faced an issue where he couldn't get an exclusive lock on '/var/lib/rpmpackages'. He also encountered a problem when trying to open packages index using operation not permitted. A possible solution suggested was to do a 'rpm rebuilddb'. This issue was discussed on the rpmlist mailing list."
   }, {
       "body": "I'm sorry for any inconvenience, but it appears that the following packages have unmet dependencies related to openssl although PostgreSQL is installed. However, PostgreSQL was installed from a source other than apt, which may be causing the conflict. To resolve this issue, you might want to try using 'apt-get -f install' or manually installing the required openssl package that provides the necessary compatibility. In addition, you need php-pgsql for PHP to work with PostgreSQL. It seems there is a way to inform apt about packages it should not complain about by maintaining an RPMList on the mailing list 'peter rpmlist'. I hope this helps!"
   }, {
      "body": "Dear Peter Peltonen,\n\nI'm sorry to inform you that the following packages have unmet dependencies related to openssl, although PostgreSQL and its php extension are installed correctly. This issue seems to be due to string parsing inconsistencies in the package names. If this can be fixed by removing the explicit reference to openssl in the package, I believe the automatic binary handler will select the appropriate libraries.\n\nUnfortunately, I haven't encountered a package similar to OpenSSL that does not explicitly provide compatibility. In the worst case, I suggest they bump the major version if it proves incompatible.\n\nSince you have PostgreSQL installed from source, there might be some unmet dependencies causing this issue. If you know of specific packages (like JDK, imlib, kernel dri version, etc.) that you don't want APT to complain about, you can create dummy packages with a verbose warning attached, explicitly providing those capabilities or claiming to do so.\n\nIf you prefer a gradual approach, could you start by trying to sign your applications using the PGP signature? For more information on this, please see the end of this email for resources. If you require further assistance, don't hesitate to ask.\n\nBest regards,\n[Your Name]"
    }, {
     "body": "Dear Peter Peltonen, \n\n I'm writing regarding the issue with the packages you mentioned on February 06. The packages in question have unmet OpenSSL dependencies, but PostgreSQL is installed and functioning correctly. However, it seems that the system cannot recognize the compatibility between the installed OpenSSL and the required OpenSSH package. \n\n I suspect this could be a matter of string parsing, and if someone were to fix the OpenSSH package by removing the explicit version requirement, the automatic binary handler should be able to install the correct libraries. Unfortunately, I haven't encountered an OpenSSH package that behaves in this manner, and in the worst case, I've had different OpenSSL libraries causing issues. \n\n Strangely, all my OpenSSH packages don't explicitly require a specific version of OpenSSL. \n\n Regarding your OpenSSH version, it would be helpful to know if it is an official Red Hat package. If not, using Red Hat RPMs might solve this problem. For the OpenSSL dependencies in Red Hat packages, I've found that they only depend on certain files and not on the OpenSSL version. \n\n Kind regards,\n Matthias Matthias Saou\n System and Network Engineer\n Barcelona, Spain\n Electronic Group Interactive Phone : rpmlist mailing list"
   }, {
    "body": "Dear Govind Salinas,\n\nIt appears that you are experiencing issues with aptget, specifically related to errors during an update operation. The error message suggests a problem with the dequeueing of fetching objects within the system. This could be due to various reasons such as network connectivity problems, corrupted package files or inconsistencies in the repository data.\n\nI recommend trying these troubleshooting steps:\n1. Restart your system and try running apt-get update again.\n2. Check your internet connection and ensure it is stable during the update process.\n3. Clear the apt cache using the command 'sudo apt-get clean'.\n4. Reinstall Aptitude package manager (if you have it installed) using 'sudo apt-get install aptitude' and run 'aptitude update' instead of 'apt-get update'. If this resolves your issue, consider making aptitude the default package manager.\n5. If none of the above steps help, consider checking the repository settings or updating to the latest version of your OS distribution.\n\nIf you continue to face issues or require further assistance, please do not hesitate to ask. I hope this helps resolve your problem. Best regards.\n\nSincerely,\n[Your Name]"
   }, {
     "body": "On Wednesday, February, Harri Haataja installed an OpenSSH version I haven't encountered before. In the worst-case scenario, I have had different OpenSSL libraries, and I find it confusing as to why they can't just bump a major version if it's incompatible. Since I have created dummy packages with verbose warnings attached that explicitly provide those capabilities or claim to do so, could you guide me on how to make such packages using the rpmlist mailing list?"
   }, {
      "body": "It seems that your OpenSSH packages do not explicitly require a version of OpenSSL. Regarding the version of OpenSSH you have, it's not clear if it is an official Red Hat package. Since it appears that using Red Hat RPMs may solve your problem and it comes directly from the OpenSSH site, I assume it isn't part of the Red Hat upgrade you mentioned. However, as you don't have physical access to the box and downgrading SSH packages over SSH doesn't seem like a good idea, I would recommend considering a different approach. If possible, you could try to access the server remotely using another method or ask someone with physical access to perform the downgrade for you."
   }, {
    "body": "Dear Matthias Saou,\n\nIt appears that Peter was discussing an issue with OpenSSH packages not explicitly requiring a version of OpenSSL. He mentioned that he is using Red Hat and was wondering if you were also using it, and whether the OpenSSH package in your system is an official one or not. He suggests that using Red Hat's RPMs might solve his problem. However, he notes that the OpenSSH package from Red Hat doesn't ship with OpenSSH, which leads him to consider downgrading to the version provided by Red Hat. But since he doesn't have physical access to the box, he can't do this directly. He also mentions that uninstalling all OpenSSH related packages while connected through SSH works, although there is a risk of being stuck if the connection drops. He then suggests that a simple upgrade with official Red Hat packages could work as well."
   }, {
       "body": "On February 16th, to Harri Haataja,\n\nI've been experimenting with JDK imlib kernel DRI version and have created dummy RPM packages for certain capabilities. However, I'm concerned about potential issues during software updates as these dummy packages might get updated and overwrite the source installation.\n\nI was thinking that perhaps there could be a way to do this without making a dummy package using Apt-get or rpmlist mailing list. Is there something like 'no-depends' kind of switch in Apt-get, similar to how RPM lists work?\n\nBest regards,"
   }, {
      "body": "Regarding aptconf, you've mentioned a list of RPM packages that are left empty to disable them. To hold all kernel packages, you can use the following syntax: 'apt-mark hold kernel*'. This command will hold all packages whose names start with 'kernel'. The term 'kernel' here refers to the Linux kernel and its associated packages."
   }, {
    "body": "In regards to your message about aptconf, the RPM leave list contains packages such as 'kernel', 'kernelsmp', 'kernelenterprise' among others. To hold all kernel packages, you can use a similar syntax like 'kernel'. However, it seems that the term 'kernel' may refer to more than just these packages in this context. Regular expressions might interpret 'kernel' as matching only 'kernel' and nothing more, but 'kernelsmp', 'kernelenterprise' are also considered kernel packages in an RHEL system. Packages like 'kernelheaders', 'kernelboot', and 'kerneldoc' would not be matched if it simply said 'kernel'. If you want to hold all these kernel packages, you should ensure that 'kernel' includes the aforementioned package names."
   }, {
    "body": "Dear Mathias, I appreciate your efforts and the work you've done. However, I would like to bring to your attention that the focus of this list seems to be shifting towards apt, rather than rpm. The discussions about apt are dominating, which is making it challenging for those dealing with issues related to aptrpm. While I acknowledge that aptrpm is a valuable tool, I don't use it myself and would prefer to discuss new packages and RPM building techniques. It might be beneficial to consider establishing another list specifically for aptrpm discussions. Looking forward to your understanding."
   }, {
     "body": "Hello,\n\nI am writing to acknowledge your previous message regarding the shift of focus from the rpmlist to the aptrpmlist. You raised a valid point about the overwhelming discussion on apt, and I appreciate your suggestion for another list for those having trouble with aptrpm. While I agree that aptrpm is a valuable tool, I do not personally use it and would like to return to discussions about new packages and RPM building techniques.\n\nYou also mentioned that there has been little activity on the aptlist for some time now. Though you intended to keep this list for aptrpm discussions related to server-side mirrors and repository building, it could serve as a platform for general aptrpm questions. I hope this proves helpful.\n\nBest regards,\nMatthias Saou\nWorld Trade Center Edificio Norte\nPlanta System and Network Engineer\nBarcelona, Spain\neGroup Interactive Phone : rpmlist mailing list"
   }, {
    "body": "Hello everyone, I will be departing this evening and won't have access to any computer until next Monday. So, don't worry if there's a new release during that time, as it might not be updated quickly despite my previous efforts to repackage the latest Hackedbox which was released today. Have fun! I will return on Monday. Matthias Saou, World Trade Center Edificio Norte, Planta System and Network Engineer, Barcelona, Spain, Electronic Group Interactive Phone."
   }, {
   "body": "Dear All, I will be away from today evening until next Monday without access to any computer during this period. I'm very much looking forward to it! The network issue here for an hour was driving me up the wall. Enjoy your week, Chris Kloiber."
   }, {
    "body": "Dear RPMList Members,\n\nI am writing to inform you that I have repackaged the latest version of Hackedbox and it was released today. Enjoy exploring it! I'll be here enjoying it as well since I have recently recompiled GNOME.\n\nHave a great time!\n\nRegards,\nMatthias"
   }, {
       "body": "Chris recently emailed to inform everyone that he will be leaving tonight and won't return until next Monday, meaning he'll have no computer access during this period. The network downtime of an hour here left him restless, and he can't stand being disconnected, whether at work or home. He had planned on doing something requiring network access, but the pressure from work has almost driven him crazy all summer. With six days ahead without computers, Chris won't be miserable or bored; instead, he'll enjoy driving his Bandit roadster bike and reading the Lord of the Rings books (he still needs to finish the first one and read the other two). He also looks forward to drinking beer with friends during his holiday. Chris is delighted to finally take a break this year."
   }, {
      "body": "There is a severe shortage of sequencers at the moment. I would prefer to have this running on my primary machine which runs Irix, but I might try to handle that myself. All software and hardware sucks – even my vacuum cleaner, it never listens! (Tanuki, the raccoon-dog, is a scary devil) - Regards, [Your Name] (for RPMList mailing list)"
   }, {
     "body": "Hello, I'm making a rare announcement. I've rebuilt a new ALSAPlayer package, modeled after AngleSharp's version. I believe this is the final iteration of the ALSA driver and ALSKernel packages as they address all known SMP build issues. You can find them here: https://link-to-packages. I've also repackaged GKrellm, with a standalone server package that doesn't require the main installation. Additionally, my latest ProFTPD package includes some exciting new features, such as support for LDAP, MySQL, and PostgreSQL databases. When you rebuild the source RPM with rpmbuild, you can enable desired extra authentication methods. All package requirements are set accordingly, and the release tag is changed too. I plan to use this more often, especially where possible. Some of my other packages already utilize it, such as xmame for its output targets, sqlrelay for its modules, and my latest Sylpheed, Claws-Mail spec to enable pilot support. As always, feedback and comments are welcome. Here's the usual place: Red Hat Linux release Valhalla running Linux Kernel LOAD: ACOne online battery rpmlist mailing list."
   }, {
    "body": "On Wednesday, regarding Matthias Saou's email, I believe I will utilize Switch more frequently wherever applicable. I have also been considering this idea myself. Do you have any good suggestions for documenting these targets and their descriptions? I will share my thoughts on the ikiwiki-rpmlist mailing list."
   }, {
    "body": "Hello, I'm back from my holidays and hope you are well! I think I will be using Switch more often from now on. I've encountered a few issues while trying to get the Redhat Samba Packager to do the same thing I have been doing. One of the problems was hashing out things for other uses. Regarding the kernel, I still haven't found an easy way to rebuild it without having to wait for an hour for it to generate headers for all arch. It's quite frustrating! (arrghhh). I've posted my concerns on the lee rpmlist mailing list."
   }, {
      "body": "Once upon a time, Clee wrote: I think I will use this more frequently with Switch where possible - great stuff! Now, to get the Red Hat Samba packager to do the same thing, I'm sure that if you file a bugzilla entry with a relevant patch against the spec file, the chances of getting the change done are on your side. I have used their spec file and found a few problems in it, one of which was hashing out things for other uses. Now, to tackle the kernel, I'm still struggling to find an easy way to rebuild it without having to wait an hour for it to generate headers for all arch - arrghh! The problem is that the way a package is built isn't meant to be changed deeply. Its use would be more like enabling/disabling gpg, LDAP, whatever SQL support in packages. Unfortunately, using something like 'with' for a wider scope isn't possible with Red Hat Linux RPM packages."
   }, {
   "body": "Matthias Saou has rebuilt a new ALSAPlayer package, based on Angle's ONEless, as it is easier to maintain. An intriguing aspect of ALSAPlayer is that it plays media files out-of-the-box, whereas Red Hat's XMMS package may not. Furthermore, the development team at ALSAPlayer is progressing rapidly in their CVS, and their next version seems promising. However, I am unaware when this new version will be available."
   }, {
    "body": "I was thinking about increasing SylpheedClaws' priority. I noticed that Sylpheed has received a boost, so let's show some 'claws' too! Best regards, Jesse Keating, Mondo DevTeam"
   }, {
    "body": "Angles Puglisi is rapidly progressing with their CVS, and it appears that the next version of Alsaplaer will be quite intriguing. However, I'm not certain about its release date, as I was unaware that they had already launched the new angle (in geometry context) for the rpmlist mailing list."
    }, {
     "body": "Previously, Jesse mentioned considering an upgrade for SylpheedClaws as he noticed Sylpheed received an update. However, in the SylpheedClaws branch, you need to wait for developers to backport all updates from the main branch before a release with the same version number can occur. Currently, the latest Claws release is still ongoing. Since it serves as your primary mailer, you can rest assured that an update will be made once it's been updated. \n\nMatthias maintains clean custom Red Hat Linux RPM packages for this software. The Red Hat Linux release 'Valhalla' runs on a Linux kernel load, and it's associated with the AC Online battery rpm list."
   }, {
       "body": "Hello,\n\nIt seems that there may be some confusion regarding the use of codecs with MPlayer. It appears that the documentation still suggests using them for certain architectures, but I was wondering if there might be licensing issues or other reasons preventing such a practice.\n\nI have noticed performance and feature differences when it comes to fullscreen playback on Nvidia graphics cards, particularly regarding visual artifacts. The MPlayer authors seem to recommend using codecs for specific architectures, but I may be mistaken as I am not an expert in MPlayer codecs.\n\nIs there perhaps a reason why this is suggested, or should these codecs be avoided?\n\nBest regards,\nAxel Thimm"
   }, {
     "body": "Dear All,\n\nAxel Thimm previously asked if anyone knew why the mplayer documentation still recommends using codecs for certain architectures. Axel mentioned that his avifile build can run with the default ffmpeg's ffdivx decoder, and he has been satisfied with this for most divx files. However, he noted that some files encoded with a peculiar divx sound format still require the use of codecs. He also stated that he hasn't observed any quality or speed improvements when using these codecs.\n\nAxel inquired if there were perhaps licensing issues or other reasons that prohibit such practices. His question arises from his observations of performance and feature differences, specifically fullscreen viewing without keeping the aspect ratio and visual artifacts on Nvidia, comparing with and without the use of codecs.\n\nAxel clarified that he is not an expert in mplayer-codecs, and he might be lost. He was referring to custom Red Hat Linux RPM packages: Red Hat Linux release Valhalla running a Linux kernel load AC Online battery RPM mailing list."
   }, {
      "body": "I recently discovered a well-designed repository for various audio apps, located at angles (in geometry context). Mathias Saou, Peter, and Angles Puglisi have rebuilt a new ALSAPlayer package, modeled after the original one. This is beneficial because it means less work in maintaining one package. One notable aspect of ALSAPlayer is that while Red Hat's XMMS package may not play files, ALSAPlayer does so without any issues right out of the box. They are also actively developing their software, and it appears that the next version of ALSAPlayer will be quite impressive, although I am uncertain as to when it will be released. This is discussed on the rpmlist mailing list."
   }, {
    "body": "On Friday, Sep [date], Matthias Saou updated something. Since it's my primary email, you can be confident that I will update my build as soon as the changes are reflected. The updates have already been made by Jesse Keating on Monday. I found the Mondo Devteam to be helpful regarding this issue. I will also inform others through the rpmlist mailing list."
   }, {
      "body": "I need to conduct some tests involving the removal of my advanced cut-pastecode, which appears to be a historical artifact from early versions of Tk and Emacs cutbuffer, among other oddities. You can achieve this by modifying seditbindtcl appropriately. I've been encountering issues with marking text in an exmh message window and pasting it into a terminal window. The cut buffer seems to be empty, and the previous contents are no longer there either. Brent admitted recently that he had attempted to manipulate the x models of copy and paste, although not in those exact words. I struggle with copying and pasting from or to exmh across a VNC link, particularly when dealing with items in the VNCViewer and things outside it. As long as I stick to apps displayed on my X server, I don't have many problems. My recollection from my X programming days is that the x model, like everything in X, is more complex than the human brain can handle. It also appears that Tk attempts to unify these two models and fails. I'm not certain what the exmh-specific contribution to the confusion is. This email is being sent to the Hal exmhusers mailing list, Brent Welch (Software Architect, Panasas Inc), pioneering the world's most scalable and agile storage network."
   }, {
       "body": "Here is a rephrased version of your email:

       The functionality you are referring to is outlined in these lines, more commonly known as textselectionTcl. This is the procedure that exmh uses to locate text for pasting. However, there seems to be an issue with the last cutbuffer get, as exmh saves its own deletions in a lesser-known stash and might be the only application on Earth still using this method. We should probably look into disabling this feature.

       Everything flows through this spot, so you just need to tweak it here to resolve your issue. Rick Baartman, I've never quite grasped the mouse buffer operation with exmh either. Here is my behavior:

       I have windows for exmh, xemacs, a terminal, and enlightenment as WM open. If I select text in the exmh window while it is highlighted, I can paste it into anything else. However, if I deselect it by clicking so the highlighting disappears, then what I paste is not the recently selected text in exmh but an old selection.

       This behavior is acceptable except for one additional issue: If nothing is highlighted, what I paste into exmh is different from what I paste into other windows. To elaborate, if nothing is highlighted in any application, xemacs pastes whatever was last selected unless it was last selected in exmh; xterm behaves the same as xemacs; abiword, nedit, and sedit paste nothing; however, sedit pastes whatever was last highlighted in sedit and overwritten.

       This needs some clarification: If I highlight something in sedit, obviously that's what gets pasted. However, if the highlighting is off, what gets pasted is not what was last highlighted in sedit but what was last highlighted and then typed over. It appears that exmh and sedit are behaving inconsistently.

       Often, when I try to paste something in sedit, I find myself muttering 'wtf' Rick. Exmh users mailing list, Brent Welch (Software Architect, Panasas Inc.), pioneering the world's most scalable and agile storage network."
    }, {
     "body": "In his book, Hal Devore Brent mentioned that while the paste function can be convenient, it can be confusing for users who primarily understand the clipboard. This is because they need to keep track of the difference between two selections. It's best to have separate user actions for pasting each selection. The convention is that the 'set insert point and insert primary selection' action (often triggered by a key event like the paste key) simply inserts the clipboard selection at the current insert point. I learned this from experiencing the distress of EXMH users. If you search for 'bind' in seditbind, you'll quickly find the textselection proc I mentioned earlier. Brent Welch, Software Architect at Panasas Inc., is a pioneer in creating the world's most scalable and agile storage network. This discussion originated from the EXMH users mailing list."
    }, {
      "body": "Hi All, \n\nI've observed that Kevin Oberman's issue was resolved for him, but I am hesitant to attribute it as a TkTcl issue since other apps seemed to work fine with cut and paste. Tk handles the clipboard differently compared to most toolkits, so I'm not pointing fingers just reporting my experience. \n\nIn X and cutpaste X, there are at least two mechanisms specified for cut and paste, but as usual, no clear policy is mandated. Windows and Macintosh have a slightly different mechanism and one uniform policy. I am quite sure that Tk implements all primary and clipboard selections accurately. The primary selection is tied to the visible selection on your X display, while the clipboard selection is the same as what you have on Windows and Macintosh. However, exmh includes support for the cutbuffer mechanism, another archaic mechanism that was perhaps still in use by some versions of Emacs. \n\nexmh has a policy that aims to unify all these mechanisms under one umbrella, and based on reports, it's not great. I encourage everyone to experiment with the textselection lines of code and share what works well for them. We might discover settings that work for everyone or perhaps introduce another setting that allows users to choose between a few useful models. This is an admission of policy failure, but I am willing to do that. \n\nBest, \nBrent Welch, Software Architect, Panasas Inc - Pioneering the World's Most Scalable and Agile Storage Network"
   }, {
       "body": "I would like to encourage users to experiment with the code related to TextSelection and share what works best for them. We might find common solutions or even introduce new settings that allow users to choose from useful models. However, I must admit that there seems to be an issue with our current system, although it works perfectly fine for me, except for one problem: a button click clears the primary selection where it shouldn't. The previous selection should only be cleared when there is something else to replace it, even if the highlighting of the selected text disappears. This issue can be observed in various applications, not just EXMH. In most other applications, there is no mouse-based method to intentionally clear the primary selection, which remains as a null string until asked for its value. If you click with the intention of setting the insert point, followed by paste, the primary selection still belongs to EXMH because nothing else has taken it. As a result, EXMH finds some random data from either the clipboard or cut buffer and pastes that instead. This behavior, I believe, is the real issue that needs to be addressed. Once this is fixed, we can return to the standard click-at-new-insert-point-paste mode of operation that most users expect."
   }, {
        "body": "I have updated to the latest CVS. When I run a build from June and click on the 'flist' button, I am encountering a syntax error in expression while executing 'expr g procedure ftocfindmsg'. This issue seems to only happen in a folder with no unseen messages. It appears that the problem could be related to your recent changes. I made changes to the arguments of ftocshowsequences to drop the folder argument and instead have an optional msgids argument. However, it seems that your version of scanfolder is still trying to pass the folder argument. I am using the latest ftoctcl but not the latest scantcl. I'm not sure how this happened, but I suggest updating your source tree completely. Let me know if you need further assistance."
   }, {
      "body": "I apologize for the confusion. It appears that during the installation, I wasn't careful and the 'exmhlibrary' variable was pointing to my old installation. Remarkably, it functioned better than expected. I've since removed the old library directory and edited 'exmh', 'exmhbg', 'exmhstrip' among others, to point to the correct one. However, now I'm encountering another traceback: 'cant read no such variable while executing mhseq'. This error occurred during the execution of 'mhseq folder seq add mhprivpubseqfolderseq mhseqexpand folder msgids procedure mhreadseqs'. I'm currently working remotely and it's rather slow. I'll investigate further when I get home tonight to see if there are any other issues. \n\nIn the meantime, I've updated to the latest CVS. Pressing the 'flist' button now gives a syntax error in expression while executing 'expr g procedure ftocfindmsg'. This problem seems to occur only in a folder with no unseen messages. Chris, is this issue related to your recent changes? If so, you might have missed updating some components of Scantcl. Please ensure your source tree is fully up-to-date."
   }, {
       "body": "Dear Scott Lipcon,\n\nI have just updated to the latest CVS and I'm encountering a syntax error while executing the 'expr g procedure ftocfindmsg' in the 'ftocshowsequences' procedure. This issue seems to only happen when there are no unseen messages in the folder.\n\nIt appears that my recent changes might be related to this problem. I have changed the arguments to 'ftocshowsequences' to drop the folder argument and instead have an optional msgids argument, but your version of scanfolder is still trying to pass the folder.\n\nYou seem to have the latest ftoctcl but not the latest scantcl. It seems that the source tree might not be fully up-to-date. Please update your source tree completely and let's see if the problem persists.\n\nRegards,\nChris Garrigues"
    }, {
       "body": "Dear Scott Lipcon,\n\nI apologize for the confusion earlier today regarding the EXMH library. It appears that I was not careful during installation, causing the exmhLibrary variable to point at my old installation. Remarkably, it functioned better than expected! \n\nTo resolve the issue, I removed the old library directory and edited exmh, exmhbg, exmhstrip, etc., to direct them towards the correct one.\n\nHowever, I'm now encountering another traceback error: 'cannot read no such variable' while executing mhseq folder seq add mhprivpubseqfolderseq mhseqexpand folder msgids procedure mhreadseqs line invoked from within mhreadseqs folder seqs procedure mhsequences line invoked from within mhsequences folder procedure flistunseenupdate line invoked from within flistunseenupdate folder procedure folderchange line invoked from within folderchange family msgshow cur invoked from within time list folderchange folder msgshowproc procedure folderchange line invoked from within folderchange exmhfolder procedure exmh line invoked from within exmh after script family.\n\nI believe the folder I was in when I quit EXMH should not have been able to happen, but I've made some adjustments to the code to make it slightly more robust. If you need any further assistance, please let me know. \n\nBest regards,\nChris Garrigues\nVircio Congress Suite\nAustin, TX"
   }, {
    "body": "Scott Lipcon, I have returned home and found the current copy of EXMH less than ideal. I've been running it from CVS on Sunday night, with the only change being the one you made this morning in mhreadseqs for bulletproofing. Upon running EXMH, I can visibly see it count up the number of unseen messages as it looks through the folders. This takes a few seconds to complete, especially for folders in the fcache, which turn blue once done. However, it seems to be considering more than just unseen messages, causing a delay in the background to build the sequences window. There may be some tuning possible in this area. In my Inbox, unread messages are white and have normal colored font. I changed the default display of unseen messages from a foreground of blue to a white background to make it easier to see other sequences' unseen messages. I did ask Brent before doing this if you prefer the old behavior, but the old lines are still in appdefaultscolor, commented out. When I click on a message, I receive an error saying 'invalid command name mhmarkseen while executing mhmarkseen exmhfolder msgid'. This is due to your hookmsgshowupdateunseen which is calling a function that no longer exists. I suspect you need seqdel exmhfolder unseen msgid instead of mhmarkseen exmhfolder msgid. The message does seem to be marked as seen once it loses the white background, but nmh reports the same. If I click on the flist button, it zeros the unseen count and then there is again a visible delay as it counts up all the unseen messages. My installation seems fine now, but if this behavior is just really strange, I'll reinstall everything to be sure. I am comfortable enough using nmh and am willing to help track this down."
   }, {
       "body": "Scott Lipcon, the issue seems to be regarding the slow rescanning of sequences. This problem is particularly noticeable when hitting the 'flist' button or during background flist operation. The system you're using (Athlon RAM RPM Ultra SCSI disk) is fast, so the delay might not be due to system speed but rather a change in the code that now updates each folder count individually instead of all at once. I doubt I will have much time for coding soon, but if I do, I would appreciate your suggestions for optimization. If not, perhaps we could add preferences to disable some of the more resource-intensive features. Specifically, I'd like to disable all sequence support except for 'unseen', and maintain reasonable speed. I believe that people on slow machines may find the current state unusable. The problem appears to be with your hookmsgshowupdateunseen which is calling a function that no longer exists. It seems you need seqdel exmhfolder unseen msgid now instead of mhmarkseen exmhfolder msgid. I'm not sure if this will be necessary with the new sequence code, but it might. Yes, the new code commits sequences immediately unlike the old code."
   }, {
       "body": "The proposed solution is to code a menu item that marks all messages before the current one as read, specifically in Exmh mailing lists. This would help you manage heavy traffic mailing lists better by allowing you to read only a subset of list messages without losing track of your place within a particular folder. Here's a rough idea of how this could be implemented:

1. Add a menu entry for the function, which can be done easily. Place this in your :all section.
2. Provide the source code for the function and arrange for Exmh to include it. You can put it in your tkexmh directory or in pickpatch if you enable the source hook under prefshacking support.
3. The implementation would look something like this (based on the guts of pickmarkseen):

```bash
global exmh pick msg
exmhstatus clearing unseen up to cur red
mhsetcur exmhfolder msgid set pickids get message ids for pick busy pickmarkseen
exmhstatus ok blue
```

4. You will need to fill in the code for the 'get' section, which I was unable to complete due to time constraints.
5. Once implemented, you may encounter issues with recent changes as this is somewhat untested."
   }, {
     "body": "Dear Chris Garrigues, \n\nHere's a proposed solution that I believe will significantly improve FTOCShowSequences functionality. The enhancement allows FTOCShowSequences to be called with an optional list of msgids for updating. If called this way, it only removes or adds tags for the specified messages. In places like msgchange, we would only update the messages that have changed. Additionally, a separate FTOCShowSequence function should be written, which updates the display of one sequence and takes an optional list of msgids. In situations like msgchange, it would only need to update the current sequence if no other modifications are made. I will implement this change upon my return. I have tested this modification and it has significantly improved speed; latency has dropped and we are back in good shape again. Well done, Anders. \n\nBest Regards,"
   }, {
    "body": "It appears that over the last few weeks, there has been a change in a folder named 'msgs'. When messages in that folder are marked as current (read) and then changed to another folder, they briefly show up as unread before changing back to 'ncurrent'. This behavior is somewhat annoying because it marks messages as read. Additionally, it seems to be happening on the exim4 mailing list."
   }, {
    "body": "It appears that there has been a change in a folder 'msgs' during the past few weeks. The issue seems to be that messages are being incorrectly marked as 'current' for a brief moment when changing folders, which marks them as read even though they have not been read. I haven't seen exactly what you described, but I have noticed something similar. I will need to investigate further to identify and fix the bug. It seems that there is an issue with the message being incorrectly highlighted as 'current' possibly related to the current message in another folder rather than the actual message itself."
   }, {
     "body": "I am sending a patch for Exmh, which addresses my concern about it caching my PGP passphrases. I have added code to allow for the use of an external tool like Quintuple Agent to store passphrases instead. The attached patch is against Debian version and modifies the files extrasinittcl and pgpexectcl. Three new preferences in the general PGP section have been added, allowing users to utilize their preferred external tool to retrieve passphrases. Everything that spits out the phrase on stdout is acceptable. I hope someone with CVS access finds this worth adding. Apart from that, I'm open to suggestions, comments, or critique. Please note that I'm not exactly a TCL expert, so my code may have areas for improvement. Regards, Alexander Zangerl."
   }, {
    "body": "I will need to test it with a different window manager and see if I can get exmh to confine it within reasonable boundaries. I don't encounter this issue with any other windows, but just the unseen exmh window. As an alternative, could we enable the 'show unseen message count in folder cache' option? This feature displays the number of unseen messages next to each folder name if there are more than a few. Therefore, you might not need the unseen window unless you're using more sequences than just unseen."
   }, {
     "body": "On Fri, Sep [Year], Paul Menage wrote that you don't really need the 'unseen window' unless you're using more sequences than just 'unseen'. He suggests using a virtual window manager and keeping the main exmh window and the detached folder list on one virtual desktop. However, the 'unseen window' should be set to show on all desktops. He clarified that he didn't provide help for the problems but just explained why some users find the 'unseen window' invaluable."
   }, {
      "body": "Dear User,\n\nI hope this message finds you well. I'm writing in response to your recent email regarding Exmh, specifically the issue with unseen messages not being visible in certain folders. It appears that this feature has disappeared within your window manager and you can't seem to locate it.\n\nYou mentioned that you're using Enlightenment with a virtual desktop. You've tried dropping it to only one screen, but the issue persists. I understand that this might not be helpful in your current situation, but I thought I should mention it.\n\nRecently, you discovered that pressing Alt+MiddleMouse brings up a list of all your windows. However, when you leave your mouse on the background, it seems to move your mouse to the edge of a window and centers it on an offscreen window. This issue only occurs with the Exmh unseen window, not any other windows.\n\nYou mentioned that you'll try this with another window manager to see if you can get Exmh to behave as expected. I hope this helps in your troubleshooting efforts.\n\nBest regards,\nExmhusers Mailing List"
   }, {
       "body": "I've rephrased your email to make it clearer and more concise. Here is the revised version:\n\nDear Exmh Users,\n\nI encountered an issue with the 'exmhunseen' window in my current setup, where it exceeds the defined boundaries. I don't face this problem with any other windows, only with the exmhunseen window. To help you identify unread messages more easily, consider enabling the 'Show Unseen Message Count in Folder Cache' option, which displays the number of unread messages next to each folder name if necessary.\n\nHowever, I prefer keeping the unseen window visible across all virtual desktops even when the main window is minimized. Unfortunately, I couldn't find this specific preference option, and I am running version 'creaky'.\n\nI discovered an issue with my Enlightenment window manager causing the problem. The settings file for Enlightenment had my exmhunseen window shaded and placed off-screen, making it very small. After some investigation, I found entries related to the unseen window in the file: 'exmhexmh', 'exmh', 'unseenunseenwin', 'unseen', and 'pagerleftblue'. Restarting Enlightenment and then Exmh resolved the issue.\n\nI learned that this was an Enlightenment problem, not an Exmh one. I wonder how it got mixed up initially. I cannot intentionally move a window off-screen, unless it was partially over and then snapped off-screen when shading. This is strange, but hopefully, this information will be useful to someone searching the archives in the future.\n\nThank you for your suggestions, and here's hoping that this issue helps someone in the future."
    }, {
     "body": "After tinkering with the exmh TCL and experimenting a bit, I've managed to get the 'catchup unseen messages before cur' procedure working. Here's the code for everyone's reference, along with the list archives in case anyone needs it in the future. I must thank John R Loverso for guiding me on the right path. To utilize this script, insert it into your tkexmh directory, run 'automkindex' on it, and add the following lines to your ketchup catchup all before current:

    Ted Cabeen
    Check website or keyserver for my PGP public key (pgp key ID) as I have taken all knowledge to be my province.
   }, {
    "body": "Here is the code for everyone and the list archives, should it be added to CVS in the future? I vote yes. Please let me know if there are any objections on the alexmhworkers mailing list."
   }, {
    "body": "Here is the rephrased email:\n\n'Dear Team,\n\nAttached is the code for everyone, as well as the list archives. In case anyone needs it in the future, this will be a useful resource.\n\nI propose that we add this to CVS. If there are any objections, please let me know. However, I suggest modifying the name of the procedure from 'ted cabeen'. You can find my PGP key on the website or keyserver for verification.'\n\nBest,\n[Your Name]'\n\nRegards,"
    }, {
       "body": "I vote for this proposed addition to CVS, with no objections. However, I find the use of 'pickmarkseen' and 'pickids' as an alternative to 'seqdel exmhfolder mhprofileunseensequence' unnecessary. In essence, pickmarkseen does what can already be achieved via 'busy'. The same criticism applies to 'pickmarkseen', which, despite its name, has no connection with 'pick' other than the misuse of the 'pickids' variable in the same way. Changing its name would be difficult due to its recognition in appdefaults files for the 'catch up unseen menu item'. Nevertheless, I believe its implementation could be improved."
    }, {
       "body": "I apologize for not staying current with the code changes for some time now. I'm currently trying to address the issues and differences that have arisen. It appears that the 'Unseen Window' has been replaced with the 'Sequences Window', although I appreciate the flexibility of the Sequences Window, the Unseen Window held significant importance for me due to its small size and ability to be set to display on all desktops in a virtual window manager without taking up much space. Since my normal mode of operation involves two copies of exmh displayed on a VNC session screen space is at a premium.\n\nAs things stand now, I have a Sequences Window that shows a lot more information than I need to have handy and takes up a lot more room than I can spare. I could like the new Sequences Window for certain operations, but I prefer a clean, uncluttered tiny window that only shows me info on my unread mail.\n\nOne possibility that occurs to me would be a button or mouse click that shrinks the Sequences Window to show only the sequences in the 'Always Show List' and of course a way to expand it back. I hope this suggestion is helpful. Looking forward to your responses on the hlexmhworkers mailing list."
   }, {
    "body": "I encountered a problem with the binding 'bindingskeyflistfindunseen incpresortfinish' in my 'exmhbindings' after updating to the current code in CVS. Now, when I press the 'f' key, I get a 'bad key f' error. However, I can open the bindings commands window and define the binding, which works until I restart exmh. I suspect there might be a parsing issue. I'll look into this tomorrow unless someone knows where the problem might be. If you have any insights, please share on the 'hal exmhworkers mailing list'."
   }, {
       "body": "Dear Chris Garrigues, \n\nI have been experiencing an issue with my exmh bindings after updating to the current code in CVS. When I hit the 'f' key, I get a 'bad key f' error. However, if I open the bindings commands window and define the binding, it works until I restart exmh. I suspect this might be a parsing problem. I will try to look into this tomorrow, unless someone knows where the issue might lie. \n\nIt appears that flistfindunseen has changed to flistfindseqs in the updated code. It takes the same arguments but I changed the name because it now looks for all sequences, not just unseen ones. \n\nBest regards,\n[Your Name]"
   }, {
    "body": "One idea that came to mind is implementing a button or mouse click function that minimizes the Sequences window, displaying only the sequences in the 'Always show list'. To expand it back would also be necessary. This seems like a good idea, but I'm unsure if I'll be able to work on it soon as there's a known bug that I haven't been able to address yet. Chris Garrigues (Vircio Congress Suite, Austin, TX) - Discussion about 'World War: The Wrongdoers vs The Evildoers' Application"
   }, {
      "body": "I am experiencing a few minor issues with exmh and I'm unsure if these are related to exmh itself or my setup. First, when I try to start exmh with 'wish', it takes forever to launch, but starting it with 'wish' from another location starts immediately using the latest cvs. Second, when I open exmh and navigate to a folder containing unread messages, instead of moving to the first unread message in the current folder, it jumps to the next folder with unread messages. Lastly, when I reach the end of the messages in a folder and move on to the next unread message, exmh always goes back to the Inbox which has no unread messages, rather than moving to the next folder with unread messages. However, if I go to 'next' from the Inbox, it does go where I would expect it to go. I wanted to share these observations and find out if my expectations are incorrect. Thank you for your hard work on exmh."
   }, {
     "body": "Chris Garrigues, I have a vague idea about when I might be able to attend to it. The phrase 'hell freezes over' seems more plausible at the moment, but whenever you need me will certainly work. Thank you for your patience in the meantime. I've adjusted the minimum entry lines so it won't prompt me to revert back to the old version."
   }, {
        "body": "Subject: Issues with Exmh on my system\n\nI've encountered some issues when using Exmh on my system.\n\n1. When I run Exmh with wish from one location, it seems to take forever to start, but with wish from another location, it starts in a snap. This might be an issue with the piggy code in the flist, as flist in general is taking seconds which is interesting.\n\n2. When I open Exmh and navigate to a folder that has unseen messages, hitting 'next' changes the focus to the next folder with unseen messages rather than the first unseen in the current folder. This appears to be weirdness.\n\n3. When I reach the end of the messages in a folder and go on to the next unseen, Exmh always goes back to the Inbox which has no unseen messages. Instead, it should move to the next folder with unseen messages. However, when I go to 'next' from the Inbox, it does go where I would expect it to.\n\n4. I usually observe this issue with the Inbox, but it's also been stuck on some other folders as well.\n\n5. I use Procmail for rcvstore into folders and have noticed this behavior with Exmh. Valdis Kletnieks, Senior Engineer at Virginia Tech, is using a similar application (pgpsignature not included in the description).\n\nRegards,"
   }, {
      "body": "Dear Chris Garrigues,\n\nI have made a change to my email client settings from 'flistfindunseen' to 'flistfindseqsi'. It seems I was more sleepy than I thought and inadvertently pasted the wrong content into the bindings definition dialog without noticing that it differs from what is in my exmhbindings file. Can you point me towards a freeware Tcl/Tk debugger? Also, would you be able to provide information about the 'exmhworkers' mailing list where I can discuss further issues related to this email client?\n\nBest,\n[Your Name]"
   }, {
      "body": "It appears that restarting EXMH was likely unnecessary for the future. Next time, try clicking on the folder name in the sequences window for the sequence that is requested. If the sequence does not exist, it will be cleaned up automatically. It might be nicer if flist could perform this task as well, but this method seems effective enough for kre. This has been discussed on the EXMH workers mailing list."
    }, {
      "body": "It seems I accidentally saved a draft of my email last night and didn't send it. I haven't had a chance to look into it today, but I have updated the code using 'pickmarkseen' and 'pickids' as an alternative to 'robert seqdel'. I've also pulled down the latest from CVS and am running with it. However, I miss the blue FToc lines which I will sort out soon, as per Chris's suggestion that it's a simple resource change. Ted and I were not particularly up-to-date, but I have fixed most of Chris's code. It appears to be working now, except for the highlighting on the FToc which I will address later. If anyone has any suggestions or clues about fixing this issue, feel free to share. Additionally, I found that my sequences are rather cluttered and plan to tidy them up. I'll keep you updated."
   }, {
    "body": "Dear Dag Nygren, \n\nI understand that you've successfully configured Procmail to ring a bell whenever a new email arrives in your inbox, excluding mailing list spams. Now, your requirements have expanded as you frequently use your laptop remotely and wish the bell to sound when you are connected. \n\nYou've attempted to use the KDE Remote Sound Server, but it works only during tests and fails when Procmail runs due to lack of authorization to communicate with the laptop as another user. I am writing to seek your advice on this matter.\n\nKind Regards,"
    }, {
    "body": "Dear User,\n\nOn Tuesday, October Dag Dag Nygren encountered an issue where procmail didn't seem to run as expected. This appears to be due to the fact that dag doesn't have authorization to communicate with the dag laptop when running as another user. I am not familiar with the KDE sound server, but I suspect your problem lies in the environment where procmail runs. You do not specify where procmail is being run from in this case; for instance, it may be run by fetchmail which operates through a cron job. Please note that in my situation, procmail is utilized by the qmail delivery agent to sort all incoming mail. However, I discovered an error message in procmaillog that resolved the issue. The following line in my delivery script seems to function properly: artsplay.\n\nRegards, Dag Ex-husband's Mailing List"
   }, {
      "body": "In response to your message, Ulises Ponce suggested a method to insert a signature using specific keys within the NMH components (replcomps, forwcomps, etc.) without having to send the email first. This can be achieved by altering the component files for specific folders, which allows you to modify your signature per folder. Ulises also mentioned some tricks detailed in the NMH documentation. He further noted that there might be a way to get sedit to perform this task, but he has been using gvim as his exmh message editor for quite some time now. With a command, he loads email-specific settings and syntax color highlights headers and quoted parts of an email. Additionally, he suggested mapping VIM keys that would add a signature or provide a selection of signatures to choose from. Lastly, Ulises mentioned the possibility of randomly selecting signatures somewhere in RTF format. This information is intended for exmh users mailing list."
   }, {
    "body": "I have implemented the changes to the unseen sequences and installed them, however, I encountered one major issue. Instead of using the exmh icon, I use the unseen window, and with the new code, I can't seem to determine the number of unseen messages when I have the main window open. This is not crucial since I don't require it most of the time, but it would be helpful to know if possible. The code was borrowed from 'unseenwin', though I haven't tested it as I don't utilize that functionality. I will ensure to check this issue on my list. Regarding the unseenwin functionality, please consider it on your to-do list. Chris Garrigues Vircio Congress Suite Austin TX World War - The Wrongdoers vs The Evildoers Application"
   }, {
    "body": "Chris Garrigues, I would like to vary the background color in this window from that of the FTOC. The background color in the FTOC is not constant and messages in the unseen sequence have a different background than others in the FTOC. However, in the sequences window, this is not necessary as unseen already has a different foreground. There's no problem with that, it doesn't need a different background as well. I will experiment with making it vertical instead of horizontal and see what turns up. The only sequences defined there are those which are defined in appdefaultscolor or exmhworkersdefaultscolor. I have been thinking about dynamically generating highlighting for other sequences but haven't figured it out yet. In this case, highlighting wasn't my primary concern, a method to get messages out of sequences comes first. However, as a suggestion, any unknown sequence could highlight any message in a sequence which has no defined highlighting. Maybe something as simple as a dark brown text color almost indistinguishable from normal black. I made the current message a little brighter. The most significant change came from changing relief from raised to sunken. However, even with that, cur and unseen are still too similar. I ended up using background palegoldenrod, relief sunken, borderwidth. Some of the colors I was using had spaces in their names, so I used 'palegoldenrod' which translates to a safer generic name. This was sent on the exmhworkers mailing list."
   }, {
           "body": "Just checked, and I'm experiencing similar slowness with handling large unseen message sequences in Catchup. It appears that the code might be reading the sequences file multiple times unnecessarily. I need to enhance the code's intelligence in managing this file before optimization can take place. However, I have other priorities in my current patch. There's no cause for panic as I plan to clean things up before optimizing. Unfortunately, the recent fix didn't seem to improve the speed; it may be slightly faster than yesterday, but still slower than a month ago. The log shows an unseen countdown for the 'homeandermaillistslkmhsequences' list, which has messages in the 'unseen' list. I've observed this issue with other lists as well. Additionally, the digit sequence in the 'listslk' seems to be changing. Folder change, EXMH msgshow, curexmhworkers, and mailing list commands are working fine."
        }, {
    "body": "Anders Eriksson, on Thursday, August [date], I've just updated the CVS and am currently catching up on unseen messages which is extremely slow for large messages and unseen sequences. It seems like this issue is affecting others as well. I suspect that we are needlessly reading the sequence file multiple times due to other sequences. I will make the code much smarter about handling that file, but first, I have a few other tasks in my large patch that needs attention. There's no panic, I'm all for cleaning things up before optimizing it. The fix for this issue has been checked in, but unfortunately, it didn't help as the speed seems to be slower than last month, albeit slightly faster than yesterday. I'm still seeing an unseen countdown in the log. 'catchup unseen' is something I don't use frequently, but I can reproduce this issue and will look into it. It's likely a simple problem."
   }, {
     "body": "I'm experiencing issues with the application as it doesn't work at all, and I encountered this error on startup and while attempting to change folders which fail. The error message reads: 'doesn't work at all', 'cannot read no such element in array', 'invoked from within incr flistseqcountfolderseq delta procedure seqdel line invoked from within seqdel', 'exmh folder mhprofile unseensequence msgid procedure msgseen line invoked from within msgseen', 'msgid procedure msgshow line invoked from within msgshow', 'msgid procedure msgchange line invoked from within msgchange', 'show invoked from within time list msgchange msgid show procedure msgchange line invoked from within msgchange msgid show procedure msgshow line invoked from within msgshow', 'cur eval body line invoked from within eval msgshowproc procedure folderchange line invoked from within folderchange listsexmh msgshow cur invoked from within time list folderchange folder msgshowproc procedure folderchange line invoked from within folderchange exmh folder procedure exmh line invoked from within exmh after script exmhworkers mailing list.'"
   }, {
    "body": "In your message, you suggest using component files for signatures but want to switch between different ones using a keyboard command. This is possible with exmh if you are open to using a mouse for such tasks. To set up multiple signatures, create numerous files starting with 'signature' and at startup, exmh will load them all in the sedit window. A 'signmenu' item will allow you to select the desired signature file for each email. Multiple signatures can be used if needed, though I'm not certain about the specific preferences option for this. The signature is added upon sending, not directly inserted into the existing sedit window prior to composition. Additionally, if a signature file has the execute bit set, exmh will attempt to execute the script and use the stdout of the script as your signature. Hopefully, this clarifies things."
   }, {
      "body": "Dear Paul,\n\nThank you for your message. I understand that you'd prefer not to use a mouse for inserting signatures in your messages and would like to know if it's possible to do so using keyboard commands. In the context of Exmh, it is indeed possible.\n\nExmh allows you to create multiple signature files, each beginning with 'signature'. Upon startup, Exmh will load all these files in the Sedit window. A 'Sign' menu item will appear, allowing you to select from the listed signature files for each email. You can even use multiple signatures if needed, though I'm not certain about the specific preferences option that enables this.\n\nHowever, please note that the signature gets added on send, not inserted directly into the existing Sedit window before composition.\n\nI see you already have different sig files to choose from. Additionally, if a signature file has the execute bit turned on, Exmh will attempt to execute the file and use the stdout of the script as your signature.\n\nHope this helps!\n\nBest regards,\nUlises Ponce"
   }, {
       "body": "I've just received and read your email. I was reading it in a rather dim room, with my keyboard mainly illuminated by the light from the laptop screen. I think I may have accidentally hit the wrong keys, as I mostly use the keyboard while running exmh. The fixes for the issues mentioned yesterday are included in today's CVS update. Initially, I had trouble connecting to the CVS server and received an unexpected 'expected integer but got while executing incr m procedure'. Here's a breakdown of some of the procedures involved:

         1. mhseqexpand line invoked from within mhseqexpand folder
         2. seq how oldmsgids msgids procedure mhsequenceupdate line invoked from within mhsequenceupdate folder
         3. replace seq msgids procedure seqset line invoked from within seqset folder
         4. cur msgid procedure mhsetcur line invoked from within mhsetcur
         5. exmhfolder msgid procedure msgchange line invoked from within msgchange
         6. noshow invoked from within time list msgchange
         7. msgid show procedure msgchange line invoked from within msgchange
         8. selectsel noshow procedure selecttypein line invoked from withinselecttypein
         9. midrig command bound to i have the sequences window vertical instead of horizontal and all colors from the ftoc stuff are deleted. It currently looks almost as bad as the old, unseen window used to look. I still need to do some work to make it more presentable. Listboxes appear to have some odd behaviors, and eventually, I aim to make everything optional and parameterized. At the moment, I'm just embedding stuff in the code for quicker prototyping. Once completed, I will send a patch for review.

   I will post this on the exmh workers mailing list."
   }, {
    "body": "I am currently performing tasks using Exmh Ponce Paul, but I'd like to avoid using a mouse for such operations. The best solution I can think of is to determine the Tcl command that selects and inserts the signature within Exmh, then bind it to a key sequence. This shouldn't be too challenging, it just requires figuring out the Tcl script, which my Perl-based brain isn't particularly thrilled about. I know I might appear idle, but I am actually waiting actively for all my problems to resolve. If you're not enjoying yourself, then you're not doing it right. Regards, Exmh Users Mailing List."
   }, {
        "body": "Anders Eriksson apologizes for the issue with charsetusascii not working at all, which occurred during startup and on any attempt to change folders, which also failed. He has already checked it and found that the problem persists even after you had initially checked it out. He hopes that he was quick enough so that you would not notice this issue before receiving this email. Please try again."
   }, {
    "body": "I apologize for any inconvenience, but I encountered an issue on Thursday where the application doesn't work at all upon startup and when attempting to change folders, which fail. After realizing this, I checked it out in the app before sending you this message, hoping I was fast enough that you wouldn't see it. However, after your check, everything seems to be working fine now, as if the box was on some sort of drugs or something. While testing, I accidentally selected my favorite folder 'lk' and marked messages as unread, which took a long time or about as long as catchup unseen did before any changes."
   }, {
     "body": "Dear Anders Eriksson,\n\nI apologize for the inconvenience you have experienced with Textplain. Upon startup and any attempt to change folders, it did not function as expected and failed. I had already investigated this issue and found that it was occurring before sending this message. However, I am glad to report that after another attempt, it now seems to be working correctly.\n\nI noticed during testing that selecting my favorite folder 'lk' and marking messages unread took a long time, similar to how Catchup Unseen used to take before any improvements were made. I thought I had addressed all instances of this particular coding issue but it appears there were more remaining.\n\nIf you have any suggestions for resolving this issue or any other concerns, please let me know.\n\nBest,\nChris Garrigues"
   }, {
   "body": "On Friday, August [date], regarding your statement 'this is from today's CVS', this would now translate as 'yesterday's CVS'. Since the most recent set of changes have not yet caught up or completed, it is expected that there may be delays and speedups."
   }, {
       "body": "I'm sorry to hear that you are having trouble checking GPG signatures in EXMH after updating and changing the path. It seems like the issue is that EXMH can't find the public key. Here are a few suggestions:

1. Ensure that the GPG public key has been properly exported and imported into your keyring.
2. Check if the file permissions of the public key allow it to be accessed by EXMH.
3. Verify that the key ID you're using matches the one in your keyring exactly.
4. Make sure the path to the GPG executable is correctly set in the EXMH executable and that it can be executed.
5. Try running GPG manually from the command line with the same key ID and see if you can check the signature successfully."
   }, {
     "body": "I recall fiddling with similar issues in the past, particularly ensuring that no sound was played when the screen was locked or EXMH wasn't running. It might be worth considering this point for discussion on the dagh-alexmhusers mailing list."
   }, {
      "body": "Dear User,\n\nIt appears that Procmail is not able to communicate with the Dag laptop as it does not have the necessary authorization. This issue might be related to the environment in which Procmail runs. In my case, Procmail is run by the qmail delivery agent to presort all mail I receive.\n\nI found an error message in procmaillog that helped me solve the problem. The following line in my delivery script seems to work fine: artsplay (by the way, if you use exmhwrapper found in the misc directory, you can generalize this to displaycat homeexmhdisplay artsplay).\n\nHowever, using exmhwrapper might require having exmh running on the laptop to receive notifications. It seems that exmh gets upset when two instances are running at the same time, which creates a problem as I cannot run to the closest computer to check out the new mail.\n\nThank you for your hint. I might use that for some other hack in the future.\n\nBest regards,\nDag (Exmh users mailing list)"
   }, {
    "body": "When I receive a message with a line starting 'From' that is split into two messages, my mail comes from varspoolmail (the program that incorporates mail). The program seems to think that the 'From' line starts a new message. My system administrators have informed me that the sending mail client is supposed to escape lines beginning with 'From'. However, exmh does not seem to do this. I inquire if using mh or nmh will resolve this issue for exmh users on the mailing list."
   }, {
      "body": "The issue at hand seems to be related to the interaction between Sendmail, Solaris, and MH. The receiving mail server is responsible for escaping lines beginning with 'from' if they choose to enable that facility. However, it appears that your MH (or nmh) is not handling this properly due to its unawareness of rcvstore gags. \n\nThere are a few possible solutions: 1. Get your mail administrator to add the 'e' flag to your Sendmail configuration, which will prevent any lines beginning with 'from'. 2. Learn to use Procmail and invoke rcvstore directly instead of letting Sendmail put your incoming mail into the spool. This method avoids the whole issue as rcvstore deals with a single message at a time.\n\nJim McMaster suggests that there was a patch for MH to respect this, but it might not have been ported to nmh during its development stall. You can check with the nmh list at to find out if it has been done.\n\nIt seems that the sending mail client is supposed to escape lines beginning with 'from', and exMH should do this. If it's not, it might be a configuration issue that needs to be addressed."
   }, {
     "body": "According to my sysadmins, there seems to be an issue with the mail client Jason J. Rennie's configuration. They mentioned that lines beginning with 'From' in the mail should be escaped. This is presumably handled by the local mail delivery agent (MDA) storing the mail into the braindead mailbox file called var/spool/mail[username]. It appears that the program responsible for this, referred to as the local MDA, is incorrectly handling lines that start with 'From'. They suggest that it would be ideal if you avoid storing your mail in a mailbox file altogether. If your sysadmins are capable, they can set up the Receiving Mail Transfer Agent (MTA) to allow the use of Procmail as the local MDA. This way, Procmail could be used to invoke rcvstore and deliver your mail directly into your mh mail folders. Most Linux systems come pre-configured in this manner if a user has a .procmail file. The mail would then be delivered using Procmail."
   }, {
       "body": "This issue is not related to exmh, but rather an interaction between Sendmail, Solaris, and MHcorrectJames. Your sysadmin is incorrect; it is the responsibility of the receiving mail server to escape lines beginning with 'from' if they choose to turn on that facility. It is not the responsibility of email clients to cater to the design flaws of the Unix mail spool or Sun's decision to rely on it instead of dealing with this problem directly since MH is unaware of rcvstore gags. Trying to parse messages from the spool also causes issues in fairness, but I cannot defend the header as I consider it extreme brain damage inherited from ATT. The solution is for your mail administrator to add the 'e' flag to your Sendmail configuration. This means you will never see a line beginning with 'from'; such lines will look like 'from specifically. You can find the relevant line in /etc/mail/sendmail.cf that starts with 'mlocal'. Use grep 'mlocal' /etc/mail/sendmail.cf to locate it. If your sysadmin uses this to generate sendmail.cf, any good sysadmin should then implement the following magic line for MH: ednl. You can learn to use Procmail invoking rcvstore directly instead of letting Sendmail put your incoming mail into the spool. This avoids the whole issue as rcvstore only deals with a single message at a time. Additionally, while Procmail per se is not needed, other filters such as local which is part of the nmh distribution do the trick just as well."
   }, {
       "body": "It's possible to learn how to use Procmail, but it appears that forwarding is not an option on your machine due to lack of root access. I understand your concern about approaching the sysadmin regarding Sendmail, as a response may result in the daemon being shut down and being advised to use Outlook. However, let me suggest an alternative: you could explore using web-based email clients or IMAP/POP3 clients that can be installed without root access."
   }, {
    "body": "In regards to Kevin Kenny's message, you can learn to use Procmail, and it can indeed be done by forwarding emails. I am in the same situation as you and this is how I accomplish it."
   }, {
    "body": "This email contains a multipart message signed conforming to GPG or PGP for verification. The text is in US-ASCII encoding and was sent on Wednesday, October [date] at [time]. It appears to be from Kevin Kenny. He suggests that you can learn to use Procmail if you wish to do this. The Procmail binary may reside in a different path. He requests a list of points detailing how technology has failed to improve our lives. For your convenience, I have removed the 'signature' section from the original email.\n\nGPG/PGP Signature:\n\n--\npgp gnupg gnulinux\n--"
   }, {
    "body": "Robert Waldner has emailed Kevin Kenny, suggesting that he can learn to use Procmail. According to Robert, this could be achieved by modifying the forward settings so that it includes 'usr/bin/procmail' (including quotes). The Procmail binary may be located in a different path, so check the Procmail documentation for the correct one. He also mentions some commands: ifs, ppath, toprocmail, test, f, exec, p, fexit. However, he doesn't explain what these do, but they are explained in the Procmail documentation. Jim McMaster refers to the exmhusers mailing list for more information."
    }, {
    "body": "Dear Jason Rennie, \n\nAccording to my sysadmins, the sending mail client is expected to escape lines beginning with 'From' when using the exmh system. However, it seems that in your case, this is not being done. It appears that you are using mh and they suggest that nmh might fix this issue.\n\nHistorically, this problem has escalated into a heated debate among users. The 'From' envelope is an artifact of the mbox mailbox format, and some argue that it should be the mail server's responsibility to escape lines beginning with 'From' when storing mailboxes in mbox format.\n\nHowever, changing the message body contradicts the assumption that the mail transport only modifies the message headers and leaves the message body untouched. Modifications like those made for PGP signatures can break when the mail server alters the message body.\n\nStrictly speaking, the 'From' envelope in the mbox format is not just any line starting with 'From', but rather a specific format: a valid email address followed by a single space, a valid date, and for example: 'From: sun jul john abreau executive director boston linux unix email pgpkeyid pgpkeyfingerprint'.\n\nSome argue that the enemy of one's enemy is one's friend. When elephants fight (referring to the ongoing debate), it is often the grass that gets trampled.\n\nBest regards,\n The Application PGP Signature follows:\n\nPGP Signature: [Application PGP Signature Details]\n\nRegards, exmh-users mailing list"
   }, {
    "body": "Dear Mathias, \n\n I performed the build as per your suggestion, however, there's an issue regarding the switch from pspell to aspell. It seems that aspell is not available in rawhide at the moment, which means spell checking is temporarily disabled until a decision is made about it. I missed updating the webpage and mistakenly posted here before checking it again. I apologize for that. \n\n Building recent aspell packages may not be upgraded when moving to the next Red Hat Linux release, which might not be desirable. I will test this out and see. \n\n By the way, I have been following the thread in the sylpheedclaws list, it's very informative. The update on aspell in Red Hat is something I will keep an eye on. Your help was indeed useful to our rpmlist mailing list. Jesse Keating and the mondo devteam appreciate your contributions."
   }, {
     "body": "Dear Matthias Saou,\n\nPreviously, Jesse had mentioned that he would update his build as soon as the source is updated. The source has now been updated, consequently, so has his build.\n\nHowever, there seems to be an issue with the change from pspell to aspell, which requires aspell, a package not currently available in rawhide. Therefore, spell-checking is temporarily disabled until a decision about it can be made.\n\nIn addition, the spec file has undergone a significant update. The options for rebuilding source packages without and with different settings are now listed in the description.\n\nLooking forward to your next update,\nBest Regards"
   }, {
     "body": "Back then, Jesse mentioned that he was observing a discussion on the sylpheedclaws list, finding it intriguing. He suggested he might continue to follow it until Aspell gets updated in Red Hat, which could take months or more given that the freeze on package versions for the next stable release has likely already occurred. As a precaution, if it doesn't cause any issues, Jesse may consider releasing recent Aspell packages, but he will need to perform some testing first. Matthias, a system and network engineer based in Barcelona, Spain, mentioned that he would check on the rpmlist mailing list."
   }, {
    "body": "Hello,\n\nFirst, please retrieve the files and then configure them on Friday at Axel Thimm. I was wondering if anyone knows the reason why the mplayer documentation still suggests using these for certain architectures.\nRegards, Axel\nOn Saturday, June at Axel Thimm,\nIs there perhaps a licensing issue or any other reason that would forbid such a practice? The reason I ask is that I have noticed performance and feature differences (such as fullscreen display without keeping aspect ratio, visual artifacts on Nvidia) comparing with or without the codecs. It seems that the mplayer authors recommend using these for certain architectures. However, I am not an expert on mplayercodecs, so I may be completely lost.\nRpmlist mailing list"
   }, {
      "body": "Hello everyone, I've uploaded the RPMs for the newly released Netatalk. Given that this version resolves an issue with saving files via Illustrator, which I've been eagerly awaiting, I thought it might be of interest to you here. These RPMs will be mirrored on rpmfind.net by tomorrow. By the way, Troy Engel - Systems Engineer, is as cool as the other side of a pillow. This information will also be shared on the rpmlist mailing list."
   }, {
    "body": "Hello Thomas, \n\nWelcome to the rpmlist mailing list! I understand that you are new here and seeking information about recompiling a working apt RPM for null or psyche. If you need good GStreamer packages completed by Monday when it's released, please share more details so we can help you better. \n\nI noticed that some posts related to the GStreamer repository were made on this list, but I'm not certain why they appeared here. As the RPM maintainer, feel free to ask any questions you might have. \n\nRegarding your query about getting an updated apt RPM, it seems the port is closed. If Dave reads this message, kindly let us know where we can obtain the updated RPM. Thanks in advance for your cooperation.\n\nBest regards,\n The rpmlist moderator team"
   }, {
    "body": "Thomas wrote previously that he intended to discover who had recompiled a functional apt RPM for null or psyche. He wishes to complete good GStreamer packages by Monday when it is released. Currently, he has a working apt package for Red Hat Linux which will be available simultaneously with the distribution release and also an entire apt repository, already including numerous of his updated packages for Red Hat Linux. Thomas did not want to disclose all this before Monday, but since the new release has leaked from multiple sources and official statements have been made about it, he doesn't consider it a big deal. He will keep everyone posted on Monday, and there will be a significant apt-related surprise."
   }, {
      "body": "Hi there,\n\nRed Hat release is tomorrow, Monday. I've spent some time to create RPMs of gstreamer for it. All core plugins and player have been uploaded to the apt repository in a new directory. The dependency repository remains as 'deps', while the one for the gstreamer RPMs is now named 'redhat'.\n\nThe base distro this time includes all necessary packages, so you shouldn't need any additional installations.\n\nPlease find a screenshot of red hat running gstplayer at the provided link. However, there are some known issues with the resulting RPMs:\n- gstreamernautilus was not built as its package got renamed and I don't have a devel package for it yet.\n- The c plugins encounter problems that I haven't been able to resolve yet.\n  - The info plugin 'usrlibgstlibgstwincodecso' failed to load due to undefined plugins 'usrlibgstlibgstwincodecso', 'usrlibgstlibgstmodplugso'.\nI'm not sure how to fix this issue, but running strings on the libs in usrlib reveals that there are other libs that have these symbols. There must be a straightforward solution to resolve this. If anyone has any suggestions, please share. I'm Thomas from the davedina project 'future tv today'.\n\nSincerely, Thomas"
   }, {
     "body": "Hello Thomas, \n\nI'm writing to inform you that the usrlibgstlibgstwincodecso plugin has failed to load due to an undefined error. It seems that the issue might be related to linking issues, as it appears not to be connecting to a required library somewhere. I'm unsure about the specific library it should be preloading, but here are some steps you could take to find out:\n\n1. Check if the plugin and its dependencies are using the same version of GCC for compilation.\n2. Ensure that everything is built within a chroot environment.\n3. If the problem persists, try debugging to find out which library it's unable to link with. \n\nI hope this helps! Regarding the DavaDina project - Future TV Today, your urgent input would be highly appreciated if you have a moment."
   }, {
        "body": "Dear Thomas,\n\nOn September, you mentioned an issue with the plugin 'usrlibgstlibgstwincodecso' not loading due to undefined symbols. You confirmed that you are using the same version of gcc as its C dependencies and that everything is built inside a chroot environment. However, it appears that it is not linking to a library somewhere, but you're unsure which one.\n\nTo determine which library it is, it seems like there might be an issue with avifile since you've been unable to recompile the latest version successfully.\n\nRegards,\nMatthias Saou (System and Network Engineer)\nBarcelona, Spain\nInteractive Phone: rpmlist mailing list"
    }, {
    "body": "The plugin 'usrlibgstlibgstwincodecso' failed to load due to an undefined library. I am using the same version of gcc to compile the plugin as its C dependencies. I suspect it is not linking to a lib somewhere, however, I am unsure which one it should be preloaded with. To find out, it appears that there might be an issue with the avifile library you've rebuilt. I have been unable to recompile the latest version successfully inside the same chroot. However, aviplay works well and I encounter X errors when trying to run it without xv (although it doesn't complain about linker problems). This suggests that my avifile library might be compiled correctly. Despite the difficulties with avifile, I should mention that it is one of the most problematic packages in terms of naming of tarballs, versioning of libraries, and API stability. The Thomas the Dava project (future TV today) left me floored when I needed help, and even though the feeling has passed, I can't seem to let go. If I had the love it takes, I would change. Lastly, the radio on your rpmlist mailing list is one of the best on the internet."
    }, {
       "body": "Dear Peter Peltonen, I've just come across a quite nice looking apt repository for various audio applications. It appears to be a comprehensive collection in the field of audio apps. This discovery was made on the rpmlist mailing list, often referred to as 'Angle in Geometry'. Best regards."
   }, {
     "body": "Dear All,\n\nThe Freshrpmsnet is now prepared for the upcoming release of Red Hat Linux. I want to express my gratitude for all your hard work, it's simply fantastic!\n\nI plan to post to the list once I open up the ftp server at freshrpmsnet, allowing you to be among the first to download.\n\nAlthough I believe you won't face any trouble finding a fast mirror using my mirror list, I thought I should mention it. Also, there are mirrors available for the apt repo on Sep at Matthias Saou.\n\nI'll keep you all updated on Monday, and there will be an apt-related surprise in store. It seems there might be more surprises to come, so stay tuned!\n\nThanks,\nMatthias"
   }, {
    "body": "I was contemplating returning to creating mods, and it's great to see Aptgetable Soundtracker mentioned. By any chance, do you know where I can find a good variety of sample loops? On Monday, I would appreciate recommendations from Angelo Puglisi, who has an extensive audio app collection. Thank you in advance! If my response appears overly human, it's merely because I may have been misunderstood. I subscribe to the Dream Theater RPMList mailing list."
   }, {
      "body": "Dear All, \n\nI would be grateful if you could procure the gabber packages for Red Hat as I am preparing for a new release soon. Even though I may not need them immediately, I would appreciate having them on hand. I'm aware that during the beta testing of Red Hat, they were using a modified version of gnomelibs which is incompatible with the latest gnomemm. If this is still the case, I can provide you with a patch that makes gnomemm functional again.\n\nRegards,\nJulian\n\nP.S. We are now setting up freshrpmsnet for the upcoming release of Red Hat Linux. Unlike previous releases, the process has been less secretive due to some leaks, including a mirror purposely left open. For more information on the release and the leaks, please refer to this article: [article link].\n\nWith the files no longer a secret, they will be available later today for Americans (afternoon for Europeans) from our mirrors. We already have several freshrpmsnet packages prepared for download, although they are not yet accessible.\n\nNew freshrpmsnet package list: [package list link]\n\nOf course, APT is also available now and has been thoroughly tested if you prefer it for your desktop machines. I would also recommend checking out the new Synaptic package as it has been ported to GTK and seamlessly integrates with the distribution.\n\nI will likely post to the list once I open up ftpfreshrpmsnet, allowing you early access to download these packages. However, I don't anticipate any difficulties finding a fast mirror using my mirror list. Have fun with Red Hat Linux!\n\nBest regards,\nMatthias\n\nCustom Red Hat Linux rpm packages: Red Hat Linux release 'Valhalla' running Linux kernel load:\n\nRPM list mailing list"
   }, {
    "body": "Hello, I have reviewed your query. The new apt releases are suitable for use on ReiserFS file systems, as it is well-defined that reiserfsck will return a usable system. However, one might expect some remaining data after the process, and Felix V Leitner discussed this on the rpmlist mailing list."
   }, {
      "body": "Subject: Inquiry about alsa dependency and mplayer packages\n\nDear RPM list,\n\nI recently noticed that the directory for FreshRpms ALSA (alsanull) has been erased since the release of psyche. This led me to worry that the new packages might cause some issues. Specifically, I am concerned about the MPlayer package, as it seems to lack options for Vo and Ao. I have two questions:\n\n1. Is the absence of ALSA in rh causing this issue with mplayer from FreshRpms, or are there switches to enable these options during rpm build?\n2. For my recent packages that support both with and without options, I've listed them in their description section (e.g., available rpmbuild rebuild options). Is there a way to include ALSA as an option for all of these packages moving forward?\n\nI've noticed that the ogle package has an 'with alsa' option and I encountered a bug report regarding Xine that was apparently compiled with alsa directly. This leads me to believe that blending ALSA into more packages would be beneficial, especially since I've just spent time recompiling the alsakernel package for all the psyche kernels.\n\nI would appreciate if we could discuss this on the RPM list. Specifically, I am curious about whether adding a new dependency of the alsalib package for many packages (e.g., mplayer, ogle, xine) would cause any problems for FreshRpmsNet users. Any insights or suggestions are welcome.\n\nBest,\nMatthias Saou\nSystem and Network Engineer\nBarcelona, Spain\nelectronic group interactive phone"
   }, {
      "body": "Ralf, regarding your email about the new apt releases on Rh and potential issues when rebuilding packages for Psyche on Valhalla, you expressed concern that lowering the tag to keep an upgrade working might complicate your CVS repository, which is located on your Valhalla box. While there are solutions to mitigate this problem, you prefer waiting until you upgrade your main box to Psyche and using Valhalla only on a secondary rebuild system. This approach will be taken under the system and network engineer role at the World Trade Center Edificio Norte in Barcelona, Spain, electronic group interactive phone: rpmlist mailing list."
   }, {
    "body": "Dear Matthias Saou, \n\nI understand that when rebuilding your recent packages for Psyche on Valhalla, you're concerned about lowering the tag to ensure an upgrade works. However, this action might cause issues with your CVS repository located on your Valhalla box. My apologies if my initial message wasn't clear. To clarify, it seems you're questioning the need for a release tag decrease. I would like to emphasize that proper communication and understanding are crucial in our community, so please do not find my question presumptuous or impolite. I look forward to your response."
   }, {
       "body": "Dear RPMList, \n\nMatthias Saou would like to inquire about a potential issue regarding the addition of a new dependency for the alsalib package, particularly for packages such as mplayer, ogle, and xine. He is considering incorporating ALSA into these packages, given his recent efforts in recompiling the alsakernel package for various psyche kernels. However, he lacks extensive knowledge about ALSA and uses custom kernels on many machines. \n\nHis concern is that if this change necessitates using the shipped kernel, he might be against its implementation as a default. In such a scenario, to run applications like mplayer, for example, would it be necessary to first compile a custom kernel option or module? If so, would this mean that packages like alsalib and others would not install since they require the alsakernel package? \n\nIn essence, Matthias is seeking clarification on whether this change could potentially cause issues for freshrpmsnet packages users. Any insights are appreciated.\n\nBest regards,\nTroy Engel, Systems Engineer"
    }, {
       "body": "Subject: Request for Discussion on RPM List Regarding alsalib Dependency\n\nDear RPM List,\n\nIn reference to Hesty's previous email, I would like to clarify the rebuild options when using rpmbuild. When rebuilding the package, if you choose 'alsa', you should simply run 'rpmbuild rebuild srcrpm with alsa'. If you are missing dependencies required for the selected options, you will be informed (for example, for alsa, you'll need alsalibdevel).\n\nI would like to discuss a potential new dependency of the alsalib package for many packages such as mplayer, ogle, and xine. I am keen on integrating alsa now, especially since I have recently spent time recompiling the alsakernel package for all the psyche kernels.\n\nHowever, there is a problem with alsakernel that every time Red Hat issues a new kernel update, I need to rebuild my alsakernel to match the new kernel. This can be inconvenient as I have to do it each time.\n\nRegards,\nMatthias Saou\nBarcelona, Spain\ne-mail: matthias@example.com\ntel: +34 934 567 890"
   }, {
    "body": "Hi Matthias Saou, I believe the issue you're experiencing is due to having two packages installed, one with the same version, but different dependencies. This is causing a conflict. To avoid such issues in older distributions, I usually keep package versions lower. However, it seems this isn't an issue here as you mentioned. Since it's a non-issue, I will rebuild locally. The phrase 'for eats anything and is fond of children' seems to be unrelated to the topic at hand, but it sounds like an interesting dog quote!"
   }, {
     "body": "Dear Matthias Saou, \n\nIn your previous email regarding rebuilding packages for Psyche on Valhalla, you expressed concern about having to lower the tag which might cause issues with your CVS repository. I understand your worry that this could disrupt your Valhalla box's CVS repository. However, let me clarify a few points.\n\nIt appears that your confusion stems from the package versioning and dependency conflicts when upgrading from an older distribution to a newer one like Psyche. When you rebuild a package for Valhalla, if you upgrade to Psyche using the Red Hat CDS or APT-GET update with a new Psyche repository, the system might identify two packages of the same version but different dependencies. This is where the problem lies: it will display both the installed and the available package with the same version but different dependencies.\n\nTo avoid this issue, you usually keep package versions lower for older distributions as a precautionary measure to prevent such dependency conflicts during the upgrade process. This ensures a smoother transition without encountering any errors related to incompatible dependencies.\n\nI hope this clarifies your concern about versioning and dependency issues during the upgrading process. Best regards, [Your Name]"
   }, {
       "body": "Is it feasible to utilize the new APT for a null-to-null upgrade even though there might be an option? I'm wondering if there are compelling reasons why I should refrain from doing so and instead opt for the RedHat ISOs. It seems unlikely that an upgrade would occur when starting from null, as in geometry, with regards to the rpmlist mailing list."
   }, {
      "body": "It appears that you are considering upgrading from a beta version of your system to the latest released version using 'new apt'. However, it's important to note that Red Hat does not officially support such an upgrade. This doesn't necessarily mean it won't work; rather, it implies that no one has tested it or fixed any issues to make it function properly. If you choose to proceed, you would be doing so at your own risk. \n\nHistorically, major number changes in Red Hat releases imply significant modifications have been made, which can potentially cause problems during an upgrade from any previous release. Consequently, most users typically install a new release from scratch rather than performing upgrades. If you wish to avoid potential issues, I would recommend reinstalling the system. As for the Davedina project: Future TV today, every time she sneezes, it seems like love, and you mentioned that you're not ready for this kind of thing - take your time! Lastly, the radio station you mentioned sounds fantastic!"
    }, {
    "body": "I recall successfully using apt-get dist-upgrade on Tuesday, October 18th (Thomas Vander Stichele's date). It might work again. If I appear overly human, it's because I may have been misunderstood. For the record, I am a subscriber of the Dream Theater rpm-list mailing list."
   }, {
       "body": "Dear all, \n Mark previously wrote about upgrading a system using 'apt-get dist-upgrade'. I have also performed this action on several production servers. However, there's an essential detail to consider: replacing 'kernelheaders' with 'glibc-kernheaders'. This is achieved by running 'apt-get install glibc-kernheaders'. \n\n Upgrading between releases should work fine, but upgrading between betas or from a beta to a final release is not recommended due to some packages potentially being downgraded or rebuilt with the same versions but different dependencies. Such upgrades through apt or similar tools might not function correctly because older packages could be considered as the newest and kept on the system - much like Red Hat does. \n\n I strongly advise against attempting to upgrade between betas or from a beta to a final release. It's safer to make a backup of your home, etc., root, and /usr/local directories (if necessary) and perform a clean reinstallation instead. This will likely reduce potential complications and provide the most pristine system.\n\n Regards,\n Matthias Matthias Saou \n World Trade Center Edificio Norte Planta System and Network Engineer \n Barcelona, Spain \n electronic group interactive phone : rpmlist mailing list"
    }, {
       "body": "Dear Angles Puglisi, \n\nIt seems that you had a difficult experience upgrading your laptop from null using apt. You mentioned issues such as a corrupted rpmdb and the upgrade not being smooth due to changes in the system and apt's handling of dependencies. However, you also mention that you successfully upgraded both your laptop and home box without encountering any issues. \n\nYou ask if there are good reasons why you should not do it and just use the RHEL isos instead of upgrading from null. While it is technically possible to upgrade from null using apt, it's important to note that it's not officially supported by Red Hat. So, I would advise caution when proceeding with this method.\n\nRegarding your post on the rpmlist mailing list, it seems that you shared your experience and others have also successfully upgraded from null using apt without encountering issues. I hope this information helps!\n\nBest regards,"
    }, {
     "body": "Dear Team, \n\nPreviously Julian mentioned that he needed Gabber packages for Red Hat as he was planning a new release soon. However, even in the interim, the packages would be acceptable. He also pointed out that Red Hat was using a modified version of gnomelibs which is incompatible with the latest gnomemm. If this issue still persists, Julian can send a patch to make gnomemm functional again. \n\nCurrently, he is facing another problem: libsigc is no longer included in the distribution and gtkmm won't compile without it. It seems he will have to repackage it himself, assuming it's possible. \n\nRegarding the custom Red Hat Linux RPM packages, Julian is referring to the Red Hat Linux release 'Valhalla', running a Linux kernel with the rpmlist mailing list."
   }, {
   "body": "Does providing the srcrpm help in diagnosing the issue, Matthias? I'm assuming you've successfully built a custom Red Hat Linux RPM package for libsigc. However, when attempting to rebuild on 'a' and 'la' files, you're encountering problems because the required so libraries are missing. Could the problem possibly be related to the RPM build process or dependency resolution? I suggest checking the dependencies of your custom package and ensuring that all necessary libraries are included."
   }, {
    "body": "Dear Matthias Saou,\n\nI would advise against attempting an upgrade between betas or from a beta to a final release. It's recommended to backup your home directory, root directory, and any necessary files under /usr/local before performing a clean reinstall. This should minimize potential issues and provide the cleanest system possible. The reason for this recommendation is that during upgrades, not all latest features might be automatically enabled in some config files due to Red Hat's cautious approach, resulting in rpmnew files instead of rpmsaved.\n\nRegarding your backup concern, if you don't have a box with a large hard drive for network backup, you could consider using cloud storage services or an external hard drive. If you do not wish to re-rip all the media files, you may keep them on the original CDs as a backup copy.\n\nHope this helps,\nBest Regards,"
   }, {
     "body": "Dear Matthias Saou,\n\nI would recommend against upgrading between betas or from a beta to a final release. It's best to backup your home directory, root and usr/local if necessary, then perform a clean reinstall. This method should save some hassles and provide the cleanest possible system.\n\nI believe this is the most effective approach because upgrading may not always enable the latest features in some configuration files as Red Hat prefers to avoid updating those files to reduce support calls.\n\nIn case you are dissatisfied with Red Hat, I would encourage you to consider its benefits, such as not overwriting your config files on a whim. It's better that they do not perform automatic detection and changing of configurations. Instead, they inform you about the necessary configuration files during an rpm upgrade.\n\nRegarding your concerns about backing up large data networks, if you don't have a box with a tape drive, you could use one with a large hard drive with plenty of free space to store the backup. If you don't have access to such a computer, you should make backups using an NFS or SMB mount from another machine and rsyncing straight to the mount. If that's not possible, you can use rsync over SSH as it's the best method for making backups.\n\nYour media files are already compressed, so compressing them again would be redundant. In case your media files are backed up on the CDs they came from, it's actually the other way around - the CDs are backups of your media files.\n\nBest regards,\nThomas"
   }, {
      "body": "Dear Matthias, \n\nI am writing to propose a modification to the alsa driver spec that facilitates a clean build under a mostly Red Hat system when the kernel is manually configured and built. I understand that the freshrpms.net packages are designed with standard Red Hat in mind, including a standard kernel RPM. However, I hope you will consider this small tweak as justified for incorporation.\n\nAttached below is the diff outlining the changes. The first part of the diff includes a conditional that checks for the presence of the expected rpm. If it is installed, karch and krpm flags are set as before, but if not, karch uses uname p while krpm remains undefined. The second part of the diff requires the kernel source to be installed only if the kernel comes from an RPM; otherwise, it is presumed that the user has retained the sources in the expected place.\n\nI recognize that I am operating outside of warranty by not using a Red Hat kernel RPM. If you find this tweak reasonable and aesthetically pleasing, I would be delighted to see it implemented. If not, at least this message will remain in the archives and may benefit others in the future.\n\nBest regards,\n[Your Name]"
   }, {
   "body": "Dear Thomas, Matthias and Saou,\n\nI strongly advise against upgrading directly between betas or from a beta to a final release. To ensure a smooth transition, consider backing up your home directory, root directory and usr/local if needed, then perform a clean installation.\n\nThis should help you avoid potential issues and get the most streamlined system possible.\n\nI'm in the same boat as you - I too have learned my lesson about living on the bleeding edge. No more Ximian for me! Lesson learned.\n\nAs for upgrading, if you need RPMs, I'm not opposed to this but 'apt-get dist-upgrade' can cause issues. To find the ISO, just search mirrors and proceed with the installation.\n\nBest regards,\nBrian Fahrlender, Linux Zealot, Conservative and Technomad Evansville"
   }, {
      "body": "Dear All, \n\nPreviously, Ben shared his configuration for building a custom kernel on Red Hat systems. He suggested a modification to the alsadriverspec that helps in creating a clean build under such circumstances. Ben recognizes that freshrpmsnet packages are designed with standard Red Hat in mind but he hopes Matthias will consider incorporating this tweak as it is small enough to justify its inclusion. \n\nBen expresses that it doesn't seem consistent to use an rpm package built against something that wasn't installed through rpm. He recommends maintaining at least one original Red Hat Linux kernel for emergencies, installing the matching alsakernel package due to dependencies, and then following these steps for the custom-built kernel: configure with 'make all', 'make install', 'depmod' as root, copy all the modules under 'tmpalsadriver/libmodules' to your 'modules' directory. Additionally, he advises not compiling unnecessary drivers to speed up the process. This method, according to Ben, is the easiest and cleanest way to resolve this issue. He has been following this approach on his laptop where he runs a kernel recompiled with ACPI and custom Red Hat Linux rpms. \n\nBest regards,\n[Your Name]"
   }, {
    "body": "Matthias Saou, I understand your concerns about inconsistency when using an RPM package built against something that wasn't installed through RPM. To address this issue in your case, I have devised a simpler approach involving a small kernelspec. This spec installs no files but claims to produce a kernel package with the version number matching uname -r for architecture uname -p. It also provides kernel sources at the same version, which should satisfy alsadriverspec and provide a reasonable representation of what your homemade kernel offers to the system. I wish I had thought of this approach sooner."
   }, {
    "body": "Brian previously mentioned that he had to address an issue due to his experience with Ximian, a lesson learned never to live on the cutting edge. He switched to Red Hat (now known as FreshRPMs.net) and kept his root filesystem, home directories, music, and games on separate partitions. However, he encounters a problem where every upgrade requires RPMS, which he is not opposed to but finds apt-get dist-upgrade unusual due to core dump issues. Although he suggests upgrading to apt, he advises against it because the C binaries are incompatible. He also mentions that apt is entirely written in C and dynamically linked, but this doesn't explain the core dump. Instead of searching for mirrors for the ISO and moving on, he asks if there's a secret solution or if he should just continue the search. Matthias Matthias Saou, a system and network engineer from Barcelona, Spain, is part of an electronic group interactive phone list and has sent this message to the rpmlist mailing list."
   }, {
       "body": "Hi, I've managed to make some progress on the topic that we've been discussing in multiple forums. You can now include the 'rpm' task in your sourceslist. After running 'apt-get update', you can explore what's available with the command 'apt-cache search task'. These packages are directly generated from the 'compsxml' and hence contain exactly the same packages as you would get by selecting various categories during installation. I didn't include SRPMS for these, as they are not particularly interesting. If you wish to regenerate the specs, simply run the appropriate command. Please note that the repository only contains the 'taskpackages'. To perform any action with it, you need an 'apt-enabled' mirror in your sourceslist."
   }, {
    "body": "Brian previously wrote: 'I try to be considerate towards your server, following the principle of using free resources without causing trouble. I highly appreciate your work as it allows me to accomplish tasks that I wouldn't be able to otherwise, and I respect that. Don't worry too much about it. If the server becomes overly busy, I will clean up and publish addresses for some FTP mirrors as there are numerous ones available including an apt one. For now, the limit is sufficient. When I unlocked the psyche ISO images on Monday, the bandwidth usage on the current ftp.freshrpms.net server increased significantly, but it's not problematic as the server has a physical NIC. However, I would get into trouble if this was always the case. The average usage when there is no new Red Hat release is between 50-100GB per day, which my company tolerates as they understand it provides a valuable return to the community, allowing us to run our servers on such a great operating system. Matthias Matthias Saou, System and Network Engineer, Barcelona, Spain, Electronic Group Interactive.' rpmlist mailing list."
   }, {
      "body": "Dear Matthias Saou, \n\n I hope this message finds you well. You mentioned that you have returned to Red Hat and are in the process of upgrading your system. It appears that you are encountering issues with RPMs and are considering using APT instead due to binary incompatibility. However, since APT is C binary incompatible and entirely written in C and dynamically linked, I understand your apprehension. \n\n To clarify the core dump issue, it seems to be a linking problem. As for now, you are using the stock version of RPM, RPMLIB, POPT, etc., along with the recommended version of APT that I provided earlier. However, no new code is getting loaded. It might be a long day's work or a complex issue at hand that is causing this. \n\n To troubleshoot further, I suggest you continue searching for the ISO on the remaining non-hammered site and also check other mirrors if needed. Remember, there are plenty of choices available. If you need more assistance, feel free to ask. \n\n Keep up the good work and appreciate your commitment to Linux. \n\n Best Regards,\n Brian Fahrlender"
   }, {
      "body": "In a previous email, Angles mentioned switching to open source and stopping the use of Partition Magic. They were seeking software to nondestructively repartition a hard drive for creating a separate partition for home. The recommended tool was Parted, although it has limitations such as not being able to move the start of a partition. However, Angles expressed satisfaction with Parted. If Angles didn't put home on a separate partition in Windows, they used to delete the Windows directory and some program files directories and install fresh instead of upgrading while saving other data. This trick can potentially be applied to RPM-based distributions like Red Hat, but it would mean deleting all packages and starting afresh. It's important to backup any edited or installed files before reinstalling cleanly, formatting the installation partition, and restoring the home files. However, this method may lead to losing any tweaks made to files like etc/sysconfig/networkscripts or specific parameters added to an etc/modules.conf entry. Copying the grub conf files might be necessary if there are special kernel parameters to save."
   }, {
       "body": "Subject: Suggestion for kernel package build consistency\n\nDear Matthias Saou,\n\nI've noticed that using an RPM package built against a non-RPM installed component is inconsistent. Following this line of thought, I've been installing my custom-built kernels through RPM lately. However, I find it inconvenient that packages like alsakernel and similar ones only build for the currently running kernel.\n\nI've attached a patch to allow specifying an alternate kernel by setting the 'targetkernel' environment variable before running 'rpmbuild'. While you still need to have the RPM for the specified kernel installed, at least it doesn't have to be the currently running one. This method is somewhat hackish, so if anyone has a better way to do this, please let me know.\n\nBest,\nGary"
   }, {
       "body": "Matthias Saou, it would be wise to backup all locations where you have manually edited or installed files (only in etc root and home). After a clean reinstallation by formatting the system and then putting your home files back into place, you should be ready to go. I have confidence in your usage of your RPMs for some time now; that's the approach I will take - a fresh start but with the old configurations ready for diffs when needed. I'll find an old hard drive for those media files (in the context of geometry)."
   }, {
       "body": "Gary previously mentioned that using an RPM package built against a kernel not installed via RPM is inconsistent. In response to this, he has been installing his custom-built kernels through RPM. However, he finds it inconvenient that packages like alsakernel only build for the current running kernel. To address this, he has attached a patch to specify an alternate kernel by setting the targetkernel environment variable before running rpmbuild. This method requires having the RPM for the specified kernel installed but doesn't necessitate it being currently running. Although this solution is somewhat hackish, if there are better ways to achieve this, please let him know. \n\nHe proposes a few improvements: \n- The patch should support packages named kernelsmp.\n- A cleaner way than the env variable is preferred, and ideally, editing the spec file should be avoided.\n- Defining 'target' with 'smp' sounds good enough.\n\nAdditionally, the buildrequires on kernelsource will need to be removed because it may not always be necessary. This does bother him a bit. \n\nHe welcomes more ideas and suggests a cleaner, env-variable-free solution for custom Red Hat Linux RPM packages on the rpmlist mailing list."
   }, {
    "body": "Dear Matthias Saou, \nIn the past, you recommended backing up only the root and home directories before performing a clean reinstallation of custom Red Hat Linux RPM packages. You also suggested putting the backed-up files back into place afterwards. I trust your advice, as I have been using your RPMS for some time now. However, please remember that I am not a messiah; you are free to do what you think is best for you. \nRegarding Red Hat Linux Release Valhalla running the Linux kernel load, I assume this is related to the rpmlist mailing list. \nBest regards,"
   }, {
    "body": "Hello,\n\nI've noticed that since you upgraded to mplayer, the VoSDL is not functioning correctly for you. It seems to be displaying a black screen while playing audio. I'd be happy to assist you with this issue.\n\nAlso, you mentioned that the source RPM specified it could work without libdv, but it didn't seem to function as expected for LIRC and ARTS. If you need help figuring out a solution for these dependencies, feel free to ask.\n\nBest regards,\nRoi"
   }, {
       "body": "Dear User,\n\nIt appears that your mplayer with SDL is not working due to the upgrade. This issue might be caused by an existing libdv package that was installed on your system. To resolve this, you can try rebuilding the RPM without libdv. Here's a link to the spec file for reference: [Spec File Link]\n\nRegarding your previous message about LIRC and Arts being fixed, it seems that they were indeed working due to the presence of the libdv package.\n\nBest regards,\nMatthias\nRed Hat Linux RPM Packages Team"
   }, {
       "body": "I appreciate your initiative towards consistency and ease of use for RPM package builds, especially with custom-built kernels. I understand that you've attached a patch to specify an alternate kernel by setting the `targetkernel` environment variable before running `rpmbuild`. This approach seems reasonable, although it may need further refinement. \n\nAs suggested, renaming `targetkernel` to `kernelsmp` and removing the buildrequires on `kernelsource` might be a good start. However, I'd like to propose an alternative solution that doesn't involve environment variables or modifying the spec file excessively. \n\nInstead of using an environment variable, how about defining `targetkernel` as a macro in the spec file? This would make it more streamlined and less prone to errors. Here is a rough idea of how the spec file could look like:

```makefile
Name: mycustomkernel
Version: 1.0
Release: 1%{?release}

Summary: My custom kernel package

%description
This is a brief description of your kernel package.

%prep
# Your preparation steps here

%build
# Your build commands here

%define targetkernel 4.18.0-300

%install
# Your installation steps here

%files
# Your files to be installed here

%changelog
# Your changelog entries here
```

This way, you can easily switch between kernels by changing the `targetkernel` definition in the spec file without having to remember or set environment variables. \n\nLet me know what you think about this approach, and I look forward to hearing more about your progress."
   }, {
     "body": "On Friday, Oct 08, Mark Derricutt asked if anyone knows where one could obtain RPMs for a lot of Python libraries as it is quite inconvenient the way Red Hat ships Python and Python packages that only work with one or the other, particularly the pgdb and xml modules. It seems Red Hat insists on using Python to preserve binary compatibility across all their x releases, making it the default. Is there any reason for this? For more information, you can check the rpmlist mailing list."
   }, {
       "body": "Is anyone aware of where one could obtain RPMs for a lot of Python libraries? It's quite frustrating how Red Hat ships Python and Python3, along with the libs that only work with one or the other, especially the pgdb and xml modules. Do you happen to know why Red Hat insists on using Python but doesn't like to break compatibility during major releases? This was because when it was initially released, it was current. For further information regarding digital signatures, please refer to the end of this message for PGP signature details. Here is the RPM list mailing list:"
    }, {
    "body": "On Friday, Mark Derricutt asked about Red Hat's decision to continue using Python. Ian Ahnbarhe explained that Red Hat has a backward compatibility 'shim' set, which has been available in their Rawhide for months for early adopters and backporters. Red Hat maintains binary compatibility across major releases as their server management tools are heavily reliant on Python and becoming more so. Adding Python 3 at this stage in the RHL series would have been disruptive to an existing installed base. This was shared on the rpmlist mailing list by Russ Herrold."
   }, {
      "body": "Hi Vincent, I'm working on locating the package for Red Hat. Does anyone know where to find it? I've been trying to compile it myself but encountered an error. Since the RPM and spec file is quite messy, I'm cleaning it up currently. I believe I have all the build requirements and installation requirements sorted out, but more testers are needed. If you could test it, that would be greatly appreciated. Jesse Keating and the Mondo Devteam have been notified about this. Let me know if this helps in any way. Best regards, [Your Name]"
   }, {
    "body": "Hello, I have a suggestion regarding the aptconf that comes with the freshrpmsnet apt package. I found it unusual when the behavior changed between old and new versions, specifically during an apt-get upgrade where it does not indicate which packages will be upgraded but only that something is about to be upgraded. Could we apply these changes to aptconf: set downloadonly to false and showupgraded to true? This would make it clearer for users during the upgrade process. Regards, Ille Skytt (illeskytta at ikifi) RPMList mailing list"
   }, {
       "body": "It appears there's a justification for me to upgrade as there is an announcement about preserving binary compatibility for all x releases by Red Hat on October 7, regarding Python being the default. If I appear unusually human, it may be due to misunderstanding. This information was shared in the dream theater rpmlist mailing list."
   }, {
   "body": "Hello Jesse Keating, \n\nIt seems you're having trouble compiling a package for Red Hat. I don't have the specific solution for your error, but I can help you with the srcrpm file compilation. Here's how you can do it:\n\n1. Install the necessary tools: rpmbuild and mock.\n2. Create a build directory (rpmbuild -bb path/to/your_specfile).\n3. If you face issues with the tarball source file compilation, try using the srcrpm file instead. If it works, great! If not, let me know.\n\nRegarding your issue with the dirty rpm and spec file, it's good that you're cleaning it up. I agree that a clean code base is important for effective testing.\n\nLastly, I'd be happy to help with more testers for your package. Let me know if you encounter any troubles.\n\nBest,\n[Your Name]"
   }, {
    "body": "Ville previously wrote about applying changes to the default aptconf included with the freshrpmsnet apt package. Ville found it odd when the behavior changed between old and new versions, as during an apt-get upgrade, it wouldn't specify which packages were to be upgraded, only that something was about to be upgraded. Ville noticed the 'u' switch but found your solution to be superior. The next apt build will incorporate this change, and since some significant bugs are currently being fixed, an update is not far off. Lastly, Ville mentioned creating custom Red Hat Linux RPM packages for the Red Hat Linux release Valhalla running a Linux kernel load. This was discussed on the rpmlist mailing list."
   }, {
     "body": "If you encounter issues with compiling the targz source file on Friday, October Vincent, it is possible that the srcrpm source file compilation may work. To manage with a srcrpm file, you would need to perform 'rpmbuild' with the 'rebuild' target and specify the appropriate architecture ('targetarch'). The necessary filesrcrpm will prompt you for any additional packages required. Jesse Keating from the Mondo Devteam suggests consulting the rpmlist mailing list if needed."
   }, {
      "body": "I'm checking the build system type, host system type, and target system type. However, the configuration for machine 'AthalonRedhat' is not recognized. The command 'binsh adminconfigsub AthalonRedhatLinux' failed with a bad exit status. Additionally, the user 'jkeating' does not exist using root group or user. The same applies to the group 'jkeating'. Furthermore, the build process failed due to a bad exit status from prep. This issue also occurred during the preparation of the dale rpmlist mailing list."
   }, {
      "body": "Apologies for any inconvenience, it appears I have misspelled 'rpmlist' mailing list. Let me learn how to correctly spell it."
    }, {
       "body": "Dear User,\n\nIt appears that you are experiencing an issue with mplayer's SDL mode not functioning correctly after upgrading, resulting in a black screen and audio only. I understand your concern and will do my best to help you resolve this issue.\n\nRegarding the black screen problem, it seems that you might have had 'libdvdevel' installed, which mplayer automatically detected. The new spec file now explicitly disables libdv when rebuilt without it. However, in your case, you didn't have libdv at all; you installed it specifically for mplayer installation.\n\nI suggest you try reinstalling mplayer without 'libdvdevel'. If that doesn't work, I would recommend checking the mplayer source RPM and the corresponding spec file to ensure everything is set up correctly. You can find the spec file at this location: matthias rpmlist mailing list.\n\nHope this helps! Let me know if you encounter any further issues.\n\nBest regards,\n[Your Name]"
   }, {
    "body": "Dear Matthias Saou,\n\nI believe I can help you with the issue you're having with mplayer and SDL not working after your upgrade. The problem might be due to the presence of libdvdevel, which mplayer is automatically detecting. To resolve this issue, try uninstalling libdvdevel if you have it installed. If not, ensure that you don't have any conflicting packages or libraries.\n\nRegarding your mention about the source RPM specification and libdv, it seems that the new spec file does want to build the package without libdv. However, there might be an issue with configmak during the build process. I would suggest you to revert back to the normal spec file and manually remove libdv from the buildrequires as a workaround until the issue with the new spec is resolved.\n\nBest regards,\n[Your Name]"
   }, {
      "body": "Previously, ROI stated: 'The new spec didn't even want to build the package with configmak. This is odd as it appears similar to the old one, but includes libdv and libdvdevel in the buildrequires. I manually removed it. My mistake, fixed now.'\nRegarding the mplayer vo sdl black screen issue you reported, I was unable to reproduce it on my home computer. It worked as expected.\nI am creating custom Red Hat Linux RPM packages for Valhalla release running a Linux kernel load (AC online battery).'\nRegards,\nMatthias"
   }, {
    "body": "The AtahlonRedhat machine is not recognized during binsh adminconfigsub, with a failure in prep having a bad exit status. It seems you might have adjusted some default RPM flags yourself. The distro you're running doesn't appear to be standard AtahlonRedhatLinux; it should be a combination of Athlon and Linux without Redhat. However, I can't confirm this for sure. It appears that your system is setting an unusual flag for the rpm build user 'jkeating', which does not exist using the root group or user. Additionally, there seems to be an issue with the davedina project : future tv today, where the files appear to be owned by the wrong user (original spec builder Thomas). This message is sent on the rpmlist mailing list. It's urgent and the best radio on the internet."
   }, {
     "body": "I recently installed a Linux distribution that seems to have undergone extensive quality assurance testing yesterday. Despite being installed on an old Celeron box, parts of it were slow but overall, it performed well compared to my more modern machine. The interface is sleek and user-friendly, even the average user can appreciate its simplicity and leave their tech restraints behind. \n\nThe applications, both KDE and GNOME, are intuitively separated not by the traditional names (gnomekde) but by their functions. It's evident that a lot of time was spent improving usability and graphics to make it more internationally accessible. For instance, the web browser icon features a world symbol with a mouse around it, while office apps have familiar icons like pens, paper, and calculators. \n\nI plan to customize the graphics with my own themes, but for wide release, this one is impressive. I miss the character of KDE and GNOME, but I'll likely tweak the graphics settings. If you get a chance, I recommend giving it a try - I think you'll be pleasantly surprised. \n\nI identify as a Linux zealot, conservative, and technomad from Evansville. We strive for our machines to make big decisions programmed by fellows with compassion and vision. Once the work is done, they will be clean, forever free, and eternally young."
   }, {
     "body": "It seems that I haven't received a response from Matthias yet, but I can see his previous message on the website and it appears that I have subscribed, likely to a digest. In the past, Steve wrote about updating packages using 'apt-get update', however, when he tried to install packages such as 'lame', it didn't work. He ran 'apt-get update' again and shared the output below:

     ```
     apt-get update
     ...
     apt-get install lame
     ...
     Couldn't find package lame
     ```

     Steve then suggested checking the apt-get update process more closely. After re-running 'apt-get update', it appears that the files are updated, but the installation of Synaptic (another known package) also failed. He is now trying to uninstall and reinstall apt-get, as well as exploring other methods like rpm or Synaptic.

     It's worth noting that the software 'the box' requires Windows NT or better, so Steve installed Linux. Additionally, he has joined a mailing list for RPM lists.

     Currently, Steve is stumped and looking for help from Matthias and myself."
   }, {
      "body": "Dear [Recipient],\n\nPreviously, Brian expressed his interest in installing ALSA (Advanced Linux Sound Architecture) on a fresh Red Hat Linux system due to its ability to run certain games like 'Search and Rescue' and 'FlightGear Flight Simulator'. He had concerns about potential complications, but was assured that with the new ALSA packages in Mandrake RPMs, it has never been easier for Red Hat Linux. The only tricky part is editing the etcmodulesconf file, however, a detailed matrix of supported cards can be found on the ALSA website to help with this process.\n\nBest Regards,\nMatthias\n\nNote: Custom Red Hat Linux rpm packages - Red Hat Linux Valhalla running Linux kernel load : AC Online battery rpmlist mailing list"
   }, {
    "body": "Dear Matthias, I believe that with your ALSA packages, using ALSA on Red Hat Linux has never been easier. For months, I have been hand-building those ALSA packages to utilize my laptop's ESS chip for best hard disk recording and other such tasks. I didn't look forward to the tedious build every time I changed a kernel or something. With your solution, that is now a thing of the past. It's a no-brainer - just use apt-get or download and install. Additionally, OSS is fully emulated; older apps using OSS are as happy as a clam. My personal preference leans towards newer apps which use ALSA sound, as I find them to be superior. For instance, alsaplayer/xmms with the ALSA module sounds better to my ear. The modulesconf file was one of the things that used to trick people. When I started with ALSA, there wasn't an automatic matrix page, but now you truly don't know how good you have it. On my old installs, only the first time I installed it on a clean box did ALSA always mute until you fired up a mixer and turned up the music. It seems even that issue has been addressed by you as well. The only one-time thing on installation that was an issue in the past is now resolved. Those ALSA dudes had been trying to get it into the kernel, but missed it. However, it's been in for a while now, so ALSA is indeed the future of sound in the Linux kernel. As far as geometry goes, I suppose you could say that ALSA is the 'angle' that will shape the future of sound in the Linux kernel. Best regards, [Your Name]"
   }, {
       "body": "Matthias Haase has shipped the code with the bytecode hinter disabled, causing Nonaa fonts to appear ugly. This issue can be resolved by adding 'includefreetypeconfigftoptionh' which is well-documented. It is worth noting that Red Hat ships with the bytecode hinter enabled. The change for enabling ftoptionh seems to have been made by Red Hat in their SRPM before building. By carefully examining the SRPM, it appears that this action exactly addresses the issue at hand. Therefore, if your fonts appear ugly, lack of bytecode hinting is not likely the cause."
    }, {
     "body": "I've encountered an issue while trying to build this package as RPM found files not included in any of the packages I tried. I attempted to add them, but was unsuccessful. The problem seems to be related to the documentation being loaded. Has anyone managed to get this to work? I would appreciate your insights on this matter, especially if you have experience with the coy rpmlist mailing list."
   }, {
       "body": "I understand that you're encountering dependency issues while installing my package on a Rh Box system. You've tried to install both dev and lib RPMS, but they keep returning errors due to mutual dependency problems. It seems that each package requires something from the other's package. I suggest you try installing them without the 'without' options, but it appears you've already done so. The issue seems to be with the dependencies of glut, aalib, lirc and 'is', where 'is' seems to depend on each of these packages in a loop. It would be helpful if you could check if there are any specific versions of these packages that might resolve this issue. Thank you for your patience."
   }, {
       "body": "Dear Brian Fahrlender,\n\nI am having trouble installing your package on my system running Red Hat. I keep encountering dependency issues even after attempting to install the dev and lib RPMs. It appears that each package requires something from the other, creating a loop of dependencies. I've tried using the without options, but I still end up with similar issues for the regular package.\n\nHere are some specific dependencies I am running into: glut is needed by aalib, aalib is needed by lirc, lirc is needed by isdbm, isdbm is needed by what. I'm not sure what I am missing here.\n\nYou mentioned that Red Hat might suggest the necessary packages for me, but since you are more familiar with this environment, I thought it would be best to reach out to you directly.\n\nI look forward to your guidance. I am reachable via ICQ at machines to make big decisions programmed by fellas with compassion and vision. We will ensure the system is clean when the work is done, always free and forever young.\n\nRegards,\n[Your Name]"
   }, {
     "body": "Hi,\n\nIt seems you're having trouble building a package due to files not included in any of the packages. The issue might be with the documentation loading. Could you please provide the list of the specific files that are causing this problem? It's possible that more documents get generated when a certain doc tool is installed, and I may not have had that installed during the package rebuild.\n\nBest,\nMatthias\n\nPS: I am working with custom Red Hat Linux RPM packages on Valhalla release running Linux kernel load : ac online battery. If you're subscribed to the rpmlist mailing list, feel free to ask for more assistance there.\n\nRegards,"
   }, {
     "body": "Dear Matthias, \n\nI have attached a patch to allow specifying an alternate kernel by defining 'target' with SMP and removing the 'buildrequires on kernelsource'. This method isn't ideal as it requires the RPM for the specified kernel to be installed, but doesn't need to be currently running. However, I believe there might be a cleaner way to do this without using an environment variable or editing the spec file directly. \n\nThe idea looks good, but it needs some tweaking. It doesn't support packages named 'kernelsmp', and I prefer defining 'target' rather than using the env variable. Additionally, the 'buildrequires on kernelsource' should be removed because it may not always be necessary. \n\nOnce my computer is back from repairs, I will rewrite the spec file to include support for 'kernelsmp' and send it to the list for further criticism. \n\nRegarding the issue with the alsadriver source needing a usbrelated patch to compile under the latest test kernels, I have noticed the same problem or is it just my setup? Other people using the same kernels have faced the same issue? If you have any insights on this, please share. \n\nGary, thank you for the ALSA packages. They greatly simplified what used to take way too long before RPM. \n\nBest regards,\n[Your Name]"
   }, {
       "body": "Quaffa previously wrote: I have tried building without options, but still end up with similar issues for the regular package. Glut is required, you need to install the Glut package from Red Hat Linux and Glut-devel if you plan to recompile the source RPM. Aalib is also needed (Lirc is needed by something, something else is needed by Lirc as well, and another thing is needed by that). Both aalib and lirc can be obtained from freshrpms.net. They are small and can be quite useful. You should be able to eliminate those two if you rebuild the source RPM, otherwise it may be a bug in my packaging. To rebuild without aalib or lirc, use 'rpmbuild rebuild --without aalib --without lirc'. If this doesn't resolve the issue, it might be a problem with my custom Red Hat Linux RPM packages (Valhalla running Linux Kernel Load). For any assistance regarding online battery RPM list, please refer to the rpmlist mailing list."
   }, {
      "body": "Thank you Matthias, it appears that after installing the packages, Xine is now working as expected. I suppose I should have figured that out on my own. Thank you for your assistance on the rpmlist mailing list."
    }, {
    "body": "Apologies for any confusion, but I understand now that the fonts appearing ugly is not due to a lack of bytecode hinting. This issue seems to occur only within applications when antialiasing is enabled. Unfortunately, I did not have a better solution yesterday late in the evening. Regards from Germany."
   }, {
      "body": "Hello Matthias, \n\nRegarding your request, I've rebuilt the rpmbuild rebuild target and encountered an error. The output suggests that 'rpm build user' and 'root user' do not exist. However, the unpackaged files are present: usr/shared/doc/clamehtml/basichtml, usr/shared/doc/clamehtml/contributorshtml, usr/shared/doc/clamehtml/exampleshtml, usr/shared/doc/clamehtml/historyhtml, usr/shared/doc/clamehtml/indexhtml, usr/shared/doc/clamehtml/lamecss, usr/shared/doc/clamehtml/modeshtml, usr/shared/doc/clamehtml/switchshtml, rpmlist. The issue seems to be related to the user accounts mentioned in the error message.\n\nBest regards,"
   }, {
    "body": "The error message indicates that the 'dude' user does not exist during the rpm build process, even when using root. The issue seems to be related to unpackaged files under 'usr/shared/doc/clamehtml', specifically 'basichtml', 'contributorshtml', 'exampleshtml', and 'historyhtml'. This problem appears to stem from the spec file not accounting for all the files produced during the rpm build. Russell Herrold has brought this to the attention of the rpmlist mailing list."
   }, {
    "body": "In the MPlayer source package, the 'with' and 'without' options seem to be malfunctioning. I have opted for not using arts, but it still insists on installing with arts. This issue is being reported on the rpmlist mailing list."
   }, {
       "body": "In the mplayer src package, it appears that the 'with' and 'without' options are not functioning correctly. I managed to run it without arts, but it still attempts to install with arts. This time, it seems that xinelibs configure script underestimated its capabilities, as it does not appear to support disabling arts. If you have artsdevel installed, the support for arts will be compiled in. Additionally, I made a mistake and added the configure option to disable Lirc or Xinelib when it should have been for XineUI. These issues are addressed in the upcoming release. Furthermore, custom RPM packages for Red Hat Linux Valhalla were built with Linux kernel load and AC Online battery. The RPMList mailing list was used."
    }, {
    "body": "Dear Alvie,\n\nIt appears that you are encountering an issue with DVD playback on devhdc, and hdparm is returning 'operation not permitted'. One possible solution could be to enable DMA transfers. Here's a step-by-step guide:\n\n1. Open the terminal.\n2. Type 'sudo nano /etc/modprobe.d/dvd-cd.conf'\n3. Scroll down and add 'options dvd-cd dma=1' to the file.\n4. Save the file and exit nano.\n5. Type 'sudo update-initramfs -u' to update the initramfs.\n6. Reboot your system.\n\nPlease let me know if this resolves your issue. If not, I'd be happy to help you troubleshoot further."
   }, {
    "body": "Hello,\n\nOn Sunday, your HDPARM command for devhdc on Alvie reported an 'operation not permitted' error while attempting DVD playback, which appears to be jumpy. Could you please suggest some solutions to enable DMA transfers? I added the 'idecd' option and posted this question on the Chris Kloiber RPMList mailing list.\n\nBest,\nAlvie"
   }, {
    "body": "Thank you for your message. The DVD is now working fine for me, but I'm encountering an issue where I can't extract the contents of the DVD. The last message suggests using libdvdcss for DVD access, but it fails on Sun. When using hdparm devhdc, it returns 'Operation not permitted'. DVD playback is very jumpy. Do you have any suggestions on how to enable DMA transfers? I've added 'idecd' as an option. I thought you might be able to help, or perhaps someone from the rpmlist mailing list could provide insight."
   }, {
    "body": "When I attempt to use 'apt-get upgrade', it suggests installing libusb, but I already have the same version. The issue seems to arise from the RPM list mailing list. This may indicate a conflict or incorrect package dependency."
    }, {
     "body": "On Monday, October 4th, I encountered an issue when trying to use apt-get upgrade. It suggested installing libusb, but I already had the same version and attempted to remove it without nodeps. However, this caused a collapse. After removing libusb and using apt-get f install, everything was fine. I am Brian Fahrlender, a Linux zealot, conservative, and technomad from Evansville. I've been stuck in a long journey, so I thought I'd let you know."
   }, {
     "body": "Hello Thomas, \n\nI'm having issues with some kernel packages for kernelsources in my build scripts. The problem is that when I run 'apt-get install kernelsource', it tells me that 'kernelsource' is a virtual package. This doesn't help me much as it doesn't explain the two options available. \n\nCould you please clarify how I can instruct apt-get to install one of these packages? As this is done automatically in my build scripts, I'd like it to proceed without interruption. \n\nThanks,\nThe davedina project: Future TV Today - I'm Alive - The best radio on the internet (rpmlist mailing list)"
   }, {
     "body": "Dear Matthias Saou,\n\nThank you for your help with the DVD issue. It's working great now! I think I will modify my Ogle package so that it automatically adds the options to etcmodules.conf.\nCurrently, it creates the devdvd link to devcdrom which works most of the time if there is only one drive. However, if no devdvd exists, it can cause issues (eek!). I'm not sure if it's just me, but I don't think this approach is ideal.\nI suggest outputting a message in post and providing a readme of some kind would be better. Additionally, perhaps adding a note in the description could help clarify things for others. Looking forward to your feedback on the Ikifi RPMList mailing list.\nBest regards,\n[Your Name]"
   }, {
     "body": "Ville originally suggested that his 'ogle' package will automatically add this option to etcmodulesconf, but currently creates a link from devdvd to devcdrom. This works well if there is only one drive, but may cause issues if no devdvd exists. Ville thinks a message in the post section and providing a readme would be better. He also suggests adding a note in the description about why this happens: If no devdvd exists, it will create it; if devdvd exists, it won't make any changes. For a DVD player installation on Red Hat Linux, Ville assumes that the hardware is recent enough for software playback and that the drive is a DVD-ROM, all of which support DMA. However, since the change requires a reboot or manual alteration, he is still hesitant to integrate it. His goal is to allow users to install a DVD player quickly through Synaptic and play DVDs easily. Placing a tip in the description instead of the post section seems like a good idea to Ville."
   }, {
       "body": "Dear Matthias, \n\nAlvie wrote to you about having trouble rebuilding Transcode from scratch. The error message provided is quite extensive and includes the following issues: type declarations not defined, syntax errors, parse errors, conflicting types, invalid conversions, and undefined variables. Here's a summary of some of the main problems:\n\n- Waveformatex, fmt, and avmwaveformatname are not defined as types.\n- There are issues with the declaration of fprintf, samples, buffersize, buffer, fflush, ipipe, syncstr, and pwrite.\n- Some variables (like iso c) appear to be undefined or incorrectly used.\n\nAlvie mentions that this issue might be due to a missing library (libdvdcssdevel), which they believe could be the cause of their current Red Hat build of Transcode having avifile support disabled. They also suggest that it may be a simple mistake on their part, as they haven't used Transcode for a while.\n\nIn conclusion, Alvie is seeking help to resolve these issues with Transcode on their home computer and would appreciate any assistance you can provide. Thank you."
    }, {
       "body": "Alvie previously wrote about an issue with rpmbuild rebuild, which has a parse error before 'if' due to the absence of avifile being defined as a type. This problem seems to be related to support. Typically, your build of transcode doesn't use avifile, but you can force it by using '-with' for recompiling against it. Could there be an old avifile installation? You might want to check the configure line run at the start of the rebuild process to see if it includes the option '--enable-avifile'. Regarding your custom Red Hat Linux RPM packages, they are being built on Valhalla running a Linux kernel. For any further assistance, you may refer to the rpmlist mailing list."
   }, {
     "body": "Dear Matthias Saou,\n\nI believe I understand your concerns about the current approach. It might be more appropriate to provide a README file with the RPM, and possibly include a note in the description as to why 'eek'. If no devdvd exists, it will create it; if it does exist, it won't interfere. However, users who have CD drives that don't support DMA may encounter issues.\n\nTo avoid any potential system disruption, it would be advisable to not modify the modulesconf during installation unless absolutely necessary. If 'ogle' adds the DMA setting in modulesconf, and nothing else requires it, then it can be safely removed.\n\nRegarding your suggestion, I think separating the creation of symlinks and modulesconf modifications into a separate RPM sounds like a good idea. This could help mitigate potential issues with uninstallation or users with CD drives that don't support DMA.\n\nLastly, I share your goal of allowing users to install a DVD player quickly through Synaptic. However, due to the nature of the change required, which may necessitate a reboot or manual modification, I am still hesitant to integrate it at this time.\n\nBest regards,\nIlle Skytt (Villeskytta)"
   }, {
    "body": "Matthias, I believe you won't abandon or delete these and the modulesconf change on uninstall. However, users who install this RPM with a DVD drive or an ordinary CD drive that doesn't support DMA might end up with a non-functioning CD drive after removing the RPM, without understanding what caused the issue. It's tricky because you can't remove the DMA setting from modulesconf unless you're certain that 'ogle' added it there and nothing else requires it. I've never encountered any CD/DVD drives having issues with DMA, but it's possible given Red Hat's decision to default disabling it in recent releases. If Chris could confirm this, I suppose I'll accept the devdvd link change as described and include a tip about DMA in the description. As for your custom Red Hat Linux RPM packages for Valhalla release running Linux kernel load on rpmlist mailing list, carry on."
   }, {
      "body": "Dear Matthias Saou,\n\nAlvie wrote that the parse error before if in your recent build of transcode is due to the fact that avifile, which was used as a type but not defined, is not installed or properly defined. He suggested checking the configure line at the beginning of the rebuild process to see if it includes the option to force recompiling against avifile.\n\nIt appears you correctly guessed in an earlier email that there were still remnants from an old failed avifile installation, as the transcode srcrpm now builds perfectly.\n\nThank you very much for your help, Alvie. Your expertise in creating custom Red Hat Linux RPM packages has been valuable in resolving this issue on Valhalla running Linux kernel load.\n\nBest regards,"
   }, {
    "body": "On Monday, October 18th, Mathias Saou mentioned that CD-ROM or DVD-ROM drives have never had problems with DMA, but since Red Hat decided to disable it by default in a few releases, there might be issues. During my tenure as a PC repair tech at a computer store chain, I encountered several DVD drives that would lock up if DMA was enabled. This seems to be more of a chipset/drive issue rather than the drive itself. Jesse Keating's insights on the Mondo devteam mailing list might have been helpful for others."
   }, {
     "body": "In the past, Jesse mentioned that he encountered DVD drives locking up when DMA (Direct Memory Access) was enabled while working as a PC repair tech for a computer store chain. He suggested that this issue is more of a chipset-drive problem rather than an individual drive concern. If I'm correct, the chipset in question was either VIA or SIS. Following Red Hat's approach, I will leave the DMA setting alone and direct users to a page with instructions on how to enable it at their own risk. This discussion pertains to custom Red Hat Linux RPM packages, running on the Valhalla release of Red Hat Linux, utilizing the Linux kernel load as listed in the rpmlist mailing list."
   }, {
      "body": "I understand that you will proceed with the link change for devdvd as mentioned, and add the DMA tip to the description. Thank you for your response, it makes me feel more at ease. I'm Ille Skytte from the ikifi rpmlist mailing list."
   }, {
      "body": "Does your organization have any plans to distribute Nessus RPMs? This is a question regarding the IkiFi RPM list mailing list."
   }, {
    "body": "Previously, Ville mentioned plans for rolling Nessus RPMs for Miss It, and it appears that this is one of the RPM-related emails left in your inbox. As it's a substantial piece requiring testing, I mentioned it privately as I tend to be a bit lazy about such tasks. However, I will make an effort to package it as soon as possible or at least set up a testing version first if I fear there may be imperfections. The packages will be for a custom Red Hat Linux distribution, Valhalla, running the Linux kernel load. This is in reference to the rpmlist mailing list."
   }, {
     "body": "I have uploaded a new build of Nessus on Red Hat Linux. Although it's untested, it should be fine. The new menu has been added, but some configuration files may need adjustments due to the new or different defaults. I welcome your feedback. This is a custom Red Hat Linux RPM package running Valhalla release with Linux Kernel load list on rpmlist mailing list."
   }, {
    "body": "Subject: Request for a fixed spec file for XMMS\n\nDear Community,\n\nI have encountered an issue with XMMS as Redhat has disabled support for files relinking it with a module. I was wondering if anyone here has a working spec file for XMMS that is capable of playing audio, as this would be most helpful. Unfortunately, I have not been able to get XMMS to work properly on my system; it didn't function as expected and gave me a black screen. I thought the issue might have been with my setup, similar to MPlayer not working under certain conditions, but I am now suspecting that there may be a problem with XMMS itself.\n\nCould someone please share any relevant information or guidance on this matter? I am currently seeking assistance from the rpmlist mailing list as well, but your insights would be greatly appreciated.\n\nThank you,\n[Your Name]"
   }, {
       "body": "Matthias Saou previously mentioned that XMMS did not work for him as well, and he thought it might be an issue from his end but found out it was normal due to Red Hat removing all support because of patent and royalty issues. He suggested finding the XMMS plugin on freshrpms.net, but also mentioned the availability of libmad lame encoder and soon, other plugins. However, he noted that not only XMMS, but also players like Alsaplayer, Xine, Mplayer (like MPlayer), are experiencing issues and display a black screen. He emphasized this is abnormal, and suggested trying 'mplayer vo help' then using various output methods to see if some do work or not. Matthias also mentioned that mplayer works with dga when he is root and works with sdl but does not now with Redhat, giving a black screen window and playing the music of the movie. This issue occurs on the RPMList mailing list."
   }, {
    "body": "Previously, ROI mentioned that mplayer works with DGA when logged as root and with SDL, but not currently on Red Hat, displaying a black screen window and playing the movie's music. Interestingly, it works for him, and he suspects that the issue might be related to sdlimage or something similar. Please check the custom Red Hat Linux RPM packages for Valhalla release running Linux kernel load, if not already done."
   }, {
       "body": "Dear Matthias, \n\nIn your email, Joshua suggested a way to generalize ALSA (Advanced Linux Sound Architecture) for easier building of custom kernel modules. He proposed creating scripts or step-by-step instructions, such as building a kernel RPM with ALSA, getting the kernel source, and running a customkernelsh script. However, he expressed that it might not be worth the effort due to potential system breakage if not carefully tested. \n\nHe also suggested an alternative approach, which is to leave the current kernel unchanged, get the ALSA driver RPM, rebuild and install the resulting packages. Drivers like ltmodem, nvidia-alsa, etc., can be easily repackaged separately as RPMS and ported for various kernel RPMS from the source RPM. \n\nHe further explained that what you described seems to be the opposite of RPM packaging, which is more about a 'one size fits all' approach in the general case. He also mentioned that the kernel isn't an exception as there are packages optimized for various processors. However, he expressed concern about including the kernel in his packaging due to potential issues for new users. This applies to major components like GNOME, KDE, and other distribution bits as well. He wants users who use his packages to be able to upgrade to the next Red Hat Linux release without encountering problems. \n\nLastly, he mentioned that he wants to keep the kernel away from his packaging to prevent newbies from potentially damaging their systems due to packages on his website. \n\nBest regards,\nChris"
    }, {
       "body": "Dear Matthias,\n\nThank you for your help with getting the speakers and subwoofer working in digital out mode. However, I'm still confused about switching between analog and digital modes as I have a tuner and cassette deck hooked up to line-in on an sLive which is currently in analog mode. Digital out works great now.\n\nLance mentioned that he got ALSA installed and there is no static in between like before, but the sound is only coming from the front speakers and subwoofer, with no sound from the rear speakers. Additionally, ALSAmixer or aumix are unresponsive. Perhaps you could find more information or tips on the ALSA page for your card. Alternatively, you could try editing the ecasoundstate by hand using alsactl store editing and then running alsactl restore to see if you're able to change what you want.\n\nI hope this helps! Let me know if there are any further insights or tips that would be beneficial.\n\nBest,\n[Your Name]"
   }, {
      "body": "Dear All,\n\nI would like to express my gratitude to everyone involved in making these RPMs accessible. Thank you, Matthias and Lance.\n\nI have successfully managed to get all four speakers with subwoofer working in digital out mode using Gamixer. However, I am still perplexed about switching between analog and digital modes as I have a tuner and cassette deck hooked up to the line-in on an SBLive, which is currently in analog mode. The digital out function works splendidly now.\n\nPreviously, Matthias (Saou) wrote that he had successfully installed ALSA with no static interference as before. However, his setup is digital but sound is only coming from the front speakers and subwoofer; the rear speakers are not producing any sound. Additionally, both alsamixer and aumix are unresponsive. He suggested looking for more information or tips on the ALSA page for your card, also trying to manually edit the alsactl store and run alsactl restore to see if changes can be made.\n\nMatthias (Saou), as a System and Network Engineer from Barcelona, Spain, Electronic Group Interactive Phone: rpmlist mailing list, provided some useful tips on finding files larger than a given size using the command 'find path/directory -type f -size nk' where n is a number like for and multiples thereof. Discussions on this topic can be found in the July edition of the rpmlist mailing list.\n\nThank you,\n[Your Name]"
   }, {
      "body": "Matthias Saou, it seems that in your build directory, some packages have hard-coded a path which appears to be your home directory when being compiled. This could potentially be due to some programs incorrectly coding your home directory during the compilation process. These issues seem to be bugs in the programs' build processes, especially noticeable with Xine. I plan to report them upstream if I have some free time. \n\nThis issue is a common one when building things from source. It's generally wise to use a special build environment to avoid such hassles. As Cameron Simpson suggests, you might have a library loading path in your env and an 'strace' of the app will show the app calling 'dude'.\n\nTo prevent this kind of error, I recommend using a script like 'logbuild', which starts a shell with a minimal build environment logged with scripts. This prevents errors caused by configuration scripts yanking various undocumented values from your environment for use in the build process.\n\nIt's often the easiest thing to have a special non-root account with no profile for building things. Cheers!"
   }, {
     "body": "I understand your issue. You're trying to rebuild an ALSA driver package for a custom kernel on your Red Hat system, but you're encountering errors during the RPM rebuild process. It seems there are some undefined symbols related to sndhackusbsetinterface in your kernel source configuration. Here's a suggestion: \n\nCheck if there is a mistake in the config file for your kernel source (usrsrcyourkernelsourceconfig). Make sure that the line where you define sndhackusbsetinterface is correctly formatted and all necessary symbols are defined before it. If the problem persists, consider seeking help on the Linux or RPM mailing lists, particularly the rpmlist mailing list. Also, if you're trying to find files larger than a given size in a directory, you can use the command 'find path/to/directory -type f -size +nk', where n is the number of kilobytes or multiples thereof."
   }, {
     "body": "Dear Ille Skytt, \n\nI have reviewed your email regarding an ALSA bug that affects the configuration of ALSA when using 'withcardsall'. It seems the issue lies in the automatic activation of certain configsndusb macros even if configusb is not set. You propose to patch the alsadriverspec to rectify this problem and suggest sending it to the ALSA developers for consideration. \n\nI will look into hooking up your proposed patch in our alsadriverspec, but I would also recommend sending it directly to the ALSA developer community for their review and potential integration. It appears that someone on this list may already be part of the ALSA developer community and could help shepherd this through for you. \n\nRegarding your suggestion about freshrpmsnet rpms, I believe it is more appropriate to address upstream changes directly rather than including it in freshrpmsnet rpms.\n\nBest regards,"
   }, {
    "body": "Ville previously stated that it is off-topic to include the mentioned issue in freshrpmsnet RPMs. Ville's opinion is that upstream is the correct approach, especially since most of the packages are primarily intended for original Red Hat Linux kernels. If someone removes USB support from their kernel, they likely won't recompile ALSA with all drivers anyway. Matthias, a system and network engineer based in Barcelona, Spain, concurs with this viewpoint."
   }, {
       "body": "Dear List Members,\n\nI am writing to share some insights about the ALSAspecial Mixer, which I've found to be a useful addition alongside other mixers when special requirements arise. Recently, Matthias Saou mentioned that he had built it some time ago and might need a rebuild.\n\nVille initially looked for an init script due to the ALSAspecial Mixer, as it was what sparked his interest. He didn't check if the existing setup would have worked with it. After using it for just a few days, Ville reports that both the main and PCM volume levels can be adjusted either through alsamixer or the classic aumix.\n\nALSA has proven to be quite impressive as it works seamlessly without breaking any OSS compatibility.\n\nWhile my experience is limited, I believe it would be beneficial for other list members to try out this mixer. They can report back on any problems they encounter, particularly the issues with libasoundso and wrong xine dependency which have been resolved in the current packages.\n\nI'd also like to mention that I've finally implemented sorting by both last change date and alphabetically for my build list in the php code. I welcome any patches, comments, suggestions regarding all those spec files.\n\nBest regards,\n[Your Name]"
   }, {
      "body": "If you're currently running the Null Beta, you might appreciate these GNOME theme packages. They are enhanced and re-packaged from my previous theme packs, now conforming to the way prerelease handles themes for Red Hat. Red Hat has a Preferences Themes app, but only themes with both 'themes' and 'aka' themes available will show up there. When applied, the theme is applied to both GTK versions, ensuring that users don't notice different GTK toolkit versions are being used as they should look the same. This RPM has ported themes for those themes included in the Red Hat package 'gtkengines' themes pack. Mainly, these re-packaged theme RPMs aim to please Null Beta users and will supposedly also be suitable when the next release comes out. For this one, you'll need gtkengines and a thinice engine. Note that the link might be old by now, but it's 'angle' as in geometry."
   }, {
      "body": "Dear Ille Skytt Villeskytta, I appreciate your feedback on the newly installed build at iki.fi. The new menu has been added, but some configuration files may require adjustments with new or different defaults. Everything seemed to work smoothly during a local scan. Your feedback is invaluable for improvements. Thank you and best regards."
   }, {
    "body": "In your earlier email, you mentioned that 'rpm build' encountered an issue due to the non-existent user 'dude' while using root. However, this seems to be a normal occurrence since the user doesn't exist. What puzzles me is that this message appears at the beginning of the build process, but it's a reminder file, isn't it? I would expect such a reminder at the end. Furthermore, you mentioned that 'argh, I forgot to exclude aaxine from the files when using without aalib.' The current spec file should address this issue now. Lastly, you were building custom RPM packages for Red Hat Linux running the Valhalla release with a Linux kernel load. This was discussed in the rpmlist mailing list."
   }, {
    "body": "Long ago, ROI mentioned that XMMS didn't work for him either. He suspected it might be an issue from his end, but it turns out this is a common occurrence due to Red Hat removing all support because of patent and royalty issues. You can find the XMMS plugin on freshrpms.net, as well as libmad lame encoder. Soon, many other players like Alsaplayer, Xine, MPlayer (specifically not 'mplayer' but 'mplayer vo help') may also have trouble playing files and may display a black screen. This is abnormal, though you might try using 'mplayer vo help' first and then experiment with various output methods to see if any work. Additionally, Mathias creates custom Red Hat Linux RPM packages for the Valhalla release of Red Hat Linux running Linux kernel load."
   }, {
    "body": "Hi Panu, \n\nIn your build scripts, I've noticed some issues with the kernel packages for kernelsource. When you run 'apt-get install kernelsource', it informs you that 'kernelsource' is a virtual package. This doesn't explicitly state the available options. However, when a package is marked as 'allowduplicated', it means multiple versions of the same package can be installed simultaneously. \n\nIn your case, since there seems to be only one version available, 'apt-get install' will proceed with the installation. The output might appear strange due to the way apt handles virtual packages. If you wish for the scripts to proceed regardless, you can add a command that forces the installation, such as 'apt-get -y install kernelsource'. \n\nI hope this helps! Let me know if you need further assistance."
   }, {
       "body": "Regarding the topic of CD-ROM/DVD-ROM drive problems with DMA, I've rarely encountered such issues myself, but it's plausible given that Red Hat made the switch to disable DMA in some recent releases. During my tenure as a PC repair technician at a computer store chain, I did come across several DVD drives that would freeze when DMA was enabled. This issue seems to be more associated with chipset/drive compatibility rather than the drive itself. Interestingly, my IBM Intellistation would lock up immediately if DMA was enabled for the CD-ROM. However, if the CD had Joliet extensions, it functioned normally with DMA enabled."
    }, {
       "body": "Hi Matthias Saou, \n\nIt appears that the XMMS plugin you're trying to install is causing it to segfault upon exit. However, there seems to be another plugin available for listening to your old files. I have an XMMS ALSA module that I've been using for a while now. Additionally, there are RPMs for AlsaPlayer that work well. Both were built on an Rh Box with Errata, current as of the build date. Currently, I'm running Null Rh Beta and recall that alsaxmms still functions. I can't remember if Alsaplayer needs a rebuild in this version. As a side note, Alsaplayer is maturing into a versatile application, which I've been packaging for numerous releases now. I've also scripted the CVS build of alsaxmms to make it easier to spin another one if these RPMS don't work on Null Rh Beta. \n\nRegarding this matter, please find my packages in the 'rpmlist' mailing list."
    }, {
       "body": "After installing and enabling xosdxmms, I encounter an error when attempting to start xmms: 'unexpected async reply sequence'. The application starts but it fails to detect mouse commands. Thank you, Mike D. Michael Basinger, rpmlist mailing list."
   }, {
     "body": "Apologies for the late response to your email from last week. I'm afraid I'm not sure what could be causing the issue you're experiencing with DVD playback using Ogle Xine, VLC, or Mplayer. Here are a few questions that might help identify the problem: \n1. Does this occur with different DVDs or just one? \n2. Are you using oss or alsa for audio output? Have you tried both? \n3. Are you using binary packages or recompiling from source? \nI recall a user experiencing similar trouble after upgrading libdvdcss to a recent version, but I haven't heard the final outcome yet. If it's not already, could you please check your libdvdcss version? Additionally, this issue might be related to your custom Red Hat Linux RPM packages: Red Hat Linux release Valhalla running Linux kernel load. I recommend checking if there are any known issues with DVD playback in this specific environment.\nRegards,\nMatthias"
   }, {
       "body": "I have also attempted to rebuild my RPM database, however it has not resolved the issue. I've noticed that the files seem rather small (gensrclist, genpkglist, archives, srcpkgcachebin, pkgcachebin). I ran strings on them and they do not appear to contain a complete listing of either my system's installed RPMs or the RPMs in the ls -l total. These files have a 'lock' partial name and if I kill them, they are recreated about the same size the next time I run apt-get. I posted about this issue last week and am still unable to find a solution. Apt-get is not functioning as expected and I cannot determine the cause. I've tried removing RPMs, ensuring all traces were removed (including apt varstate and apt varcache), but I still get 'couldn't find package' when running apt-get install. Any insights would be appreciated. Below is a log of a fresh rpm - apt -apt-devel rm -rf etcapt varcacheapt varstateapt, followed by the output of running rpm ivh dsa, nokey key id preparing apt-get update, ign release pkglist release pkglist release srclist srclist srclist fetched in reading package lists done, apt-get install, reading package lists done, building dependency tree done, 'couldn't find package' aptcache search resulted in a search for xmms, beats me. I installed Linux (Steve Kann Chief Engineer at Ave Ny HorizonLiveCom) as it is required to collaborate and interact with 'the box', however it says the box requires Windows NT or better. As a result, I have also installed Linux."
   }, {
     "body": "Will there be issues if my Red Hat (RH) based apt server operates concurrently with clients running on Red Hat? Can different versions of the same OS interoperate? Thank you, Thomas Baker, Systems Programmer at Research Computing Center, University of New Hampshire, Morse Hall, Durham, NH, USA. Regarding RPM list."
   }, {
    "body": "Previously, Thomas asked about potential issues if his APT server is running RHEL (Red Hat Enterprise Linux) and some clients are connecting and will also be on RHEL. He inquired whether the two different versions would interoperate without any problems whatsoever. Currently, aptfreshrpms.net is operational with APT and many clients are utilizing it. Matthias creates custom Red Hat Linux RPM packages for these clients. The operating system being used by Thomas is Red Hat Linux Release Valhalla, which uses the Linux kernel load 'ac online battery'. He referred to the rpmlist mailing list."
   }, {
    "body": "Hello, I'm looking for someone who has created a working source RPM for 'rip' on Red Hat. Mattias has a spec file on the site and there are some spec files available on the 'rip' website as well, including one that I patched a while ago. However, it seems that the makefile automatically generated is trying to install Perl libraries onto the system, which is not desirable. Additionally, at the moment, 'rip' needs to be called with 'perliostdio', as it doesn't seem to work with 'perlio' in Perl. I'm not sure about the cleanest way to fix this issue. Is anyone currently working on this? Thanks."
   }, {
      "body": "Previously, Michl wrote about a working source RPM for 'rip' on Red Hat, stating that he hasn't tried it yet but if he had, he likely moved on to another package after encountering one of the issues mentioned. If anyone sends him patches for his spec file and any necessary additional patches, he would be more than happy to create a new build. This email was sent to the rpmlist mailing list about creating clean custom Red Hat Linux RPM packages, specifically for the Red Hat Linux release 'Valhalla' running the Linux kernel 'load'. "
   }, {
       "body": "Dear Reader,\n\nDavid Walsh forwards an article from The Irish Digest about Billy in the Bowl, a story that is also immortalized in an old Dublin song and mentioned in a Pogues track. Billy was a legless beggar in the alleys of Stoneybatter and Grangegorman during the 18th century, where you now reside. He discovered a new but not entirely legal way to make money.\n\nThe article details the story of 'The Case of the Stoneybatter Strangler,' set in your neighborhood. Billy, known as the handsome deformed beggar in the bowl, developed a plan to rob his donors. One night, he made the biggest mistake of his life.\n\nEighteenth-century Dublin was famous for two things: the architectural beauty of its public buildings and the large number of beggars who sought alms in its labyrinthine streets and lanes. Among these beggars, Billy in the Bowl stood out because he relied on a large bowl-shaped cart with wheels to move around, pushing himself along by wooden plugs.\n\nBorn without legs, nature compensated him with powerful arms and shoulders, and an unusually handsome face, his greatest asset in his daily routine of separating sympathetic passersby from their small change. However, his greed led him to evolve a plan to rob unsuspecting sympathizers.\n\nOne cold March evening, as dusk was falling, Billy put his plan into operation. The victim was a middle-aged woman who was passing through Grangegorman Lane on her way to visit friends in Queen Street on Dublin's North Quays. Hearing the woman's footsteps, Billy hid behind some bushes and, upon drawing close, he moaned, shouted, and cried out for help, causing the woman to dash towards him. Seizing the opportunity, Billy grabbed the woman and strangled her, eventually succeeding in robbing her.\n\nThe incident caused a stir, but the police could not identify the assailant. Months later, Billy attempted his tactics on a sturdy servant girl who resisted fiercely, leading to the 'Grangegorman Lane Murder.' The district became chaotic for a couple of months, but Billy eventually returned to his old ways, continuing to rob sympathetic servant girls until he was apprehended by Dublin's first police force.\n\nBest,\nRev. Dave Walsh"
    }, {
     "body": "Although I didn't claim it could learn all combinatorial possibilities, it can indeed learn some combinatorial concepts. However, it might not be able to grasp all of them in a straightforward manner. It's important to understand that it can learn examples that are linearly separable, such as those you provided earlier. Unfortunately, it may not be capable of learning the example you mentioned below, as it is not linearly separable."
   }, {
        "body": "Hello Erik Rudolf, \n\nI've noticed there are issues with the latest nightly build of SpamAssassin integrated with vMailMgr and oMailAdmin. The scan is producing an 'no' result. Could someone take a look at the code to see if option f might be missing? You can find relevant discussions on the SpamAssassin Develop mailing list. Regards, [Your Name]"
    }, {
     "body": "Dear Craig Hughes,\n\nAre you ensuring that the non-spamtrap is not inadvertently filtering legitimate newsletters, as some have allegedly sold your email address to third parties without your consent? If so, it would be advisable to manually verify that all the emails within this trap are indeed non-spammy. So far, it appears they are opt-in subscriptions, with no affiliate deals or other suspicious content.\n\nRegarding the SFNet email sponsorship, it seems you've expressed dissatisfaction with the same old cell phone offers. I'd like to inform you that we have a new offer available here for free - a spam assassin talk mailing list. This could potentially help manage your incoming emails more effectively."
   }, {
      "body": "Dear Justin Shore, Pittsburgh State University Network Systems Manager,\n\nI'm writing to inform you about an update regarding our spam filtering system. It appears that the scores assigned by SpamAssassin are currently biased towards non-HTML, non-newsletterish mail. However, over the last month, we have been adding a 'nonspamtrap' to every legitimate newsletter we can find.\n\nThis action should mean that tests which match common newsletter practices will no longer get such high scores once we re-run the gauge. I recently encountered a false positive - a solicited ad from applecom on educator deals. If you would like, I can send you a copy of this message for your records and will add it to our nonspam corpus.\n\nRegards,\nCraig Hughes"
   }, {
    "body": "Dear Ken Scott, \n\nThank you for reaching out regarding your issues with SpamAssassin. To clarify, if a user has a line in their spamassassinuserprefs file specifying an exception for yahoogroups.com, it does not mean that no action will be taken against any mail coming from this domain. However, the checking process will still be applied. \n\nTo ignore such mail, you would need to add a rule in userprefs specifically for yahoogroups.com, for example: \n\n\t\theader_CHECK\_RBL yahoogroups.com - \nThis rule tells SpamAssassin to check the RBL (Realtime Blackhole List) for the yahoogroups.com domain and if it is listed, mark the email as non-spam. If you want to bypass the SpamAssassin filtering entirely for emails from this domain, you can use: \n\n\t\tyahoo\_ Header_CHECK sum -100 \nThis will give a negative score (highly trusted) to any email that has 'Yahoo' in its headers. \n\nBefore deploying SpamAssassin systemwide, I recommend testing it with a few users who are on yahoogroups lists first. If you encounter issues, please don't hesitate to ask for assistance.\n\nThank you and best regards,\n[Your Name]"
   }, {
    "body": "In the provided email, Ken Scott is discussing about his SpamAssassin user preferences. The line 'whitelist_from : yahoogroups.com' in his userprefs file does not mean that the program will ignore all mail coming from yahoogroups.com entirely. Instead, it suggests that the program will still perform checks against such emails but won't take any action if they pass. If they fail, a negative score is added which may still direct them to the spam folder. \n\nTo ensure that emails from yahoo groups are completely ignored, Ken should consider implementing a Procmail rule for Yahoo groups lists before deploying it systemwide. \n\nRegarding the compensation rule, if Ken wants to avoid these emails being marked as spam, he might need to add his own compensation rule or increase the negative score randomly generated by the whitelist scorer."
   }, {
      "body": "Here is an update regarding the cvsroot/spamassassin/spamassassin/masses directory. Modifications have been made to the masscheck log and additions to masscheckrcs have been incorporated. Retrieving revision for masscheckv. The latest results from the mass check can now be printed from 'on' whenn. Also, the version of spamtest has been updated and will now print along with the results. Lastly, this sfnet email is sponsored by OSDN. If you're tired of your old cell phone, we have a new one available for free. For more information, check out our spamassassin commits mailing list."
   }, {
    "body": "Given the current confusion, let's allow these individuals until the end of today to upload their logs. On a related note, I accidentally left out the 'spamtrap' stuff from the corpus directory in my logs, but it should definitely be included. I'm unsure if you've included it in yours or not - it appears to be from Kelsey's mailtraps on Thursday, August at am. Also, it seems that the files Justin Mason provided are outdated, as they have no date comment and will be named nonspamdanielplog, nonspamdanielrlog, nonspamduncanlog, nonspamjameslog, nonspamlaagerlog, nonspammessagelabslog, nonspammsquadratlog, nonspamolivierlog, nonspamoliviernlog, nonspamquinlanlog, nonspamrodbegbielog, nonspamseanlog, and nonspamtheolog. Lastly, the SFNET email you received is sponsored by OSDN and seems to be promoting a free spam assassin talk mailing list."
   }, {
   "body": "On Thursday, August [date] at [time], Justin Mason and Craig Rhughes discussed a change in the meaning of the 'lang' prefix. The new interpretation would be to run these rules if the language matches what Textcat identifies for a message, as opposed to using the locale which is currently in use. I had forgotten about this. However, this does not help with the findingbrokenrules QA case. It does aid if you have a corpus of German spam and non-spam messages to feed it and you're not in a DE locality. This SFNet email is sponsored by OSDN. Tired of the same old cell phone? Get a new one for free from our spamassassin talk mailing list."
   }, {
      "body": "I believe you're asking about your public key and whether it is necessary for someone to buy licenses of SpamAssassin Pro. To clarify, the person in question does not need your public key specifically. However, if you wish to ensure that emails from them are not spam, you might consider adding a Habeas header to your mail. This could potentially help verify that the emails are coming from a trusted source. Nonetheless, enforcement will be crucial in this case, and we'll have to see how they handle it. It is theoretically possible to sign messages to someone's public key using creative scripting and openPGP-compatible software."
   }, {
       "body": "Hello Luiz Felipe Ceglia, Staff Terenet,\n\nI understand you have installed SpamAssassin on your Postfix MTA server and are looking to test it on your email account before applying it site-wide. You've configured Procmail and SpamAssassin as described in the installation guide. However, the spams are getting through untouched when you run it.\n\nIt seems there might be an issue with your rules or configuration. I suggest checking the following:\n1. Ensure that your SpamAssassin rules (usrbinspamassassin c etc/mail/spamassassin-rules) are correctly set up and functioning as intended.\n2. Verify if the spams are getting tagged as spam but not blocked or moved to the junk folder.\n3. Review your filter settings, as there might be an oversight that's allowing spam messages to pass through.\n\nHope this helps! Let me know if you need further assistance.\n\nRegards,\n[Your Name]"
   }, {
       "body": "The latest DCC version of the DCC source is now available and we should begin addressing DCCM bugs related to handling a nonresponsive server. Modify sendmailcf to reject unauthorized relay attempts with a temporary failure when they are intended for DCC but DCCM is not running, this will prevent leakage of relay spam. Use the new hackmc script to install this change in sendmailcf. Remove whitelisted entries from cdcc stats output to provide more space for totals. Prevent empty dccproc log files as suggested by Krzysztof Snopek. In addition, fatal errors should cause dccproc to exit to avoid rejecting mail as noted by Krzysztof Snopek. When server hostnames share common IP addresses, prefer the server with the non-anonymous client ID as suggested by Krzysztof Snopek. This is regarding the DCC mailing list on sfnet, sponsored by OSDN."
   }, {
      "body": "The current situation is regarding a Whitelist RBL (Realtime Blackhole List) for Ironport's Bonded Sender, which essentially serves as a whitelist where you post a bond to be included and lose it if spamming occurs from that IP address. On the other hand, DNSBL (Domain Name System-based Blackhole List) allows checking if an IP address has been blacklisted by someone. However, there is no existing service offering a DNS-based Whitelist. The reason for this is that DNS lists, whether white or black, are effective only for a limited number of IPs. If a binary decision (accept or reject) needs to be made, it will result in fewer errors by rejecting the blacklist and accepting everything else rather than the other way around. A whitelist is beneficial only when mail is desired from a restricted number of known sources, or when a secondary system like SPF is utilized to decide the course of action for the large, unlisted masses. Most MTAs (Mail Transfer Agents) make only this binary decision due to the high cost of the secondary computation. However, with SpamAssassin's cooperation, it might be worth exploring this idea further. It is also potentially beneficial if commercial anti-spam outfits agree to factor this in."
   }, {
      "body": "I'm a bit surprised that spams are managing to hit my clean corpus, as I suspect someone may have forwarded a spam that then got processed into my corpus. My corpus is quite clean and I usually don't get spam hits, but it seems like it's being forged already. To address this, we could try to figure out which non-spams are hitting and improve the rule. For instance, removing spaces from the list of gap characters might help. \n\nI subscribe to Media Unspun newsletter and a few others that regularly use the 'headline' thing. Splitting it into one that matches gappy text with punctuation characters and another that matches spaces between characters would probably improve its effectiveness if anyone is interested. If you encounter any issues, I suggest filing a bug report. \n\nRegarding the SFNET email, it seems to be sponsored by OSDN and promoting the same old cell phone 'get a new one for free' spam. The SpamAssassin development mailing list might want to be aware of this."
   }, {
    "body": "Are you using 'usr/bin/spamassassin c etc/mail/spamassassin-rules' with line breaks, or is it all on one line as 'usr/bin/spamassassin c etc/mail/spamassassin-rules all'? It should be the latter. This SFNET email is sponsored by OSDN. Tired of that same old cell phone? Get a new one for free with SpamAssassin talk mailing list."
   }, {
    "body": "Dear Brian R Melcer,\n\nI have rephrased your email as follows:\n\nI have successfully installed and tested SpamAssassin on macOS X, however, I'm still encountering issues with spamd. In addition to exploring new and different uses for SpamAssassin under macOS X, I would appreciate hearing from those who are also using it in this environment.\n\nRecently, we have converted our SpamAssassin setup to utilize Amavisd within our Postfix configuration. If you're using Amavisd-new, you won't need spamd running as Amavisd-new directly calls SpamAssassin functions.\n\nRegarding the PGP key exchange, I have attached my public key (MikeLeone) for your reference. Sometimes, you might find yourself being either the 'pigeon' or the 'statue' in this random quote. \n\nBest regards,\nRandom Quote Generator\n\nP.S. This SFNET email is sponsored by OSDN. Are you tired of the same old cell phone? Get a new one for free! If interested, visit spamassassin-talk mailing list."
   }, {
     "body": "Dear Daniel Quinlan,\n\nI believe there may be some discrepancy in your estimation regarding the reporting timeframe and the accuracy. Another point to consider is the advantage of an HLL habeas licensee list, which would be less extensive than a test for the mark of HIL but more timely and accurate. If an IP address appears on the HLL, it could receive a significantly negative score that exceeds the habeas mark alone. Regarding your SFNET email sponsored by OSDN, I am growing tired of the same old cell phone spam offers. I have signed up for the SpamAssassin talk mailing list to filter out such unwanted emails."
   }, {
     "body": "Dear Craig Hughes, \n\nThe GA run on the current corpus is currently averaging a higher false positive score of points compared to before. Some adjustments are needed, such as rule elimination, to bring this down, although it may not be sufficient in many cases. I will set the scores for the habeas and Ironport tasks considering a sensible estimated likelihood of compliance with habeas bonded sender rules and b score correction level needed to achieve project purposes using the scoreranges stuff. \n\nI would like to bring your attention to the fact that my aggressive anti-FP evaluation code resulted in an average false positive of points, with FPs and overall accuracy. However, I observed you reverted back to the other method. Just thought you'd find this information useful.\n\nP.S. The SFNET email is sponsored by OSDN. If you're tired of the same old cell phone spam, check out our free SpamAssassin talk mailing list."
   }, {
     "body": "I have rephrased your email as follows: \n\nDear team, \n\nToday, I received a support ticket from one of our technical staff stating that SpamAssassin is reporting messages as probable spam even when they are not, causing confusion for our customers. They inquired why this occurs and if we can change it. After considering the issue, the only explanation I could find was that it was easier for the programmer to code it this way. However, their concern was that this will generate more support calls, consuming both time and resources. It seems counterintuitive for a customer to use SpamAssassin without understanding its purpose. I believe we should look into this matter to ensure customer satisfaction and minimize unnecessary support calls. For further discussion, you may want to refer to the Perl documentation for Sortlynx dump, Svanstromcomt, this sfnet email is sponsored by OSDN, and for those tired of their old cell phones, there are new ones available here for free. Regards."
   }, {
    "body": "Recently, I have been receiving spam emails that appear to originate from certaintytech and are being delivered to my email address. This is due to the fact that both the 'From' and 'Reply-To' addresses have been set to mine. Here are a few suggestions on how you might address this issue:\n1. Check your account settings on the site where the all (email forwarding) service is being used. You mentioned using a sitewide all, perhaps there is an option to disable it temporarily.\n2. If disabling the all service is not feasible or desirable, consider setting up email filters to automatically move suspected spam messages into a separate folder for review.\n3. Consider using a different email address for services that have a history of generating spam.\n4. You might also want to consider reporting these emails as spam to your email provider.\n\nPlease note, turning off the all service may have disadvantages, as it does have some advantages in terms of convenience.\n\nThe sponsor for this sfnet email is OSDN, and the footer mentions a free cell phone offer. Additionally, I am subscribed to the spamassassin talk mailing list.\n\nSincerely,\ntony per scientiam ad libertatem through knowledge towards freedom genom kunskap mot frihet c perl eprint for sortlynx dump svanstromcomtthis"
   }, {
    "body": "Hello, is there a collection of real-world spam messages available that I could utilize to test my setup? This email is sponsored by sfnet and promoted by osdn. Tired of the same old cell phone spam? Get a new one for free here! If you're interested, sign up for our SpamAssassin talk mailing list."
   }, {
    "body": "I'm providing an update regarding CVSroot/spamassassin in the debian directory. The log file spamassassin/debian/rc has been modified. To use the daemon version of spamassassin (spamd), please edit etc/default/spamassassin. If you prefer using spamc, which is equivalent to spamassassin p, feel free to do so. However, if you've enabled spamd and installed the spamc package, use spamc instead. To add rules or change scores, edit the template in the appropriate location. If you wish to be notified of spamassassin commits, consider subscribing to the spamassassin-commits mailing list. This email is sponsored by osdn and can be replaced with a new free cell phone."
    }, {
    "body": "Tony, regarding your query about Habeas on August at am, I apologize for the inconvenience but there is currently no such thing available online. Habeas is employing a blend of copyright and trademark law to safeguard their sender warranties. Although they aim to patent their system, they have yet to receive the patent."
   }

   {
    "body": "As for your need of a new cell phone, we've got you covered! Here's an opportunity to get one for free:"
   }

   {
    "body": "Please note that this SFNET email is sponsored by OSDN. If you find the constant spam from your current cell phone annoying, consider this offer for a new one."
   }, {
      "body": "On Tuesday, August, Matt Sergeant informed me that he believes he currently has the developer release of our product, though it is not the same as the Gold version. The only difference I am aware of is the path to a single helpfile which we do not utilize anyway. I also encountered an issue with the help program crashing whenever I search for 'Windows'. It is unclear if this is a feature or not. For knowledge towards freedom, Genom Kunskap mot Frihet, C Perl Eprint, Sortlynx dump, Svanstromcomtthis SFNet email is sponsored by OSDN. Tired of the same old cell phone? Get a new one for free! (SpamAssassin Talk Mailing List)"
   }, {
    "body": "Justin Mason appears to be similar to TMDA in terms of functionality. The filing date is July, and I assume you've come across this situation before, but thank you for bringing it up. Even though TMDA could potentially be prior art, it might still cause issues. However, since the core functionality of TMDA was established before the filing date, it seems that TMDA may not pose a significant threat. If anyone with experience in this area has insights, I would appreciate recommendations on whether or not to pursue this further."
   }, {
       "body": "Justin Mason, I understand your concerns regarding SpamProxyD in the distro. Since we don't have direct involvement in their creation and maintenance might not always be beneficial, especially when it comes to supporting code we didn't initially write or when the original coder may not want us to maintain it. I propose a solution where we create new CVS modules and Bugzilla categories for other clients if there is enough interest and a designated maintainer."
   }, {
    "body": "I support the idea of creating new CVS modules and Bugzilla categories for other clients, given there is enough interest and a maintainer. Regarding the CVS, I suggest that many projects might find it easier to simply sign up as a new project with SourceForgeNet instead, depending on their processes. This could potentially save them from having to go through us."
    }, {
    "body": "Dear Justin Mason,\n\nI believe Procmail can handle this directly, as suggested at the top of your etcprocmailrc file. If you have set dropprivs to yes in that file, Procmail will drop any privileges it might have had due to suid or sgid. This is useful if you want to ensure that the lower part of the etcprocmailrc file is executed on behalf of the recipient.\n\nRemoving setuid/sgid bits from programs that do not require them is always a good practice, a general rule for system administration - don't grant permissions unless it is absolutely necessary.\n\nAt our school, we have a cardinal rule: no shooting at teachers. If you need to use a gun, shoot it at a student or an administrator instead.\n\nBest Regards,\nPrinceton Review Team"
   }, {
      "body": "On Tuesday, August [AM], Justin Mason and Tony Svanstrom discussed a potential antispam method in SpamAssassinTalk. This method suggests an optional trust code or trust list, or at least a trust web based on online mail delivery at a recipient's email address. The sender is required to visit the trust web and send online, or enclose the recipient's trust code in the mail and send in another way, other than the mentioned ways. After the sender's email address has been automatically stored in the recipient's trust list, they can subsequently send emails to the same recipient via any feasible method. This strategy reminds me of TMDA (Trusted Notifier Data Architecture). The filing date is July [Granted]. Have you, as a TMDAer, encountered this before? I assume TMDA is prior art but could still potentially cause issues."
   }, {
    "body": "It appears that Justin Mason has filed a patent for a system similar to TMDA in July, while the first release of TMDA was in April. This means TMDA's core functionality was fully established before the filing date. However, since TMDA could potentially be considered prior art, it might cause some trouble. I haven't seen this situation before, but thank you for bringing it to my attention. Would anyone with experience in this area have a recommendation on whether this should be pursued or not?"
   }, {
       "body": "On Tuesday, Jason R. Mastaler's project sounds a lot like TMDA to me; filing date is July, granted May. I haven't encountered this before, but thank you for bringing it to my attention. I presume TMDA is prior art, but it could potentially be problematic. Yes, TMDA's core functionality was fully established before even the filing date. Anyone with experience in this area has any recommendations on whether this should be pursued or not? If you believe you can survive it, please fight back. I recently found a patent for this; however, I've discovered others that are common sense things that any geek could implement with his script/shell language of choice. It seems like we're witnessing the new wave of 'namers'; it used to be domain names, now it's all the basic general ideas they can think of and patent them through 'per scientiam ad libertatem'. This is akin to knowledge towards freedom in Latin or genom kunskap mot frihet in Swedish. I have attached a C Perl Eprint for sortlynx dump svanstrom.com as an example."
   }, {
    "body": "On Tuesday, August 10th, Leroy B. is inviting you to explore Jabber, the world's fastest growing real-time communications platform. Instead of simply using IM, build it in your SpamAssassin Talk mailing list."
   }, {
    "body": "I have been receiving similar emails as well, and I believe they are using the domain registry database to obtain victims' addresses. The email 'sfnet' is sponsored by Jabber, the fastest growing real-time communications platform globally. Instead of ignoring or marking them as spam, consider incorporating them into your SpamAssassin Talk Mailing List for further analysis."
   }, {
    "body": "On Wednesday, August 12th, Theo van Dinter will be at Malte's street. I receive around these per week from TrafficMagnet, which Google convinces me are worth their own rule. Recently, I cleaned my spam corpus of them but these are my current overall spam/non-spam labels for all messages from TrafficMagnet. I have put it into a CSV file for testing purposes. Let's see what GA run thinks about it. Malte says coding is an art, this SFNet email is sponsored. Jabber - the world's fastest growing realtime communications platform - don't just IM, build it in spamassassin talk mailing list."
   }, {
       "body": "Dear Steve Thomas, I too have been receiving similar emails. It appears they are extracting victim's addresses from the domain registry database and possibly using web scraping on top of that, based on my observations. I recently had a conversation with someone about this issue on the ok-trafficmagnet mailing list. It seems that ok-trafficmagnet is now being accessed for mapping purposes by a junior admin. After catching up on emails, I'm grateful to Jeremy for sharing the SFNET email which is sponsored by Jabber, the fastest growing real-time communications platform worldwide. Instead of just using it for instant messaging, consider building it into spamassassin's talk mailing list."
    }, {
    "body": "On Wednesday, August 18th, Steve Thomas arrives here. I too receive many of these emails, and I believe they are using the domain registry database to pull victims' addresses. They are crawling through the pages and sending their offers to all addresses they find. However, Theo will not receive any offers since he does not publish his address there. Malte Coding is art. This SFNet email is sponsored by Jabber, the world's fastest growing real-time communications platform. Not just instant messaging, but build it in SpamAssassin's talk mailing list."
   }, {
    "body": "I've rephrased your email for clarity: \n\nAdditional comments regarding the usage of 'just like' (i.e.) construct, which may sometimes produce broken HTML tag argument values with inconsistent case throughout the document and include color arguments without the '#' or in front of the hex/RGB code. There might also be an RGB code typo on 'onmouseover' and similar elements. While I am unsure if some or most of these issues are functional in practice, they could potentially be worth checking out. \n\nYou are receiving this mail as you are either a contributor to the bug or someone who is monitoring its progress. This SFNet email is sponsored by Jabber, the world's fastest-growing real-time communications platform. Please note that this message is also sent to the spamassassin-devel mailing list."
   }, {
       "body": "The CVSroot/spamassassin/spamassassin-masses directory has had an update, removing the evolvecxx_log file. This file and the 'old evolver' have been deleted from sfnet. The email is sponsored by Jabber, the world's fastest growing real-time communications platform. Instead of just IMing, build it in spamassassin on the commits mailing list."
   }, {
    "body": "Update regarding CVS root/spamassassin/spamassassin directory:\nModified manifest log comparing with the old one.\nChanges in manifest.rc files have been noticed.\nRetrieving revision differences.\nUpdating manifestv and retrieving new revisions.\nComparing diffs between b, w, u, d manifests and augmenting them.\nAdjusting massescorpus policy.\nSubmitting massescraigevalvec, massesevolvecxx, masseshitfrequencies for review.\nMentioned: masseslibmailarchiveiteratorpm (SFNET)\nThis email is sponsored by Jabber, the fastest growing real-time communications platform worldwide. Instead of just using it, consider building it into spamassassin via the commits mailing list."
   }, {
    "body": "If you're referring to Epiphany which is celebrated in January, then yes it is a month. However, I believe you are thinking of Christmas, which is not celebrated in January. As for your joke about celebrating Christmas in January or even earlier, I appreciate the humor. On a different but equally amusing note, a spam message I received yesterday started with 'I bet you haven't realized that Christmas is just months away.' Interestingly enough, I wasn't aware of it either here in the US, as Christmas is less than months away. By the way, I've never seen the international month line, but I suspect it doesn't exist. Strangely enough, I received an email today suggesting that jabber, the world's fastest growing real-time communications platform, could be integrated into SpamAssassin's talk mailing list. As always, keep the humor flowing!"
   }, {
    "body": "Justin Mason, Phil Lawrence, here's a clarification regarding your concern about the 'nomime' option in SA. The issue arises when dealing with MIME (Multipurpose Internet Mail Extensions) messages. If you don't use the 'nomime' option and receive MIME emails, the :internet modules associated with SA become unavailable for these types of messages. This means that your incoming MIME mail won't be checked by SA unless you specify 'nomime'. I hope this helps clarify the situation."
   }, {
      "body": "I believe the changes are nearly complete, with only minor score adjustments or additional comments regarding broken high-fping rules needed. I would like to know if everyone agrees and whether anyone has encountered any issues with the new auto-conf code or found bugs from the merge of the spamcbsmtpsupport patch. By the way, this email is sponsored by SFNet - Jabber, the fastest growing real-time communications platform. Kindly consider integrating it into SpamAssassin development mailing list."
    }, {
      "body": "Hi Jim McCullar from The University of Alabama in Huntsville,\n\nI'm having trouble building SA under Digital Unix, as I'm encountering a compile error and numerous warnings regarding spamc. The Perl makefile works fine, but when I run 'make', I get the std fmt d ieee intrinsics error. The errors are related to type mismatches in several places, including msgbuf, headerbuf, buf, and outbuf. These pointers have types char, while they should be of type unsigned char. Additionally, there seems to be a problem with the linkage of 'inaddrt' and its prior declaration in the scope.\n\nCould you please suggest a way to resolve this issue? I appreciate your help.\n\nBest regards,\n[Your Name]"
   }, {
      "body": "Dear Robin Lynn Frank, Director of Operations at Paradigm Omega LLC,\n\nIt appears you have concerns about using Habeus as it might seem like a potential loophole for spamming. From a spammer's perspective, setting up a server with Habeus headers and continuing to send out spam until reported, then reconfiguring the server and reconnecting to a different IP, seems to be an effective strategy. However, if no one can trace the connection between the websites your spam is directing users to and your own IP, you would indeed benefit from making it easier for spam to bypass defenses.\n\nOn the other hand, if you are not a spammer, this argument might not apply. It's important to note that setting up SpamAssassin can help filter out unwanted emails without losing legitimate ones.\n\nBest regards,\nThe Assistant"
   }, {
      "body": "Subject: Readiness check for new autoconf code and merge of spamc bsmtpsupport patch\n\nHello everyone,\nI believe we're almost there, just needing some minor adjustments to scores or clarifications on the brokenhighfping rules. What are your thoughts? Has anyone encountered issues with the new autoconf code or found a bug from the merge of that spamc bsmtpsupport patch I checked out from CVS? When I run make test, it fails terribly, seeming to look in my siteperl spamassassin code instead of the build directory. For example, the spamassassin test can't locate object method 'checkforfromtosame' via package ::permsgstatus at line. If anyone else is encountering this issue, please let me know. As for the SFNET email sponsorship, it seems to be related to Jabber, the rapidly growing real-time communications platform. I guess we should consider integrating it into spamassassin development.\n\nBest,\nJustin Mason"
   }, {
    "body": "To update SpamAssassin, you only need to install the new tar.gz file as if it were a fresh installation. There's no need to halt incoming mail or any similar actions. Thank you, Mike Michael Clark, WebmasterCenter for Democracy and Technology.\n\nJoin our activist network! Your contribution can make a difference.\n\nThis SFNET email is sponsored by Jabber, the rapidly expanding real-time communications platform. Instead of just IM, integrate it into SpamAssassin and Talk mailing list."
   }, {
      "body": "The ISP WanadooFR, which is the number ISP in France and the third in Europe, has been using non-compliant mail that is notorious for being unresponsive to spam abuse complaints. Some of its more militant administrators have even blocked them completely. On a related note, SFNET email, sponsored by Jabber - the world's fastest growing realtime communications platform, does not just imply building it into spamassassin, but encourages integrating it for effective spam filtering. This was discussed in the talk mailing list."
    }, {
     "body": "Michael Moncur from Starling Tech has expressed concerns about the Habeas feature in SpamAssassin, viewing it as a potential backdoor for spammers and believing that it was prematurely added. He suggests whitelisting bulk emailers like Amazon or eBay but feels individuals won't bother with it. Michael also highlights the possibility of spammers forging Habeas headers and their legal evasion. He recommends subjecting Habeas to the same testing and scrutiny as any other potential new rule. When testing against his corpus, he found that the Habeas score is currently harmless but still appears unnecessary. He references Napoleon's quote about not interrupting an enemy when they are making a mistake."
   }, {
      "body": "In order to update SpamAssassin, you will need to install the new targz file as if it were a fresh installation. There's no requirement to halt incoming mail or any similar actions. However, if you are utilizing spamd, please remember to stop and restart it. This is for Larry Rosenman from Steamboat Springs Drive, Garland TX. This email is sponsored by SFNET, the world's fastest growing real-time communications platform. If you're using SpamAssassin in Talk, don't forget to join the relevant mailing list."
   }, {
       "body": "Dear Team,\n\nI believe we have made sufficient progress, with just a bit more adjustment on some minor score tweaking and commenting of certain broken high-ping rules. Some tests are producing errors here and there in the test scripts, but I believe the subtests failed due to issues that can be resolved.\n\nPlease find attached four crates without any stones, and four empty crates with no stones. The fifth inline is as follows:\npgp gnupg for more information, see end signature.\n\nThis email is sponsored by Jabber, the world's fastest growing real-time communications platform. I would also like to bring it to your attention that my email address has been encrypted using GnuPG, as a registered Linux user on Debian Linux. If you need more information about pgp/gnupg, please refer to the end signature.\n\nBest,\nJustin Mason"
   }, {
      "body": "On Wednesday, August [date], Robin Lynn Frank is warning that if someone were a spammer, they would set up a server, send out spam using Habeas headers, and continue until they were reasonably certain they had been reported. Then, they would simply reconfigure the server and reconnect to a different IP address. As long as no one can establish their connection to the websites their spam is directing people to, they remain 'home free'. This practice is enabled by Habeas' Infringers List, which blacklists users who use their trademark without permission, causing emails with misappropriated headers to be tagged as spam instead of being allowed through. This may happen independently of the IP address, requiring frequent changes in domain names and server locations when sending spam. Additionally, a little haiku included in this email is a copyrighted work, adding another layer of potential legal issues for the violator. Habeas has a team of high-powered lawyers ready to take action against such offenders. The goal here is to give them the necessary legal leverage to combat spammers and allow through only legitimate emails. This SFNET email is sponsored by Jabber, the fastest growing real-time communication platform. Consider integrating SpamAssassin into your mailing list for better protection."
   }, {
      "body": "Brian McNett, \n\nThe issue at hand is straightforward: Habeas maintains a list called the 'Habeas Infringers List.' Using their trademark without permission may lead to inclusion on this list. When sending spam with misappropriated headers, users of SA will tag your mail as spam instead of allowing it through. This action can occur independently of IP addresses, so be prepared for frequent changes in domain names and server movements, depending on the speed at which you send spam.\n\nAdditionally, the little haiku provided is a copyrighted work. Habeas has the right to sue to protect this copyright, as well as their trademark. This doubles their legal leverage against violators. They have strong legal resources who are ready to take action against offenders. The objective here is to provide them with the necessary legal power to eradicate spammers from business and not only block their mail but allow through legitimate emails that are not spam.\n\nIf a spammer forges headers, please be mindful of the actions of Robin Lynn Frank, Director of Operations at Paradigm Omega LLC.\n\nP.S. This email is sponsored by Jabber, the fastest-growing real-time communications platform. Instead of merely using IM, consider building it into SpamAssassin, Talk mailing list."
   }, {
       "body": "Justin Mason, it appears you're preparing a patch for configuring NetBSD, OpenBSD, and possibly FreeBSD using the new autoconf code. You mention that you found a bug during the merge of spamci. If the patch is ready and tested in the next half hour, I would suggest waiting for potential user reports before deploying it as not everyone can follow development during work hours. If you deem it ready, I will hold off on deployment for a few more hours to allow for such reports. This SFNet email is sponsored by Jabber, the world's fastest growing real-time communications platform. Your work is also being integrated into the spamassassin-devel mailing list."
   }, {
     "body": "Dear Dickinson College Associate Director System and Network Services,\n\nI am a new user, or about to be, of SA but have encountered some compilation errors that are preventing me from installing. Instead of combing through the code, I thought it best to ask here.\n\nWhen I run the 'make' command, I receive an error message regarding the following line in the addrt declaration:\n\nspamd spamcc\nThe base type for internet spamdspamcc in this declaration has no linkage and has a prior declaration in this scope at line number in file usr/include/sys/types.h (nolinkage typedef unsigned long inaddrt). The referenced type of the pointer value msgbuf is char, which is not compatible with unsigned char ptr. There is also a mismatch if bytes fullread in msgbuf spamdspamcc.\n\nIn addition, the referenced type of the pointer value headerbuf is char, which is not compatible with const unsigned char ptr. There are lots more where they came from. Any ideas what can be done? Thank you in advance.\n\nBest,\n[Your Name]"
   }, {
       "body": "The CVS root/spamassassin/parserules directory has been modified. The parserules formasses log has been updated for bug fixes in the parserulesformassesrcs. The retrieved revision shows differences between the current and previous versions of parserulesformasses. The augmented parserulesformasses have been committed. If the outputfile is defined, use it to store the temporary rules (tmprulespl). Please note that this email is sponsored by sfnet, the world's fastest growing real-time communications platform. Discuss further on the spamassassin commits mailing list."
   }, {
    "body": "Dear Robin Lynn Frank, \n\nI believe I understand your concerns regarding Habeas. To put it simply, you seem to view Habeas as a potential loophole for spammers since they could utilize its headers to evade spam filters by repeatedly setting up new servers and changing IP addresses. This is a valid concern, as spammers would only face consequences if their connection to the targeted websites is established.\n\nAs you've pointed out, RBLs (Realtime Blackhole Lists) experience similar issues but lack a forgeable negative header rule with a score, making Habeas unique in this regard. You also mention that the negative score is significant and not empirically determined, and express concerns about the rule being added after the rules freeze without prior discussion.\n\nFurthermore, you question the effectiveness of the rule in actually reducing FPs (False Positives) since intelligent spammers could write emails that don't appear as spam. You also suggest excluding spam mailing lists from spam filtering.\n\nLastly, you mention that this SFNet email is sponsored by Jabber, the rapidly expanding real-time communication platform. Your suggestion is to incorporate Habeas into SpamAssassin's talk mailing list.\n\nI hope this clarifies your concerns and addresses your questions. Best regards."
   }, {
    "body": "The provided email contains several issues that need addressing. Here's a breakdown:\n1. The message ID points mentioned are invalid and point to incorrect locations.\n2. The new scores in the branch, though improved, may still change and are compared with an undefined previous score (invalidmsgid score).\n3. The total of which is better than assumed could be clarified further for better understanding.\n4. If the msgid issue is resolved, it might help improve things.\n5. There's a concern about allowing comments without potentially affecting spam detection, but there seems to be reluctance towards this change.\n6. The placement of a comment after the Message-ID header is unusual and could use explanation.\n7. Lastly, there's a request to open a bugzilla ticket for the issues discussed in this email.\n8. Sponsored by Jabber, this SFNet email discusses improvements to be made in SpamAssassin, specifically within talk mailing list."
   }, {
       "body": "Hello Jim James McCullars, Director of Systems Operations at Computer Network Services, University of Alabama in Huntsville, \n\nI hope this message finds you well. I'm experiencing some issues while attempting to build SA under Digital Unix. I receive compile errors and numerous warnings regarding 'spamc'. The Perl makefile works fine, but when I run the 'make', I encounter errors related to std fmt d ieee dintrinsics iusrlocalinclude dlanguagec spamdspamcc o spamdspamc lusrlocallib lbind ldbm ldb lm spamdspamcc. \n\nThe declaration in addrt has no linkage and has a prior declaration in this scope, with an error at line number in file usrincludesystypesh nolinkagetypedef unsigned long inaddrt base type for internetaddress. The statements containing msgbuf, headerbuf, buf, outbuf pointers show mismatches between char and const unsigned char types. \n\nCould you possibly suggest a way to resolve this issue? I appreciate your assistance. \n\nRegards."
    }, {
    "body": "It appears you are seeking a way to change the placement of SpamAssassin's results within an email. Unfortunately, there doesn't seem to be an equivalent option for 'reportbottom'. However, you can consider using custom rules or plugins to achieve this. Here is a link that might help: <https://wiki2.dynamicaction.com/index.php?title=SpamAssassin_Custom_Rules>. Please note that the provided link is related to creating custom SpamAssassin rules."
   }, {
        "body": "The CVSroot/spamassassin/spamassassin directory has been modified. The latest test log indicates that spamassassin can now run concurrently with another version installed in usr. The changes made have been documented in satestpmrcs, cvsroot, and the relevant scripts (envscript, scr, perl). In particular, the scripts for spamassassin (scr), spamd (envspamdscript, spamdscript), and spamd (spamdspamd) have been affected. This update is retrieving revision and the difference between the new version (aug) and the previous one (aug) is being compared. The latest change made to your name (tname) has also been reflected. For reference, this update was sponsored by sfnet and Jabber, the world's fastest growing real-time communications platform. Please find further details on the spamassassin commits mailing list."
   }, {
      "body": "On Wednesday, August [time], Robin Lynn Frank and Brian Mcnett were notified. The little haiku in question is a copyrighted work, which means that Habeas can, and must if necessary, sue to protect their copyright rights. Since it's also a trademark, this situation presents a 'doublewhammy' for any violators. Habeas has strong legal resources prepared to take action against offenders. The goal here is to provide them with the necessary legal leverage to eradicate spammers and not only block emails from them but allow through communications that are genuinely non-spam. If a spammer forges headers, there must be methods in place to trace their activities since they aim to profit from their spamming efforts. The means by which a court might consider evidence of being the spammer is another matter. As a side note, advanced spam filtering is encouraged for effective protection. This SFNET email is sponsored by Jabber, the world's fastest-growing real-time communications platform. Don't just use Jabber; integrate it into your SpamAssassin, Talk Mailing List."
   }, {
      "body": "It appears that the spammer is making money from providing spamming services rather than from responses to the spam. While it may be possible to identify and recover damages from those who paid for the mailing, finding the actual sender can be challenging. The main issue lies in the fact that the recipients of the spam are not benefiting from this situation. This is my primary concern about the whole 'habeas gain' principle as those most likely to be held liable are least likely to be the serious abusers. This email is sponsored by Jabber, the world's fastest growing real-time communications platform. I would suggest integrating spamassassin in your email system or mailing list."
   }, {
      "body": "This email provides an update on modifications to the 'cvsroot/spamassassin/spamassassin' directory. It mentions the execution of the 'configure' script in a log, and the retrieval of revisions for the configuration files. The netbsd support is being patched by Klaus Heinz. The script checks for various functions such as socket, connect, taccept, dlopen, herrno, optarg, inaddrt, and exmax. If these functions are found, they are cached for future use. If not, alternative methods are attempted. Finally, it mentions that this email is sponsored by sfnet (now known as Jabber) - the world's fastest growing real-time communications platform."
   }, {
      "body": "The usage of 'bare' to mean 'is deprecated' at libmailspamassassinhtmlpm line is being phased out. Also, the unquoted string issue in your installation seems peculiar as it doesn't exist in my version. Please verify your installation. Regarding the email sponsorship, Jabber - the fastest growing real-time communications platform, it would be beneficial to consider integrating it within SpamAssassin development mailing list."
   }, {
    "body": "Matthew Cline, there seems to be a way of identifying and tracking down spammers who aim to make money from their activities. However, proving their identity in court is another matter, as it can be challenging to find, prosecute, and win against individuals in countries not friendly towards such actions, like China for instance. Even if they officially respect copyright laws, lawsuits are time-consuming, potentially leading to years of spam continuing to flood our mailboxes. Contact information such as phone numbers, PO boxes, stolen cell phones, temporary email addresses, etc., is often used by spammers and not always included in their communications. It's puzzling, but then again, not many people would consider spammers as bright individuals. Some spam may not be commercial or could be sent by a third party, such as pump-and-dump stock scams, making the requirement for contact information less stringent for the spammer to succeed. \n\nOn another note, this SFNet email is sponsored by Jabber, the world's fastest growing real-time communications platform. Don't just IM, build it in SpamAssassin talk mailing list."
   }, {
    "body": "On Wednesday, August at pm, Robin Lynn Frank discusses a common misconception about spam. While forged headers can be easily detected, the primary method used by spammers to hide their originating IP addresses is not through header forgeries but by sending messages through open proxy servers. Open relay mailservers were once popular among spammers, however, they often reveal the originating IP and have become less attractive due to the prevalence of open relay blocklists and port blocking by many ISPs. Robin suggests that while a combination of forged headers and mail sent through an anonymizing open proxy may seem like a good indicator of spam, tracking a spammer to his physical location is not as challenging as one might think when legal recourse allows for subpoenaing records. This email is sponsored by SFNET and Jabber, the world's fastest growing real-time communications platform. Don't just use it in IM, build it into spamassassin talk mailing list."
   }, {
       "body": "On Wednesday at 1 PM, Daniel Quinlan noted that it can be challenging to prosecute and recover money from spammers operating in various unfriendly countries, such as China (a good example), despite their supposed respect for copyright law. Much of the spam that appears to originate from China, or advertises websites hosted there, is sent by and benefits U.S.-based companies. This spam often seems to come from open or squid proxy servers and is hosted there because these spammers are no longer welcome on all U.S. ISPs. However, involving the Chinese government in such cases where a U.S. citizen is violating U.S. law is unnecessary. Legal suits can take years between initiation and conclusion, resulting in years of spam in our mailboxes. The first court cases were actually concluded years ago, establishing many legal precedents that protect ISPs' rights to block mail and terminate service to spammers. \n\nDespite this, finding current information about long-time spammers like Alan Ralsky of Detroit, Michigan, or Thomas Cowles can be surprising. For instance, Ralsky is a well-known figure who has given interviews to the news media. If a specific corpus of spam can be connected to him, his street address is widely known, making him a prime candidate for lawsuits in any state with an antispam law. Cowles is another longtime spammer, but as far as I know, he was jailed for stealing computer equipment from his business partner, Eddy Marin. Another long-time spammer you might recall is Poplaunch. Spammers do not always include contact information in their emails, which can be puzzling. However, it seems that this is because the spammers are often not very bright.\n\nInterestingly, some spam is non-commercial or sent by a third party, such as pump and dump stock scams, so contact information is not strictly required for the spammer to succeed.\n\nIncidentally, when I was working at MAPS, there was a flap over a pump-and-dump spammer named Rodona Garst. It seems that she had an open file share on her laptop, and when she forged the wrong domain, the real owner hacked in and posted all her private information online. The SEC was very interested in confirming the validity of this information found online, leading to some interesting conversations this summer. The investigation took two years, but the financial penalty for operating a pump-and-dump scam isn't small - the wheels of government grind slow but they grind very fine indeed.\n\nThis SFNET email is sponsored by Jabber, the world's fastest growing real-time communications platform. Don't just IM - build it in SpamAssassin talk mailing list."
   }, {
      "body": "Now that I have SpamAssassin and MailScanner functioning, I would like to change the spam action from 'forwarded' to 'delete'. I modified the spamactions.conf file to defaultdelete, however, it is still being sent to the recipient. Could you please help me understand why this is happening? This SFNet email is sponsored by Jabber, the fastest growing real-time communications platform. Instead of just IM, let's build it in SpamAssassin discussion forum."
   }, {
      "body": "It appears there is a need to trace down a spammer as they aim to make profits from their spamming activities. However, finding, prosecuting, and winning money from someone in countries where spam originates, such as China, may be challenging due to legal differences and filter configurations that might disregard the SWE mark when messages seem to come from or through these countries. Spammers often fail to include contact information, which adds to the complexity. Some spam is non-commercial or sent by third parties, so contact details are not always necessary for the spammer's objectives. SA could be configured to ignore SWE marks in messages resembling third-party spam like stock scams. However, this would likely still allow spam with the SWE mark to reach the US. Additionally, it might be necessary to disregard SWE marks in messages that look like Nigerian scams. The author humorously points out that even though spammers may not be bright, they can still cause trouble. Advanced spam filtering is being discussed on this sfnet email list, sponsored by Jabber - the fastest growing real-time communications platform. Instead of just using spamassassin and talk mailing lists, consider building it in Jabber."
   }, {
       "body": "Dear Team,\n\nThe Habeas Infringers List (HIL) is specifically designed to combat spammers. While we have been successful in getting judgments against them, it's important to remember that this has been challenging, especially in countries where such judgments are harder to obtain.\n\nIt's accurate to say that regular spammers have never faced significant legal consequences before, with most continuing their activities without any hassles. However, I don't understand how one can assert that we can't track down spammers when it hasn't been attempted extensively.\n\nWe can subpoena the records of the business they spammed on behalf of. We can also subpoena the records of the ISP that provided them service and the credit card used for their accounts (often referred to as 'whack-a-mole' accounts). Private investigators could be employed, if necessary. These individuals are not secret agents; they are simply trying to make a profit.\n\nHabeas' business is about finding these spammers and putting them out of business. Given that Habeas' success depends on it becoming synonymous with 'not spam', I don't understand why we would assume failure in advance, thereby potentially undermining our chances of success.\n\nSpamAssassin, like a club, encourages thieves (spammers) to target those without protection. Habeas can play the role of LoJack, enabling the apprehension of these thieves and reducing the amount of spam in our inboxes. However, this can only happen if we are given a chance to succeed.\n\nBest,\nDan Kohn"
   }, {
       "body": "Dear Brian McNett, I wanted to clarify that the court cases you mentioned were concluded years ago and dealt primarily with copyright infringements, rather than ISPs blocking mail or terminating service to spammers. Regarding the SFNet email, it is sponsored by Jabber, the fastest growing real-time communications platform in the world. Please consider integrating it into SpamAssassin's Talk mailing list."
   }, {
      "body": "Dear Don Newcomer, \n\nI understand that you are a new user or about to become one of SA. However, you have encountered some compilation errors during installation which has prevented progress. Instead of delving into the code, I thought it would be wise to reach out here. Upon running 'make', you've noticed an error with the 'spamdspamcc' line in the declaration found within 'usrinc/ludesystypes.h' file. It seems that 'inaddrt' has no linkage and has a prior declaration in this scope, at a specific line number. \n\nTo resolve the issue, I would suggest editing 'spamcc' and adding the following lines right after the line where 'exmax' is defined: \n\n    extern char optarg\n    typedef unsigned long inaddrt // base type for internet address\n\nI hope this helps! Please note that these changes may also require addressing some warnings. \n\nBest Regards,"
      }, {
    "body": "This section of the email discusses an issue with CVS (Concurrent Versions System) that occurs when you modify a file on your disk, someone checks in changes, and then you pull an update. In this scenario, CVS encounters difficulties in merging your changes with the checked-in changes. The lines between the 'snip snip snip' section and the next one are your changes, while the following lines are the changes that have been checked in. It seems you may have overlooked the warning messages about conflicts that CVS issued during the update, as indicated by the c flag next to the file when listing the files being pulled. This email is part of the spamassassin-devel mailing list."
   }, {
       "body": "I believe it would be wiser to initiate Habeas with a less aggressive score initially, one that won't provide a straightforward path for spammers into everyone's inbox. Once we have evidence that the system is effective, we can increase the intensity of the score. Alternatively, let the GA determine the appropriate score, but this will take time as you'll need to accumulate sufficient messages for it. This should give us an idea if the presence of Habeus headers are good indicators of spam or not. If they are, I speculate that Habeus might not be successful. Moving forward, does Habeus charge a license fee to organizations wishing to use their copyrighted material? Or do they generate revenue from legal judgments? If they charge license fees, I'd be concerned that during tough times, they might be less critical of organizations we currently label as spammers in order to generate license fees. If not, I'd worry that they could swing the other way and target legitimate businesses in an attempt to generate more revenues from judgments and/or out-of-court settlements. Either way, it seems like they have an intriguing tightrope to walk."
   },
   {
       "body": "This email is sponsored for Geek Heaven's SpamAssassin Talk mailing list"
   }, {
     "body": "Dear Dan Kohn,\n\nI understand your concerns about the Habeas Infringers List and its effectiveness in reducing spam. Your point about the lack of empirical evidence that it will reduce uncaught spam, especially when dealing with spammers in countries where legal action is more challenging, is valid.\n\nHowever, I want to clarify that our intention isn't to use Habeas solely for business purposes. We understand the need to protect users from spam and are working towards making it effective against spammers. Your suggestion about starting with a less aggressive score and gradually increasing it as evidence of its effectiveness accumulates is a reasonable approach.\n\nI hope this addresses your concerns and we look forward to seeing Habeas in action. Let's continue the discussion on how we can make it more effective for all our users.\n\nBest,\n[Your Name]"
   }, {
   "body": "I believe I have gained enough insight into SA to understand that I can localize a score, however, I am not comfortable with using SpamAssassin as a means to generate business at the expense of our user base. This is the same conservative approach SpamAssassin has always taken when it comes to adding unproven RBLs and such. It would make more sense to start Habeas with a less aggressive score, one that will not provide spammers with a fast track into everyone's inbox. After we have observed the system's effectiveness, then we can increase the strength of the score. I suggest starting it with a zero score and treating it like any other unproven rule, scoring it based on actual results rather than promises. At present, my corpus does not contain a single non-spam or spam message marked with Habeas, which does not impress me and wouldn't likely impress the GA either. Rules with identical statistics are being dropped from SA right now, and I don't see why this should be any different."
   }, {
    "body": "It appears that SpamAssassin is hanging and memory usage remains high on your system when run for large emails (over a certain size, most people tend to ignore). This issue was observed after an hour of running SpamAssassin before it was killed. It is recommended to consider upgrading or skipping SpamAssassin for such large emails due to the known performance issues with HTML parsing. However, if you wish, you can wait for the upcoming release that addresses some of these issues, though it may not be a quick fix."
   }, {
     "body": "Hello Urban,\n\nThank you for your email and for your prompt response. I understand that you are having trouble with SA handling large emails, but cannot find any mention of an upper limit in the SA documentation regarding message size.\n\nRegarding your question about adjusting the userprefs file, unfortunately, there is no specific configuration to set a size limit for a message in spamassassin. However, you can configure procmail to filter messages based on their size before handing them over to SA.\n\nI hope this helps, and let me know if you have any other questions or concerns.\n\nBest regards,\n[Your Name]"
   }, {
     "body": "The CVSroot/spamassassin/spamassassin has been updated in the directory. A log has been added to the sample procmail recipe (procmailrcexample). The length limit for the sample procmail recipe has been set. Retrieving revision... Retrieving revision... Diff between the updates can be found... The changes have been made on Aug 2021... The mail will be piped through spamassassin unless it's a large message, as spamassassin can take a long time to process large messages. If the mail is tagged as spam, it will be moved to the caughtspam mbox. This is a sponsored email by sfnet. Welcome to Geek Heaven! For further updates and discussions related to spamassassin, you can subscribe to the spamassassincommits mailing list."
   }, {
      "body": "Dear Mike Burger, I'm writing to inform you that SpamAssassin now seems to be functioning flawlessly, following my previous inquiries. I appreciate your patience as I continue to work with SpamAssassin via spamc, spamd, and a global etcprocmail file. My question is, could this setup also be applied in the same manner? Specifically, would it be possible for spamc to skip files larger than a certain size? I understand that changing the size limit doesn't cause any harm; however, it seems prudent to consider this option. As you may know, coding is an art, and I find this SFNET email sponsorship and the SpamAssassin talk mailing list quite appealing - welcome to geek heaven! Best regards."
   }, {
    "body": "Urban Boquist has reported an issue with high memory usage on his system that persists even after an hour. He terminated the program for further investigation. It appears to be running on an Athlon processor and it's a bit slow but still, anyone else experiencing this hang? Alternatively, he might consider upgrading his environment which is currently running on a version from today on. Here are some relevant system details: Processing message for expecting bytes Aug Silence, Clean message for in seconds bytes, resident size about according to top. Ciao Klaus. This SFNET email is sponsored and welcomes you to Geek Heaven - SpamAssassin Talk Mailing List."
   }, {
     "body": "Dear Bart Schaefer, \n\nI hope this message finds you well. I wanted to bring up a point that seems unrelated to our current discussion but pertains to Amavisd, MimeDefang, and several other MTA plugins. These tools reject messages at the SMTP level if their scores surpass a certain threshold. The issue is, these high scores suggest massive false positive rates (FPS).\n\nIf a new release starts flagging all emails as spam with no higher FPS, it should ideally have a zero FPS since all filters would lower their thresholds significantly. My main point is that we should adjust our rescore algorithm such that a spam hit above the threshold does not benefit us because recovering from a false positive (FP) using compensation rules becomes much harder.\n\nSpam will naturally score higher than this, that's just how the scoring works. However, for our code to be effective and distribute scores across a wider range, we need to optimize it to hit the threshold accurately. This message is sponsored by Geek Heavenspamassassin mailing list."
   }, {
    "body": "The uppercase rules have not been tested on messages in non-English character sets or MIME encoded messages. I'm experiencing a high number of false positives with Japanese emails, and I suspect the encoding is causing this issue as Justin mentioned. However, he stated that this issue is fixed in the latest CVS version (Dans). This email is sponsored to Geek Heavenspamassassin mailing list."
   }, {
       "body": "Dear Justin Mason,\n\nThe main point I'd like to discuss is the need for our rescore algorithm to be balanced, so that high spam scores don't benefit us as they make false positives (FPs) harder to rectify using compensation rules. However, I believe the value it currently provides is not optimal.\n\nInitially, only spammy scores were considered, but I propose that the algorithm should be symmetrical and non-spammy negative values should balance out spammy positive ones, similar to how they do in SA today. In this scenario, anything scoring positively would be classified as spam, while anything scoring negatively would be considered non-spam. A score of exactly zero could be regarded as grey. I think the current approach adds an offset that may lead people to believe the system functions differently than it does.\n\nBest,\n[Your Name]"
    }, {
       "body": "Justin Mason, I made some adjustments to scores that Lintrules flagged as negative when they shouldn't be. However, it seems to have affected the results negatively. I suggest being cautious with tweaking and running a Logstoc Evolve C to check the new hitrates afterwards. It's worth manually adjusting in some cases but be aware of potential counterintuitive combinatorial effects. My inclination is that we should avoid tweaking altogether, Dan."
   }, {
       "body": "It seems that Justin Mason encountered issues with his algorithms during the nanananana conference on Friday, August. He mentioned that they appear to lack flexibility, whereas Craig's seem to be more adaptable."
    }, {
       "body": "Dear Daniel Quinlan,\n\nBefore we release the project, it would be beneficial to test a few additional score ranges for DQ. I suggest we could lower FPS slightly more, but I'm not sure there's much room left for further reduction which the GA can achieve. Please note that the AWL will reduce FPS, but its impact on GA scores hasn't been factored in yet.\n\nThe work being done on the GA and comparing different methods of score setting is very valuable and useful. However, we really need to get a release out as it's becoming less useful as time goes by. The FPFN rate with any scoring mechanism will be better than what we currently have. For DQ, you could consider allowing low and high scores to be evolved by the GA within ranges. I would be enormously surprised if it didn't end up with a more flexible approach for setting individual scores.\n\nThe issue with fixing low and high scores is not one of optimization but rather one of human-based concern that individual scores larger than about are dangerous and liable to generate FPs, and individual scores less than are dangerous and liable to be forged to generate FNs. Perhaps even adding an NYBias loop could be considered, although changing NYBias scores may only alter the evaluation functions' idea of what the ratio should be.\n\nAs far as I know, there's nothing major hanging out waiting to be checked in. Is there something specific you want me to look into?\n\nI will be online most of today, tomorrow, and Monday while working on the next DeerSoft product release. It should be an exciting one!\n\nRegarding our previous IRC discussions on IRCrhizomaticnet about SpamAssassin, the timezone difference has been problematic. I've been searching for the details of the channel but unfortunately, the specifics seem to have got lost in the shuffle.\n\nBest,\nYour Name"
    }, {
       "body": "Dear Rick Beebe,\n\nIt appears that you encountered an issue while compiling a file with SpamAssassin. The problem seems to be related to the makefile which copies localcf into etcmailspamassassin. The brackets around the 'f' test in the makefile might not be displaying correctly, causing a syntax error at line unexpected exit stop.\n\nSuggestion:\n1. Check the part of the makefile which copies localcf into etcmailspamassassin. Ensure that there are no issues with the brackets around the 'f' test.\n2. If the issue persists, try commenting out or removing the 'f' test temporarily to see if it resolves the syntax error.\n\nI hope this helps. Let me know if you have any further questions or concerns.\n\nBest regards,\nJim James Mccullars\nDirector of Systems Operations\nComputer Network Services\nThe University of Alabama in Huntsville\nHuntsville, AL"
   }, {
    "body": "Dear Justin Mason,\n\nI'm writing to inform you that the Razor functionality is now fully supported in our system, thanks to the changes made by an unspecified individual in your code (DNSPM and REPORTERPM). However, I've noticed that the modifications regarding Razor should point towards ::debugenabled instead of ::debug. I will be submitting a bug patch for this issue shortly.\n\nIn regards to the randomly generated MA driving everything, I wanted to let you know that our application is currently under construction.\n\nBest Regards,\n[Your Name]\n\nP.S. Here's the PGP signature for your reference: gnupg gnulinux\nFor more information, see hpkl"
   }, {
      "body": "Hello Team, it appears that some of you have hardcoded honor as the default catalog server. Currently, we only have three catalog servers running and honor is acting as a nomination-only server tonight. We will be completely turning off catalog support on honor starting now, so if you are specifying honor with the rsoption, please remove it to allow the agents to discover a nearby catalog server instead. Thanks for your cooperation and remember, the future is here - it's just not software design yet! Vipul Vipul Ved Prakash"
   }, {
       "body": "I am aware that I made changes to the catalogues during the week when they were problematic, but I rectified it since then and switched it back to Discovery for transparency. It appears some of you have hardcoded Honor as the default catalogue server. At present, we have three catalogue-only servers running, with Honor functioning as a nomination-only server currently. We plan to completely turn off catalogue support on Honor tonight. If you are specifying Honor using the rs option, please remove it and allow the agents to discover a nearby catalogue server instead."
   },
   {
       "body": "Also, I would like to bring your attention to an email sponsorship opportunity with sfnet. If you're tired of the same old cell phone, consider getting a new one! Check it out here for free RazorUsers mailing list."
   }, {
   "body": "I am looking for a guide on how to use Razor with Sendmail, as I cannot install Procmail on my hosting. However, I do have full access to the Sendmail alias list. Unfortunately, I couldn't find any relevant information in the Razor documentation. Could you please point me towards some resources that might help? I am a member of the RazorUsers mailing list on SourceForge. Thank you."
   }, {
   "body": "I have recently started using Razor and have found it necessary to whitelist several mailing lists, such as YahooGroups. However, I am unable to whitelist the addresses because they belong to individuals making posts. Therefore, I will need to find another field to whitelist when my code allows for it. I am curious if the submissions are not being careful or if these are questionable mailing lists that do not drop bad email addresses that eventually become spam traps. Any employee who has left my company more than three years ago is eligible to become a spam trap, as after three years of bounced mail, one would assume the list should have figured out they are no longer here. This issue is with the sfnet email, sponsored by OSDN. Tired of that same old cell phone? Get a new one! Here for free Razor users mailing list."
   }, {
       "body": "Good day Foxon Fri Aug, \n\nI have recently installed Razor and found it useful. However, I'm encountering a situation where I need to whitelist many mailing lists, such as Yahoogroups, but the issue is that the address is the person making the post, so I can't directly whitelist these addresses. I will need to find a way to modify my code to whitelist based on another field. Is it possible that some submitters are not being careful or are these mailing lists that don't drop bad mail addresses that might become trollboxes over time?\n\nI've had great success using the xbeenthere header to avoid Procmail tripping : cheers Billnynex Iroquois for Moron, a well-known Linux kernel hacker. William Stearns Mason, who builds kernels, and are part of this sfnet email that is sponsored by OSDN.\n\nTired of the same old cell phone? Get a new one here for free (razorusers mailing list)."
   }, {
    "body": "If you missed adding it during compilation, another option is to search your sendmail.cf for the word 'milter'. I'm not certain if there's a Sendmail-specific way, as it doesn't appear in the output, but this could be done with strings which Sendmail grep -i milter. If you get a long list of function messages looking phrases like 'miler is builtin', 'filter usage x requires milter support', 'dmiltermilter', 'miltercv', 'zarzycki exp', then it's not built-in. If you get something like :filter usage x requires milter support, dmilter milter s requires milter support, dmilter, miltercv, zarzycki exp, then it's also not built-in. Can anyone tell us the lesson that has been learned here? It seems none of us could defeat you; you gain wisdom. For more information on PGP/GnuPG, see [nbseend PGP signature](mailto:nbseend%20PGP%20signature). This SF.NET email is sponsored by OSDN. Tired of the same old cell phone? Get a new one for free. Join our razorusers mailing list."
   }, {
    "body": "Dear Paul,\n\nIf your Sendmail has been compiled with Milter support, you can effortlessly add smrazor. We have been using it without any issues and other users on the list have also mentioned it. Can you verify if Milter is included in your current setup? If not, consider recompiling Sendmail to include this feature.\n\nBest,\nJulian Bond (via sfnet email sponsored by OSDN)\n\nP.S. Tired of the same old cell phone? Get a new one for free here: [razorusers mailing list link]"
   }, {
     "body": "If milter was not included during the compilation process, you have two options: either recompile Sendmail with Milter support or use 'grep' to search your sendmail.cf file for the word 'milter'. If Milter is compiled in, adding smrazor should be straightforward. We have been using it without issues and others on the list have also found success with it. To confirm if Milter is included, you can check your personal configuration. Additionally, if you are tired of your current cell phone, check out the new options available here for free: [link]. This email is sponsored by sfnet."
   }, {
       "body": "To view all options and versions of Sendmail, try the following command: echo 'z path-to-sendmail' bt This command will provide similar information as sendmail devnull, but without Milter information. The z command gives you the Sendmail version out of test mode. However, please be aware that typing 'fbkillall finamefp' may not have the desired effect on non-Linux systems, especially when done by a privileged user. This command is mentioned from the killall manual page. Additionally, for information about application signing using PGP, see the end of this email. This email is sponsored by SourceForge and OSDN. If you're tired of your current cell phone, consider getting a new one here for free. For more details, visit razorusers mailing list."
    }, {
       "body": "Dear David, \n\nThe standard way to store passwords is not to store passwords directly in a database. Instead, it's recommended to store a salted hash of the password. When you get a claimed password, resalt it, compute the hash and determine if they are the same. This method has been used by Unix systems for years and larger hashes and salts should be used compared to old Unix systems. However, this approach is not applicable to database passwords used in most web applications. \n\nAs an alternative solution, I propose storing sensitive data such as the database password outside of the web tree, encrypting it, and keeping the encryption key elsewhere. This way, an attacker would need to obtain two different things. Additionally, create a user account with very limited access. However, if security is critical, consider creating a separate program that houses these database keys, and make the web program contact it through a limited protocol, only allowing necessary operations. There will be a performance hit due to this trade-off for improved data isolation. You can add specific operations later.\n\nMore information on this topic can be found in my book. \n\nBest,\nGiorgio Zoppi"
   }, {
       "body": "Hello, \n\nI'm looking for methods to create an almost unbreakable CD key. I was thinking about implementing a cancellation date and periodic renewal from a server or using self-signature on the resulting executable. However, I understand that this might not be simple due to the software piracy issue. Are there any suggestions or hints on achieving this goal? Thanks,\nYannick Gingrasnetwork"
   }, {
    "body": "Regarding your email about Fravias's website on reverse engineering, I suggest you check it out as it may help address some of your concerns. Some of the tips mentioned are quite portable but there are a few special considerations to take when implementing such schemes on a Unix system. I hope this information helps. Thanks for the input, Josh."
   }, {
     "body": "I believe you're asking about the terms 'cdkey' and 'unbreakable'. I assume 'cdkey' was a typo, perhaps you meant 'license key'. By 'unbreakable', I would interpret it as something that is extremely difficult to break or bypass. In this context, unbreakable would mean that no one could use the system without paying the periodic subscription fee. I suggest being more explicit about the problem you're trying to solve and the constraints involved. The system you're referring to might work offline but sync frequently with an offsite server, it may not be mass-produced CDs, but rather mass personalized downloads like Sun JDK. The question seems to be if the use of trusted hardware for software protection is worthwhile and if it truly enhances security. Considering DVDs by Yannick Gingras, coder for OBB, the answer could be 'obdurately buteonine bellwether', which means stubbornly resistant or hard to influence, referring to the difficulty of breaking through the software protection."
   }, {
       "body": "I am inquiring if there are any methods to create a CD-key for software, such that it becomes extremely difficult or nearly impossible to crack. Specifically, I'm interested in techniques like setting an expiration date and periodic renewal from a server, or using self-signatures on the resulting executable. However, I understand that resolving the entire software piracy issue may not be achievable through such means, but I seek guidance on making it very challenging. By 'CD-key', I presume you meant 'product key' due to a possible typo. When I say 'unbreakable', I refer to a product key that is extremely difficult to crack or reverse engineer. The problem I wish to solve involves the creation of a secure product key system, while considering constraints such as offline functionality and mass-production of identical CDs. Additionally, I'm aware that any software mechanism will be vulnerable to some degree, but I seek advice on strategies that minimize this vulnerability, particularly when it comes to validation routines within the executable."
   }, {
       "body": "Yannick Gingras, I believe there seems to be some confusion regarding the terms 'cdkey' and 'unbreakable'. By 'cdkey', I assume it was a typo and you meant 'license key' or similar. If 'unbreakable' was also a typo, then unbreakable here would imply that no one could use the system without paying the periodic subscription fee without authorization. However, your email lacks clarity about the problem you are trying to solve and the constraints involved. \n\nIt appears you're discussing an online system that may operate offline but poll frequently to an offsite server. Perhaps it isn't a mass-produced CD but rather a mass-personalized download like the Sun JDK. At this stage, nothing is finalized. The focus seems to be on finding ways to protect the software from unauthorized use.\n\nRegarding the use of trusted hardware, I understand that providing an answer requires knowledge of your business model, but generally speaking, it may not be worth the investment. However, the difficulty in cracking the product is a factor to consider. If the product requires occasional authentication, simple copying won't work as the product would need to be cracked.\n\nYour customer base seems to vary, with teenage kids being more cost-conscious and less concerned about viruses and trojans, making them more likely to use pirated software (warez). Corporations are likely to view matters differently. Is it more secure? While software techniques can offer some protection, they have their limits. Ultimately, the same is true for hardware, but cracking hardware may require resources beyond just labor.\n\nOne interesting point is that almost anything can be reverse engineered, but ensuring that doing so is uneconomical could potentially be a solution. For instance, DVDs were cracked by reverse-engineering software players, but the developers forgot to encrypt the decryption key, making it easier for piracy. A potential strategy could be to make cracking the product economically unfeasible."
   }, {
     "body": "Thank you for your email. Regarding the use of smart cards as trusted hardware, it seems there is some debate about their effectiveness due to potential vulnerabilities. The periodic shipping of smart cards upon subscription fee cash-in would not significantly increase the cost of renting the system, however, it's important to consider the cost and feasibility of upgrading these devices regularly to maintain security. Smart cards do have an internal processing unit but their ability to self-encrypt data and decrypt data needed by the system is a questionable point, as mangling the input of the system and keeping a reference of how long it was in service could potentially compromise this. It's crucial to weigh these pros and cons and ensure that any system using smart cards has robust security measures in place. I would recommend further research or consultation with a cybersecurity expert to confirm the safety of smart cards in your specific context."
   }, {
           "body": "Software vendors have been persistently attempting to combat software piracy for years, employing various methods such as specific words from a software manual that couldn't be photocopied, proprietary DVD encoding, and software requiring registration keys. However, these strategies haven't proven effective. For instance, Windows XP was equipped with an alleged anti-piracy measure, yet it didn't take long for the code to be cracked. The number of keygens for Windows XP is substantial, but the challenge lies in preventing multiple usable keys, especially when dealing with users who are not always online. This issue is more prominent in systems like health care that require stringent data protection. It's agreed that mass-produced CDs may not be immune to piracy in the near future due to market penetration. Incidentally, I appreciate the insightful comments provided so far. I'm currently delving into GDb's disassembler, but I'm unsure if it's a tool typically used by crackers. Any hints on Unix cracking tools would be helpful. Yannick Gingras, coder."
   }, {
      "body": "Yannick Gingras is questioning if the utilization of trusted hardware indeed enhances security. He points out that DVDs don't employ this technology, yet its value in terms of software security is debatable. Whether it is worthwhile or not depends entirely on the importance you place on securing your software. Robert Woodruff adds a thought: There is no limit to what one can achieve or how far they can go if they do not care who gets the credit."
   }, {
    "body": "Apologies for any potential confusion, but in literature this is commonly referred to as omitting one testing (or omit-one test, abbreviated as oot). If you're seeking additional information, I would recommend checking out David Leblanc in Seattle, WA, USA."
   }, {
       "body": "Tim Peters, I have not conducted any experiments on training set size yet and cannot provide an estimate of the optimal amount. However, I am confident that the current one is more than enough. Each call to learn and unlearn computes a new probability for every word in the database. There is an official way to avoid this in the first two loops (e.g., for msg in gblearnmsg, true, false, gbupdateprobabilities). I have implemented this but the process remains slow when dealing with thousands of messages in each loop. The total of ham and spam in the learned set is invariant across loop trips, and you could break into abstraction to exploit the fact that only probabilities associated with the words in msg change across those loop trips. This would make the runtime for each trip proportional to the length of the message in msg rather than the size of the entire database. I had not tried this approach but it seems worth considering. Another potential area for improvement is the observation that the highest value indicators usually appear early in messages, and for spam, there's a reason for advertising to strive to get your attention early. For instance, if we only bothered to tokenize the beginning of a message, results might deteriorate due to spammers exploiting this. However, including a large MIME part at the beginning of the message in practice might work fine sometimes, as an on-topic message might start well but then ramble. I remember the time when I was ten years old and went down to the fishing hole with my buddies. This guy named Gordon had a really huge head - wait, maybe that was Joe. Well, no matter, as I recall it was a hot day and everyone was tired. Human growth hormone, girl with huge breasts, blah blah blah. It appears that the current approach does not yield appreciable results from all but one testing, so perhaps we should forget about it for now."
   }, {
    "body": "David Leblanc, I noticed that you referred to a testing method as 'omit one testing' or 'oot'. In academic literature, this method is more commonly known as Omit One Test (OOT). I wasn't aware of the term 'oot', I believe I may have coined it myself. Thanks for correcting me."
   }, {
    "body": "Dear Montanaro, \n\nI was thinking about wrapping up my spam and ham test sets for inclusion with the Spambayes project. I've given it the thought it deserves, and I believe it would be beneficial to have several people working on the same test data. However, I face a few challenges: \n1. My current data subtree is quite large, with files amounting to more than a million bytes.\n2. Even if I had space to store that much data, I'm not sure my ISP would allow me to email it in one message. If necessary, I could break it up into smaller parts.\n3. There was an early mistake in the selection of data, and it turns out that the set goes back to the last millennium, which is not what I had hoped for. Currently, Greg Ward is capturing a stream coming into pythonorg, and I hope we can get a more modern and cleaner test set from that. However, if this stream contains any private email, it may not be ethically possible to make it available.\n\nCan you suggest any place to obtain a large, shareable ham sample? Everyone seems eager to contribute their spam data, but gathering ham data is proving to be the more challenging half of the process because spam and ham messages are so alike in many ways."
   }, {
    "body": "It's great to collaborate on the same test data, and I fully support that idea. However, my current data structure contains more than a million bytes in files, which could be challenging to send via email, even if compressed. Do you have access to a modern means of transferring messages, such as cloud storage or a file-sharing service? If we zip each set of the data individually and upload them there, it should compress well due to the similarity in the headers and such. \n\nAs for obtaining a large, shareable ham (non-spam) sample, options other than public mailing lists could be exploring archives or forums related to the specific domain of your data collection. Manually cleaning, distributing, and relying on my code and rebalancing script to further cleanse it might help with diversity. \n\nThe challenge with ham (non-spam) data is that it tends to be more tied to one person, not just intimate but unique, whereas spam is often similar in many ways. I save all incoming email for ten days in gzipped mbox format before it rolls over and disappears. At any given time, I have approximately 10 million messages, most of which isn't terribly personal, which I would cull before passing along anyway, and much of it is machine-generated, so its use might be questionable. Lastly, the data is all ham and spam mixed together; we could refer to it as a 'scrambled omelette' or a 'Denny's Grand Slam,' but skip."
   }, {
       "body": "Dear Tim,\n\nIt appears that for maximum effectiveness, high-value indicators in messages often present themselves early. This is also true for spam, as advertisers aim to catch your attention immediately. For instance, if our tokenizer only processed the initial part of a message, results might deteriorate. Neil Schemenauer\n\nSpammers could exploit this by including a large MIME part at the start of the message. In practice, this would likely work fine, but keep in mind that Timtestpy's current tokenizer only examines decoded text or raw message text if no MIME exists. Spammers could insert megabytes of unwanted content before the actual message and it wouldn't be considered, unless the email package is capable of parsing non-text parts effectively and skipping over them.\n\nTokens for the most interesting parts such as Content-Type, Disposition, Transfer-Encoding, Decorations are generated for all MIME sections. Schemes that remain ignorant of MIME are vulnerable to spammers adding arbitrary amounts of appealing text in the preamble area after the headers and before the first MIME section. Most mail readers do not display this area, but it appears first in the file, making it a priority for Graham's scoring scheme.\n\nHowever, I am not overly concerned about cunning spammers as I have seen no evidence of their existence. Even if they do exist, the open-source community is such that no particular scheme will gain dominance. Furthermore, there is no incentive for spammers to try to deceive just one scheme.\n\nIf you're out to make a quick buck, you don't waste a second on hard targets. Yours sincerely, Tim"
   }, {
    "body": "I have a test set here that is the last few years' email collection, and it's currently in a rather unpleasant state of spam, ham, and unclassified messages. These addresses are scattered across different ekiteknoisiconnect websites, making them prone to spam as well as the usual assortment. Additionally, there are customers complaining about credit card charges, people interested in the service asking questions about long-distance rates, and a substantial amount of commercial speech – essentially, things that SA gets wrong quite frequently. I'm currently trying to process it by feeding all parts (text, HTML, etc.) into the filters, as well as both selected headers (to, from, content-type, x-mailer) and a list of header count. This is yielding some promising results such as the xuidl that careless spammers often copy into their messages, although it's temporarily out due to its tendency to lower rates. I'm also removing HTML tags except for href and src. There's so much potential in these messages – note that I'm only keeping the contents of the attributes (Anthony Baxter). It's never too late to have a happy childhood."
   }, {
    "body": "Tim Peters wrote, he mentioned that he received a message with text similar to this - 'This is a HTML message and nothing else. Are you sure that's in a Text/Plain MIME section? I've seen it many times myself, but it has always been in the prologue between MIME sections, so it is something a non-MIME aware reader will show you as 'no'. He added that on his to-do list is to feed the prologue into the system as well, a snippet hopefully not enough to trigger the spam filters. Microsoft Outlook Express (produced by Microsoft) MIME-ole Sun Jan MultiPartMixed This is a MIME message MultiPartAlternative Text/Plain QuotedPrintable This is an HTML message Text/Html QuotedPrintable.' He clarified that there should not be any quotation marks in the body."
   }, {
   "body": "Anthony Baxter is currently processing various parts of text, HTML, and other data through the filters. Additionally, he is selecting a number of headers from 'xmailer' content type and a list of header count-of-header. This appears to be producing some useful results, such as the xuidl that many spammers inadvertently include in their messages. Tonight's plan might also involve incorporating all headers from non-text parts of multipart messages, which could help detect virus emails quickly. Anthony Baxter often shares this quote: 'It's never too late to have a happy childhood'."
   }, {
       "body": "Subject: Razor now fully supported\n\nDear Justin Mason,\n\nI have upgraded from my modified version to a slightly modified one, where I added a routine for evaltests and sep eclectic check. However, I encountered an issue while running it - 'No such file or directory' cannot call method log on unblessed reference at tagentpm line line. I haven't quite figured out why yet. More details to come.\n\nOn a positive note, Honey is an amazingly sophisticated and efficient food source. On the other hand, it's bee backwash. For more information about Alton Brown's Good Eats Pantry Raid Comb Alone application, please refer to the application itself. \n\nRegarding the PGP signature, here it is for your verification:\n\ngpg --verify hkgw.asc\n\nFor more details about using gnupg on GNU/Linux, please refer to its official documentation.\n\nBest,\n[Your Name]"
   }, {
    "body": "Hello Peter, \n I'm sorry to hear that you're encountering issues with SpamAssassin. It seems like the initial test returned a 'broken pipe' error and you've also tried using the 'p' option without success. To troubleshoot this issue, I would recommend checking your SpamAssassin configuration files for any errors or inconsistencies. If you're still having trouble, please provide more details about your setup (e.g., operating system, version of SpamAssassin) so I can assist you better. \n Regarding your question about Perl expertise, it's not a requirement to use SpamAssassin, but basic understanding of Perl scripting may help in debugging and customizing SpamAssassin rules. \n Hope this helps! \n Best regards,"
   }, {
       "body": "If you're currently using fetchmail, MDA, SpamAssassin or equivalents, please note that an upcoming change may render your current setup ineffective. However, there are alternative antispam options available. If you choose to continue with the existing setup, it is essential to implement a small shell script named 'spamassassinwrapper'. Here's how:

1. Create a file named 'spamassassinwrapper' and make it executable with 'chmod +x spamassassinwrapper'.
2. Add the following content to the file:
   ```bash
   #!/bin/sh
   date | sed -e 'd'
   spamassassin
   echo mail
   ```
3. Use fetchmail MDA command with the modified script: 'fetchmail mda spamassassinwrapper'.

Please be aware that while using SpamAssassin, there have been issues with file locking during write operations to the mailbox and failure to return proper error codes on diskfull conditions. Therefore, it is not safe or reliable in the first place.

Lastly, this email is sponsored by sfnet and OSDN, offering a new cell phone for free. If you're interested, check out the spamassassin-talk mailing list."
   }, {
    "body": "The log for the directory 'cvsroot/spamassassin/spamassassin-master/tenpass' has been updated and the file 'spamassassincommits' has been added to the repository. This email is sponsored by SourceForge and sponsored by OSDN. If you are tired of your old cell phone, consider getting a new one for free here: [link to offer]. You can subscribe to the spamassassin commits mailing list if interested."
   }, {
      "body": "This email informs you that the status of the bug you are either assigned or watching has been updated from 'ok now' to 'statusnew', meaning it is new. The bug has also undergone a resolution and has been fixed. Additional comments have been made. If you are tired of your old cell phone, there is an opportunity for you to get a new one for free. This email is sponsored by OSDN and is not spam or sent from the spamassassin devel mailing list."
   }, {
      "body": "Further comments from the sadev mailing list devnull rootrazorrazoragentlog. The question is why does it do this when mine doesn't, hmmm. You are receiving this email as you are assigned for the bug or watching the assignee. This sfnet email is sponsored by osdn and if you are tired of the same old issues with your current cell phone, consider getting a new one for free here: [link provided]. Note that this message was sent to the spamassassin devel mailing list."
    }, {
       "body": "On Monday, September 5th, Justin Mason wrote:\n\n'Sep 5 not that I'm not grateful but: I really would like to install from a source RPM. Does anyone have time to help? Thank you in advance. Time flies like the wind, fruit flies like a banana. Strange things have happened, but nothing as strange as this. Does your driver's license say 'organ donor'? Black holes are where God divided by zero. Let me clarify, we are all individuals. What if this weren't just a hypothetical question?'\n"
   }, {
       "body": "Craig Rhughes appears to be a good idea. We might encounter two other issues tomorrow when we start downloading in earnest, as more people return to work. If it turns out to be serious, I will see if I can get Mark Reynolds to add an instance in the US to go with the primaries already set up in Australia.\n\nIt seems there may be a problem related to the Razor bug/glitch, which is triggered when file permissions don't allow its own log system to work. This issue was reported on the Razor list before and I have heard similar reports recently.\n\nHowever, the logfile version number says CVS tag tree as of this time. Without relying too much on the version control system inside our code, I have put a line in mail/spamassassin.pm instead. I will certainly tag with a release label when needed."
   }, {
     "body": "Dear Zeek, I must admit that your last email was quite perplexing. However, by juggling the arguments of spamd, I seem to have successfully triggered a spamd debug daemonize autowhitelist for a user named 'nobody'. This is despite the apparent discrepancy in your original command, where you mentioned 'spamd debug daemonize autowhitelist' but did not specify a username. However, when I repeated the command with only 'spamd debug autowhitelist', it didn't seem to have the same effect. It appears that I may have misunderstood your intention initially. As for the sfnet email, it seems to be sponsored by OSDN. If you are tired of their old cell phone offers, there is a new one available here for free. Regards, SpamAssassin Talk Mailing List."
   }, {
    "body": "Thank you for your email, Adrian. To clarify, I am using SpamAssassin as part of the MailScanner package and Sendmail as the MTA. It integrates nicely within these configurations and shares a common configuration file. However, SpamAssassin (SA) itself does not perform any actions on messages; instead, it assigns a score to each message based on its content. You would then need a frontend like Procmail or Amavis at some point in the mail delivery chain that can hand over the message to SA and perform additional processing as desired. I was under the impression that if a message received a certain score, SA would take an action such as store, deliver, or delete based on the given configuration. It seems you are interested in custom programming actions within SpamAssassin. Unfortunately, I do not believe there are many opportunities for this without modifying the source code. Again, thank you for reaching out and please join the SpamAssassin mailing list if you have further questions or wish to discuss this topic with other users."
   }, {
      "body": "There has been an update to the 'cvsroot/spamassassin', 'spamassassinlibmail', 'spamassassin' directories with modifications made to the 'conf.pm' configuration file. A log has been added, and a note of deprecation has been included regarding starting lines with spaces, as they are reserved for future use in multiline rule definitions. The sample version tag has also been updated. The 'conf.pm' file retrieves revisions from RCS/CVSroot and compares them ('b w u d'), applies changes ('aug'), separates them ('sep'), loads files from the '/usr/share/spamassassin' and '/etc/mailscanner' directories. Comments in the files begin with a 'c' character, which continues to the end of the line; whitespace within the files is not significant but starting a line with whitespace is deprecated. Please note that paths can use the 'c' character to refer to users' home directories (e.g., versiontag refers to the home directory as '~'). This email is sponsored by OSDN and OsD, tired of your old cell phone? Get a new one here for free. For more information on changes made to SpamAssassin, please visit the spamassassincommits mailing list."
   }, {
      "body": "This is a warning message. Your message has remained in the server queue and the server will attempt to send it again. However, please do not try to resend your message at this moment as delivery is currently delayed due to issues with the SMTP module of domain tgsnopeccom which appears unresponsive. The current status of your message delivery is DNS Delayed from 'helo' by Communigate PRO SMTP with ESMTPTLS ID for Thu Sep, and it has been reported as delayed from various sources including hippostarcouk, exim debian, uswsflistssourceforgenet, startechgroupcouk via smtpd, and network. Additionally, the problem seems to have originated from an unknown helo (startechgroupcouk) by mattdevintstarcouk with SMTP. The sender's email address is matt@linuxtx.co.uk and the subject appears to be about spamassassin on Thu Sep. The message is in us-ascii format and contains a bulk of text discussing spam filtering."
   }, {
        "body": "Mike Burger has encountered an issue with SA (from Theos) on a Rh system running Perl. He is receiving messages suggesting that SA cannot find 'permsgstatus'. It appears that the line where ::permsgstatus should be loaded may have been missed, or possibly some old rules files are still present. The function 'checkforcontenttypejusthtml' relies on this object method, but it seems to no longer exist (it was renamed with Malte's coding). The email is sponsored by OSDN and mentions a new cell phone offer. It suggests that the user may have a spam issue as it refers to 'spamassassin', 'talk mailing list'. I recommend checking for missing or incorrectly loaded modules, and potentially cleaning old rules files."
        }, {
      "body": "I'm encountering an error page from sourceforgenet when I try to access 'just fyi Larry Rosenman, US Steamboat Springs Drive, Garland, TX'. Regarding the SFNet email, it appears to be sponsored by OSDN. I've had enough of the same old cell phone and I'm considering a new one for free. This offer is related to the spamassassin talk mailing list."
   }, {
      "body": "Hi Clark, I'm using a FreeBSD box where I can't modify the local Perl installation. I installed Procmail in my home directory and I'm trying to get SpamAssassin to work. I followed the instructions but I'm encountering issues. The error messages are: 'perl makefilepl: prerequisite : parser not found at eval line' and 'perl makefilepl: prerequisite : usage not found at eval line'. Additionally, it seems that 'sysconfdir' is not a known 'MakeMaker' parameter. I've tried searching for solutions but haven't found one yet. If you have any suggestions, I would appreciate your help. Also, if you're interested, there's a SpamAssassin discussion group on the talk mailing list."
   }, {
   "body": "Here's a rephrased version of your email:\n\nDear Kerry,\n\nIt would be great if we could have a moment to discuss some reality check rules. While it's tempting to cram numerous factors into the header in an attempt to accrue negative points, it's important to consider whether all these factors make logical sense together. For instance, can a Pine message ID coexist with an Outlook Express one, or a Mutt user-agent?\n\nThe introduction of meta rules brings a new advantage: we can now check for an outlook-style forwarded message and not penalize it unless other indicators suggest it's from Outlook. However, the headers should be given careful attention. For example, messages originating from The New York Times or Lockergnome might initially appear spammy, but they usually don't tamper with or fake header information. Therefore, let's tone down the negative scores and penalize them more severely for any obvious forgeries.\n\nAs we gather more effective 'nice' tests, the GA will assign lower scores to these messages. The current challenge is that our rulebase contains few truly effective 'nice' tests and many VEs that newsletters often match, causing problems for the GA to solve.\n\nRegarding your SFNet email being sponsored by OSDN and you expressing annoyance about the cell phone spam from the spamassassin talk mailing list, I couldn't agree more. Let's find ways to address this issue together."
   }, {
    "body": "Dear User,\n\nIt appears there is an issue with your system regarding the 'freemegsurluritest' in the eval line of a rule file. The operator expected seems to be missing before it, and there also seems to be an outdated copy of the rules files on your system. The rule is now called 'freemegsurl' instead.\n\nThis email is sponsored by OSDN. If you are tired of the same old cell phone, consider upgrading to our free SpamAssassin talk mailing list for a new one.\n\nBest,\nThe Support Team"
   }, {
     "body": "I've been pondering a bit about RPMs and other packages, specifically regarding PerlMailSpamAssassin, SpamAssassin Perl modules, spamassassin scripts such as spamd and spamd rcfile, etc. It seems like a smart approach to distribute only the necessary Perl modules without requiring the full RPM installation due to files like rc scripts in initd. This method has already been implemented in the distributed spec file. By the way, could you explain what the eval test you add in the TVD version of the RPM is? Also, I noticed that this SFNet email is sponsored by OSDN. Are you tired of the same old cell phone? Check out our new phones available for free on the SpamAssassin Talk mailing list."
   }, {
    "body": "It appears that you performed an update via RPM, which created new rule sets with the name xxrulenamecfrpmnew. However, it seems like SA can't find the 'permsgstatus' object, possibly due to a missing load statement at line line in your Perl script. The function 'checkforcontenttypejusthtml' is unable to locate 'method checkforcontenttypejusthtml' via package ::permsgstatus. It's possible that you forgot to load ::permsgstatus or have some old rules files still lingering around. This test used to exist but was renamed by Malte. Regarding your concern that Perl doesn't complain about not finding 'permsgstatus.pm', it might be that the script is using an older version of the rules where this function was present. I recommend checking for any potential inconsistencies or errors in your Perl script."
   }, {
    "body": "I have finally located the SpamAssassin team after months of searching. I unexpectedly found them at a bowling alley in Valencia here is a picture of my beloved clan. This SFNET email is sponsored by OSDN. Tired of that same old cell phone? Get a new one for free. Check out the SpamAssassin mailing list."
   }, {
    "body": "I apologize for the duplicate email. It seems my SFNet email address may have bounced back, as it is sponsored by OSDN and I'm tired of dealing with that issue. I am considering getting a new cell phone and would appreciate if you could provide a free spam-assassin email account on your mailing list."
   }, {
     "body": "Dear Josh Hildebrand, \n\nI'm encountering an issue when running your script as it complains about the 'h' parameter and the 'f' has been removed. However, I can run it on the command line as 'spamd d c a h' without any problems. It seems that the version of spamd running from the rc script is different, with the 'h' now present and 'f' removed. Is this the case for you as well? If so, you might want to locate an old version of spamd and discard it. \n\nRegards,\n[Your Name]"
   }, {
    "body": "Dear Stephan Lentz, \n\nRegarding your inquiry about filtering emails based on additional headers in Lotus Notes, I believe I can shed some light. While it is true that Notes has limited capabilities for filtering based on hidden headers, it is not accurate to state that it cannot handle extra headers universally. However, the visible headers such as Sender, Subject, Precedence, etc., are primarily used for filtering purposes. \n\nTo specifically answer your question, yes, there is a way to filter emails based on additional headers in Lotus Notes. The method involves the creation of custom rules or agents that can manipulate and utilize these extra headers for filtering purposes. \n\nBest regards,\n[Your Name]"
   }, {
    "body": "Dear recipient,\n\nI'm writing to suggest an alternative for our communication if aesthetics are a concern. Instead of using textplain quotedprintable, I think a simple letter would work better. For example, 'x' could be used in place of the current setup. However, we should not remove the config option as it gives users the freedom to customize according to their preferences.\n\nRegarding your concern about running Lucid Emacs via NFS from a remote Linux machine in Paraguay and the issue with background colors, I've noticed this problem before. If you encounter such an issue again, please remember that it's due to certain system configurations, not anyone in particular.\n\nLastly, for information about our PGP/GPG keys, refer to [bib] for details.\n\nBest,\n[Your Name]\n\nP.S. This email is sponsored by OSDN. If you're tired of the same old cell phone, consider getting a new one. For more information, visit our website.\n\nRegards,\n[Your Name]"
   }, {
       "body": "Further comments from Sadev regarding the spamlevelchar option change:\nRemoval is not advisable as it may look terrible. If aesthetics are a concern, an 'x' could be used instead.\nHowever, we should not remove the config option if users wish to customize it. It would hinder them unnecessarily.\n\nYou have been assigned or are monitoring this bug in SFNet.\nThis email is sponsored by OSDN. If you are tired of the same old cell phone, upgrade now! It's free!\nSpamAssassin Developer Mailing List"
    }, {
     "body": "Daniel, Craig and Hughes,\n\nI propose configuring SA to prioritize spam messages by setting precedence to low. However, I've not encountered a real human setting precedence to low on regular mail. If there isn't a better solution for Lotus Notes users, we could establish a spam convention using 'junk' header (although it's non-standard, most software recognizes it). Courier and Outlook seem to handle these special headers too.\n\nAutoresponses should always contain the 'junk' notice. The spelling of 'precedence' is intentional to prevent well-tempered mail programs from generating bounce messages for these if the recipient can't be reached, the autoresponder message is simply discarded. If you're in a country where English is not commonly used or are agraphic (can't write), this will help avoid issues.\n\nThe 'precedence' header, in practice, impacts sendmail to prioritize less important messages during high load. The FAQ from coding is art, and this sfnet email is sponsored by OSDN. If you're tired of the same old cell phone spam, check out our free offer for a new one on this link.\n\nRegarding the Here for Free Spamassassin Talk mailing list, please note it was not mentioned in the text."
   }, {
      "body": "It appears that you have installed Razor correctly, but an error regarding 'Omega' is occurring, specifically a 'No such file or directory' message. I suspect there might be an issue with the '::resolver' package as the method 'new' cannot be located. It seems like you may have forgotten to load '::resolver' at some point in your code. Regarding documentation, it is often challenging to decipher due to its complex nature. As for the unrelated content about a new cell phone and spam emails, I presume they are advertisements and not relevant to the issue at hand. This email appears to be sponsored by OSDN."
    }, {
    "body": "Despite my hesitation to upgrade to using the tarball instead of cpan, with the assistance of others I was able to get Razor functioning. However, I encountered an issue in my logs which occurred twice but has not recurred yet: 'Omega check permission denied cant call method log on unblessed reference at line line'. The documentation seems to be ambiguous; it's uncertain whether whoever wrote it understood it or not, as the rest of us may not be so fortunate. This SFNet email is sponsored by OSDN. I'm tired of the same old cell phone spam; here's an offer for a new one - free of charge. This message appears to be from the SpamAssassin talk mailing list."
   }, {
    "body": "On Monday, September 20th Matt Sergeant suggested removing all whitelist entries and creating a new page to list common ones instead. I wholeheartedly agree with this proposal, though I think it would be more beneficial if this were a wiki format. It's fascinating to consider what Ronnie Scelson might do with a wiki (shudder at the thought). When it comes to coding, it's an art, and this SFNet email is sponsored by OSDN, tired of the same old spam. If you're fed up with your current cell phone, check out our free offer for a new one on our spamassassin development mailing list."
   }, {
       "body": "The following email contains additional comments regarding your post, which may necessitate a separate bug report. You are currently the assignee for this bug or are watching it. This SFNET email is sponsored by OSDN and offers a free cell phone replacement. For more information about SpamAssassin development, you can subscribe to the mailing list."
   }, {
    "body": "Dear User,\n\nCould you please guide me on how to manually decode the part 'cw' in Morse code? The first three results I obtained appear useful, and they may be beneficial for the spamassassin-talk mailing list.\n\nBest regards,"
    }, {
     "body": "I believe we should consider adding new GAD rules and removing outdated ones in our upcoming release. This would necessitate a discussion, but the new GAD scores are definitely worth implementing as the current ones seem too volatile. We should continue to develop and refine the rules on this list, but a new branch should be opened only if significant new features such as Bayes or interface changes are introduced. In other words, we should maintain the stability of the branches for the outside users while making continuous improvements under the surface. Please keep in mind that when you update to a new minor version number, users and system administrators might be less reluctant if they're assured the branches are stable and only contain improvements rather than potentially breaking changes. I will be away from my box and mail account for one week starting tomorrow, so happy coding for the next week!"
   }, {
       "body": "The email discusses different methods for dealing with spam during an SMTP transaction. The sender suggests three approaches: blocking the spam at the SMTP level with a permanent error code, blackholing the mail (seemingly accepting it but discarding it later), and returning a message indicating that the mailbox does not exist (hoping that some spammers will remove the address from their lists if they receive such messages). The sender expresses doubts about the first method as it might provoke the spammers to try other methods. They also mention that SpamAssassin, a widely-used spam filter, typically acts after the SMTP transaction has been completed successfully. The sender asks for thoughts on the effectiveness of each approach and wonders if spammers even pay attention to bounce messages due to their high volume."
   }, {
    "body": "Robert Strickler appears to suggest we should implement an identity stamp within xspam headers, enabling SA to only accept headers from authorized sources. SpamAssassin will disregard any non-authorized xspam headers, preventing them from circumventing the filter. For your reference, the SpamAssassin discussion can be found on the SpamAssassin Talk Mailing List."
   }, {
    "body": "Hi there, I encountered a similar issue while installing SpamAssassin through the ports on my fresh FreeBSD. I had to specify the order of directories in a certain way so that the latest :spec module would be used. It's good to know it's not just me. I have tried setting variables using setenv in the shell, inside the makefile, and even on the Perl command line without success. If you have any specific suggestions or insights regarding how you managed to do this, I would greatly appreciate your help. Thanks! David Raistrick (in remembrance of SpamAssassin discussion mailing list)"
   }, {
     "body": "I have successfully installed SpamAssassin Razor on my Debian Woody server. I apt-get installed SpamAssassin Razor and the necessary dependencies, then downloaded libmilterdev from ungzipped and untarred the file into /etc/mail. Following the instructions provided, I compiled the milter, installed the rc scripts, edited and updated sendmail.mc, changed etcdefaultspamassassin to set SpamAssassin to daemon mode, verified that SpamAssassin was running by tailing var/log/maillog, and confirmed that it is stable (running as 'sa' in both woody and woody-unstable). If you want to run the unstable version, change etc/apt/sources.list substituting 'unstable' for 'stable', then run apt-get update and install the unstable versions. I am currently running the stable source live right now and it is working very well. I am not sure if there is a Debianized package for SpamAssassin on Woody or anywhere else, but if you know of one, please let me know. It has been so long since I last compiled software that I am somewhat shy to try again."
   }, {
     "body": "Dear Stephane Lentz, \n\nI encountered a similar issue while installing SpamAssassin on my fresh FreeBSD system via the ports. To resolve this, I had to define a specific order of directories so that the latest :spec module would be utilized. I have tried setting environment variables in the shell as well as inside the makefile and even on the Perl command line, but none of these attempts were successful. Assuming you run Bash, here's how I set it up: \n\n1. In the shell, use a variable similar to this:\n\nperlmap print n\nsetenv SPAM_MODULE_PATH /usr/local/lib/spamassassin/3.4.x:\n\n2. Then, set up the shell variable and put it in some bashrc for future use:\n\nexport SPAM_MODULE_PATH\n\n3. Finally, try to install the software.\n\nFor more information, refer to 'man perlrun'. I hope this helps you. Let me know if you encounter any further issues while installing SpamAssassin or have any questions regarding this process.\n\nRegards,\nDavid Raistrick, Alcanet International Internet Services"
   }, {
       "body": "Thus far today, I've discovered Efforg and Mandrakesoft.com in my DCC account. My trust in DCC is starting to wane, Robin Lynn Frank from Paradigm Omega LLC. No electrons were harmed during the sending of this message, but two neutrons and a proton have complained about the noise. This issue has been reported on the Remembrance SpamAssassin Talk Mailing List."
   }, {
    "body": "I have been experiencing an issue with Defangmime since I set it up, where any spam containing HTML with a poorly formatted report is recognized as such. I believe this is because the report should be in HTML format. Is there a way to get SpamAssassin to generate an HTML report when required? It would be helpful if Defangmime could wrap the report for easier reading, similar to how it seems to handle encoded messages. Currently, the report is placed inside of the MIME text/plain section. Shouldn't this be in its own MIME section to prevent attachments from getting destroyed? This issue also seems to occur with encoded messages. \n\nI was actually in the process of writing the same message when I saw yours. It would indeed be nice if SpamAssassin could recognize a 'text/html' header and handle Defangmime accordingly.\n\nRegards,\nIan White"
   }, {
      "body": "Vivek Khera from Khera Communications Inc suggests upgrading SpamAssassin for all users as the rules need to be updated due to the evolving nature of spam. He proposes an automated notice system, reminiscent of nagware, that alerts users when their rules are say months old and recommends checking for updates. Additionally, he suggests a built-in server check on a periodic basis, even daily, to look for the existence of an update and prompt the system admin to upgrade if found. This could greatly benefit SpamAssassin users and ensure everyone stays updated. It's worth noting that this approach has not been applied to many of the apps they sell due to user concerns about spyware and phoning home, but in cases where the app needs to access the internet anyways, it has been done successfully with minimal concern from users (Joseph Burke, President & CEO, Infinisource Inc)."
   }, {
   "body": "I'm glad to hear that your progress is going well and the implementation of Naive Bayes spam/non-spam classification is working reasonably well. It appears that we indeed want a tightly integrated implementation within SA. I am still figuring out some details about how to accomplish this effectively inside SA. \n\nRegarding individual spam word file preferences when SpamAssassin is running on a mailserver for multiple users, that would be an outstanding addition if it can be done. If possible, that feature would greatly enhance the project. Thank you for your great work."
   }, {
      "body": "There is a third possibility instead of returning an error code suggesting you've identified a spammer, one could fake a non-existent mailbox response. The intention would be that some spammers might remove names reported as non-existent from their lists. Although it's a slim hope, if only a few do it, it can lower the incidence of them not doing so. I must admit, many spamtraps nowadays wait for months in the hopes of receiving legitimate mail to remove bouncing addresses from lists. Unfortunately, many legitimate mailers do not bother cleaning their lists. Some spammers do not check reply codes at all; they just send out as many emails as their system will hold without checking for any confirmation. A trick to lower spam reception that was discussed on the Postfix mailing list is to respond with a temporary error code when offered the first time, and accept it the second time. It seems most mass-emailers do not even try to deliver a second time."
   }, {
    "body": "Paul Fries has requested a solution for an issue related to the removal of the 'M' flag in Spamassassin after upgrading. Although HTML formatted emails seem to arrive properly, messages tagged as spam are arriving as just HTML source. He would like to know if there is a way to retain the formatting of HTML/RTF messages even when they are marked as spam. This can be achieved by using the 'M' flag when starting Spamd. Thank you for your help."
   }, {
      "body": "I have rephrased your email as follows:\n\nDear SpamAssassin Team,\n\nI recently installed SpamAssassin with Razor and it has been functioning well. Yesterday, I added PyZor to my setup, which I believe was installed successfully without errors.\n\nCurrently, I am using spamd and notice that it periodically spawns a PyZor process; however, nothing has been marked as spam by PyZor under SpamAssassin. It has been running for almost half a day now on my user mail server, leading me to believe that the chances of it detecting spam should be high.\n\nI run spamd as 'spamd d h' and all user home directories contain a PyZor directory with the server listed under it. I have set up a test Procmail recipe that invokes only Pyzor check, to see if PyZor alone can identify any spam. As of yet, I haven't received any results.\n\nWhen attempting connectivity to PyZor, I get the response 'pyzor d ping ok.' Any help or examples would be greatly appreciated. Keep up the fantastic work with SpamAssassin!\n\nRegards,\nNick\n\nOutgoing mail is certified free and checked by AVG Antivirus System."
   }, {
     "body": "It appears that they clean their email lists only when a spam attempt fails to deliver or cannot be detected. The question arises about what spammers do with undeliverable email addresses for several years. It seems my hypothesis for the moment is that if your business involves selling email lists to individuals who would then spam, it's in your best interest never to clean your list. This way, you can technically claim a large number of email addresses, even if the majority do not work. On the other hand, if you are a spammer, you might want to know which email addresses don't exist, but you may also want to relay through someone to make it harder to trace you. If possible, you would send mail to every available email address, avoiding setting up a valid bounce address because it makes tracing easier. However, if you technically spam people while claiming to provide a legitimate service, you might have a way of opting out, even though the user did not opt in, and you probably don't relay and pay attention to bounces. Everyone else doesn't seem to care about this."
   }, {
     "body": "It appears that you have some concerns regarding spam lists and the behavior of spammers. Here's a possible rephrasing:

    'Regarding your inquiry about getting removed from spam lists, it seems there's a common perception among individuals that once on a spammer's list, it is difficult to be removed. However, contrary to this belief, I believe the spammers have a reason not to remove emails. They want to prove they are reaching potential clients and getting their money. Therefore, they only need to show they send several million emails, not necessarily that these emails reach the intended recipients.

    They don't seem too concerned about bounces since they are often con artists. It seems they care more about proving they sent the emails rather than proving they were delivered. So it appears they clean up their lists only when an email fails to deliver or if they can detect that most of the time, the bounce goes to a recipient unrelated to the spammer.

    As for the question about what happens to undeliverable email addresses in their database for several years, yes, they do continue to spam them. They may keep these addresses on file, hoping that at some point, they will be able to deliver the email successfully.'
   }, {
    "body": "Regarding your question, it appears you're asking about the behavior of spammers towards undeliverable email addresses that have been inactive for a few years. To provide an answer, generally, spammers may still attempt to send emails to such addresses as they don't have any mechanism to determine if an address is active or not. However, these emails are likely to bounce back and be discarded by the email server."
   }, {
      "body": "I believe you're having a question about your mail server setup and DNS records, specifically MX and A records. Here's a simplified explanation:\n\n1. You have two MX records (mail and bmail) for your mail server, one of which is being used for spam and virus scanning before delivering the email. This is why you provided a 'bmail' record.\n\n2. DNS A records are typically used for load balancing, whereas DNS MX records are used to specify mail servers responsible for receiving email for a domain. They function in a priority order. If the primary server is unavailable, another server with a lower priority will be tried.\n\n3. It seems like your concern is that not all emails are being scanned and delivered as intended. This could potentially mean that some of the emails may bypass the scanning box or the box is not receiving all emails as expected. To troubleshoot, you might want to check the server logs, verify DNS settings, and ensure there are no issues with your email client.\n\n4. As for why only some mail is being scanned, it could be due to a configuration issue on your mail server or an issue with your email client. The fact that your server never goes down might not be related to the problem at hand.\n\n5. I hope this helps clarify your confusion. Let me know if you need further assistance!"
   }, {
       "body": "On Friday, September at Vernon, I have been trying to understand DNS functions and it seems that A records are used for load balancing in a rotating fashion while MX records are used either in order or priority (the latter only if the primary is not available). However, it appears that not all of the mail is being scanned as intended, leading me to believe that not all mail is hitting the primary server. This could be due to some technical glitch or intentionally sending to the secondary server, which is a semi-usual spammer trick to bypass the main server and send directly to the secondary (since it may have less filtering or be trusted).\n\nIn the world of MX records, multiple ones contain a preference indication that must be used in sorting. Lower numbers are more preferred than higher ones. If there are multiple destinations with the same preference, and there is no clear reason to favor one (for example, by recognition of an easily reached address), then the sender's SMTP must randomize them to spread the load across multiple mail exchangers for a specific organization.\n\nIf it determines that it should relay the message without rewriting the address, it must sort the MX records to determine candidates for delivery. The records are first ordered by preference with the lowest-numbered records being most preferred. The relay host then inspects the list for any of the names or addresses by which it might be known in mail transactions. If a matching record is found, all records at that preference level and higher-numbered ones must be discarded from consideration.\n\nIf there are no records left at that point, it's an error condition and the message must be returned as undeliverable. If records do remain, they should be tried in the order of best preference, randomly generated.\n\nRegarding the PGP/GPG signature in this email, for more information see the end of the email."
    }, {
   "body": "The provided spam filtering output looks correct according to 'spamc' and 'spamtxt', but when checked with 'echo', it returns 'a' instead of 'can'. This indicates a potential bug as packet trace shows that the request checks 'felicit ycontentlengt', and the response is 'ex false'. This suggests that 'spamd' is returning incorrect results randomly. For more information, please refer to the attached PGP signature and see end PGP signature. This SFNet email is sponsored. Welcome to Geek Heaven."
   }
   (The PGP signature part has been omitted for brevity), {
       "body": "On Friday, there appears to be an issue with the mail scanning at Vernon as only some of the mail is being processed. This suggests that not all mail may be reaching the designated box. I am confused about this situation as I'm sending mail directly to a backup mail server, hoping it has less stringent spam scanning. However, bypassing strict spam filtering is often a tactic used by spammers, as mentioned by Jason Kohles, Senior Engineer at Red Hat Professional Consulting. This discussion is related to the sfnet email sponsored for the Geek Heavenspamassassintalk mailing list."
   }, {
      "body": "Dear Justin Mason,\n\nIt appears that the Razor tool needs to be registered for each user. A possible solution is to create a world-readable home directory for Razor and other related tools (such as dcc) to store their files in. In this way, Spamd will share the Razor server information between all users.\n\nHowever, instead of making it world-writable, make it world-readable and use Spamd 'h' to point to the world-writeable directory. Please remember that Razor and whatever dcc uses must also be made world-readable.\n\nA more efficient approach in my opinion is to create a world-writable log file for at least Razor, using symbolic links to devnull. However, the efficiency may depend on the user base, and it takes control away from the user, which might or might not be ideal depending on the specific user base.\n\nI would also like to suggest randomly generating a funny ID. If you could send me an email with this information, that would be great!\n\nRegards,\n[Your Name]"
   }, {
       "body": "I could not locate any information regarding setting up multiple SpamD machines for load balancing in the provided list. However, you may want to look into SpamD's load balancing capabilities or consider alternative solutions such as using a spam-filtering load balancer like SpamAssassin's Traffic Shaping feature (also known as rate limiting).\nTo learn more about this, you might find it helpful to join the Geek Heaven SpamAssassin Developers mailing list for discussions and guidance on this matter."
    }, {
   "body": "Dear All,\n\nOn Friday, September, Tony L Svanstrom brought up a question about what happens to undeliverable email addresses in spammer databases after a few years. Do they still continue to spam these addresses? Yes, it seems so, as I receive thousands of bounces per day on this machine, which appear to be message IDs.\n\nLet's appreciate those daring young men and their flying spellcheckers! This SFNET email is sponsored by Geek Heaven - SpamAssassin Talk Mailing List."
   }, {
       "body": "It appears that you are receiving emails with the following issues: Linux RBL check timed out and was killed, consecutive failure of SEP Linux spamassassin timed out and was killed. These messages indicate problems with the email's source server during checks by the system. The email has been scanned for viruses and dangerous content by mailscanner at compwizcom and is believed to be clean. Additionally, this SFNET email is sponsored by Geek Heaven and related to the spamassassin talk mailing list."
   }, {
    "body": "Currently, Marc Perkel is using a single 'spam' status flag to categorize messages as spam or not. The intention is for users to create a rule that would move these flagged messages into a 'spam folder', thus saving time by pre-sorting messages into two piles. If the user lacks knowledge to filter based on the actual score, there are stars available to provide additional control. For those who want more leverages, they have more than enough options with the stars. In Latin, this concept translates to 'tony per scientiam ad libertatem' or 'knowledge towards freedom'. This approach is related to 'genom kunskap mot frihet' in Swedish and 'c Perl eprint for sortlynx dump svanstromcomtthis sfnet email' is sponsored to the geek heaven's SpamAssassin developer mailing list."
   }, {
      "body": "It appears that you are encountering some issues with your Linux system and specifically with SpamAssassin and MailScanner. The messages you're receiving about timeout and kill are due to the configuration of these tools. The timeout used for checking ordbrbl is too low, causing MailScanner to time out repeatedly. After seven such timeouts, these checks will be automatically disabled until MailScanner restarts itself in a few hours. This is a common issue when learning to configure such tools, as Chaucer once said 'so short the craft so long to learn'. The email you received is sponsored by SFNet and related to the SpamAssassin discussion list."
   }, {
    "body": "Tony L Svanstrom, on Sep 1st, discussed an idea regarding spam filtering. The current system indicates a message as either spam or not-spam with a status flag. The suggestion is to enable end users to create rules that automatically move spam-flagged messages into a spam folder, thereby saving time by pre-sorting messages. Although developers understand the concept of utilizing stars for further filtering if necessary, the main focus is on simplifying the process for end users. This email pertains to the sfnet Email is Sponsored Geek Heavenspamassassin Devel Mailing List."
   }, {
    "body": "I have observed that Razorcheck performance seems to have decreased over the last week. Disabling Razorchecks in Spamassassin has helped my queues clear out again. This is a reminder that this issue is being discussed on the SFNet email list for razorusers."
   }, {
    "body": "Is there a project FAQ available that is similar to a Perl script which fetches POP3 mail from a remote server? The retrieved mail is then processed by a standalone module (SA) running within my user account. SA outputs results back to the Perl script, and the Perl script subsequently deletes offending emails. Note: I do not have root access, so I do not need MTARIS Fortune/Fortunes Web Computer Services from Nelson BC, Canada, or sponsorship from AMD or your access to the experts on Hammer Technology's open source Linux developers. However, I encourage you to register for the AMD Developer Symposium and join the spamassassin-talk mailing list."
   }, {
       "body": "Justin Mason, I was considering removing certain rules while keeping the rest within the range as they are currently too noisy to be effective. However, I am open to keeping those same rules in the future. I think Matt Craig might agree since he could handle commenting out the lowest spamphrase scores if the GA can manage this sort of thing automatically, making them zeroed. This would make me feel better as the ranges may change next time the phrase list is regenerated or the algorithm tweaked. However, I believe we should understand why it's so low before removing it. The rules on either side perform quite well and here are the ones that seem like they should be improved: missing gappytext, invalidmsgid, mimenullblock, subjmissing. I don't like subjmissing, but I think there might be a lot of emails from cron jobs which hit it. Therefore, I suggest we drop subjmissing. The others are recoverable for sure. I am confident there are more, probably a few. Those seemed like the best prospects to me. By the way, do you agree with the proposed methodology? That is, remove the rules and bugzilla each one. However, I only want a bugzilla ticket for each one if people are okay with quick 'wontfix' closes on the ones deemed unworthy of recovery. If possible, could you put the stats for each rule in the ticket? This should be automatable with email at least, as it would help."
   }, {
    "body": "Justin Mason, I noticed that it appears fetchmail is adding 'Received' headers which may be incorrect. I believe this could be addressed by opening a bug for investigation. I will attach some examples for reference. Unfortunately, Bugzilla does not allow email submissions. However, you can still add information related to the issue with an email. Dan"
   }, {
       "body": "Justin Mason, Simon Matthews and Procmail have found Procmail to be reliable, as long as none of the recipes fail. The primary goal is to resolve the tripletstxt issue to prevent the subsequent procmail problem. However, it's uncertain if there's a direct connection between the two. The tripletstxt issue resides in an entirely different coding area and the Procmail bug occurs when the filter program behaves unexpectedly, but the specific cause is yet to be confirmed by experts on the Procmail list. It might involve the filter program exiting with a non-zero status, producing output on the standard error, or something else altogether. Simon is attempting to ensure SA runs flawlessly in order to avoid triggering the Procmail bug. This isn't a fix, but rather a workaround as he apparently can't install a newer version of Procmail."
   }, {
       "body": "Justin Mason, \n\nIt appears that there is a concern about the current implementation of the comment in head. The issue seems to stem from what sounds like a broken server and low hitrate, making it less useful in your opinion. This, as you've stated, is likely a bug in SA or the libraries we are using. Additionally, it appears that there is room for improvement in how we handle outages of network services.\n\nYou mentioned that the rule is useful and helps reduce spam. We should keep it. You also suggested that the DNSBL rules may cluster more heavily around the TO range once we start using the new GA on them. \n\nLastly, you provided some insights about the number used in the rule. You typically use a slightly conservative number because you don't have real-time data. The choice of number depends on the trend of the period data: most recent month, two months, six months, depending on the trend. This approach seems to favor better performance for recent messages with recent scores and worse performance for recent messages with lowest scores. You also advised against picking the highest number unless the rule was very accurate and the highest number was for the most recent data.\n\nBest,"
    }, {
     "body": "Dear Gary Funck, I found the PerlLocalPod line unusual in the root directory. Is it common to write documentation into the root directory? I believe there might have been a Make parameter or environment variable that should have been set when running Make. I've encountered an issue and it seems that by registering with razor, I was able to avoid the error path noted in my previous email (where ::resolver does not exist in my Perl hierarchy). Here is the new output from sa and it looks good if we use SpamAssassin on a per-user basis invoked from procmailrc. My question is, will each user have to run razoradmin register first? Is there a way to register with razor just once per system? If you use spamd with the h option and provide a shared directory for the razor config files to be written to, more details can be found in the documentation. Regards."
   }, {
       "body": "Dear Justin, I hope this message finds you well and a bit late but still happy birthday! Regarding the spam corpus, it appears that the miss ratio is rather high, although the low false positive percentage is quite pleasant. Additionally, the narrowing of average false positive false negative scores compared to what Dan mentioned is significant. This is an important point because the measurements cannot be directly compared since I changed the methodology in the scores and they were evolved on the entire corpus then evaluated using that same corpus. As a result, there was no blind testing and the scores could potentially overfit. However, if these figures were evaluated blind on a totally unseen set of messages, they would be much more accurate for real-world use."
    }, {
      "body": "Hello,\n\nIt appears that you have upgraded to a new version of SpamAssassin last week, but messages from the DCC database are not being marked as such when connected via spamc. Interestingly, these messages are detected when running spamassassin t samplespamtxt using the same user ID.\n\nYou mentioned that this used to work under both SpamAssassin and Spamd/spamc. I am not certain if this is a known feature of spamc or if there might be something you are not implementing correctly. Could you please check your configuration settings to ensure everything is set up correctly?\n\nRegards,\nRay Gardener, Sheffield Hallam University UK"
   }, {
       "body": "To whitelist messages related to spam or spam reports from your current email source in SpamAssassin, you should add it to the list of trusted sources. Keep in mind that messages containing spam indicators will still be tagged as spam if they are not on this list. Since this is typically the only whitelisting used, you can proceed with adding your SFNET email address to the Geek Heaven SpamAssassin Talk mailing list."
   }, {
       "body": "Yes, I believe that some other MGM data includes spamtrap information. To clarify, 'spamtrap' refers to email addresses specifically set up to catch spam at any given time. If it would be helpful for future communications to keep this separate, please let me know. I should add that my spamtraps are typically free of viruses and bounce messages most of the time. Michael Moncur from MGM at starlingtech.com mentioned that a lack of money is not an obstacle, but a lack of an idea is. Ken Hakuta."
   }, {
       "body": "Hi there,\n\nIn order to install SpamAssassin on FreeBSD, here are the dependencies and prerequisites you may need:\n\n1. Procmail: If you're using SpamAssassin for local delivery, not using a milter, and not using a :audit script instead, then Procmail is essential.\n\n2. Make: Both GNU Make (gnumake) and BSD Make are supported by Perl to build Perl modules. Since SpamAssassin is another Perl module, it should work fine with either one.\n\n3. Perl: Since SpamAssassin is a Perl module, you'll need to have Perl installed.\n\nUnfortunately, there doesn't seem to be a clear readme file for SpamAssassin on your system. However, the Procmail that you've already installed should be sufficient for getting started. Here's a simple English guide to help you set up SpamAssassin:\n\n1. Install Perl if it's not already installed.\n2. Install Procmail if it's not already installed.\n3. After installation, edit your procmailrc file to include the following lines:\n\n:0w\n * ^X-Spam-Status: Yes\n  spamassassin\n\n4. Restart your mail service.\n\nI hope this helps! Let me know if you have any further questions."
   }, {
      "body": "Dear Michael Moncur, \n\nRegarding your corpus on spamtraps and spam data, it appears to be well-cleaned and monitored, which is great. I understand that you have old user addresses recycled into spamtraps for trapping website crawlers. These are indeed the most effective. However, I want to inform you that these old user addresses are typically recycled several months after the user closes their account and may have been scanned for newsletters from which they have unsubscribed. \n\nIt's also important to note that some maintenance is required to avoid ham (non-spam) emails from getting into the spamtraps. I see that some of your spamtrap data has contributions from ISPs, but you mentioned you hadn't spent enough time sifting through for legit mail that was slipping through. As a result, you decided to leave those out for this run, keeping only the hand-cleaned data. \n\nPlease keep in mind the importance of separating your spamtraps from the rest of the data and let me know if there's anything I can assist with regarding maintenance or further clarifications.\n\nBest regards,"
   }, {
    "body": "The bug has been marked as 'Fixed'. I believe this issue should no longer be a concern. You are the assignee or are watching the assignee for this bug. This email is sponsored by sfnet and delivered to the SpamAssassin Development mailing list on Geek Heaven."
   }, {
       "body": "Dear David, I'm sorry to inform you that the bug tracking system is exclusively for OpenSource SpamAssassin (the Unix version). For other issues, you should contact someone at deersoft.com instead. You have been assigned or are watching this bug ticket in the sfnet email, which is sponsored to the Geek Heaven SpamAssassin Developers mailing list."
   }, {
   "body": "I understand that you have provided additional comments on the issue and expressed a preference to observe if spammers make changes. It appears your assumption is they will not modify their spamware to send messages tailored for each recipient. As a result, I am marking this as 'wontfix'. You are either assigned for this bug or watching its progress. This email is sponsored to the Geek Heavenspamassassin-dev mailing list."
   }, {
    "body": "Additional comments from Dan. Are there any code segments from this that can be checked in? I'd love to tinker around with it a bit. You are receiving this email as you are on the CC list for the bug or are watching someone who is, regarding the sfnet email which is sponsored by Geek Heavenspamassassin development mailing list."
   }, {
       "body": "Thank you for your insights on the idea. Given that the parameters are nonbinary and the major operator is mutation in evolutionary programming, it's crucial to note that the more interactions between variables, the more finely-tuned the Gaea needs to be, particularly to avoid local optima which might have contributed to the suspiciously high antiratware useragent scores seen in past results. To address this, we need to consider one or more of the following: \n1. Determine mutational parameters by adapting scores themselves with variation on a per-original score basis.\n2. Allow for having correlated mutations, meaning having a mechanism in place for trying out changes to a bunch of scores at once, with them all moving about the same amount, albeit possibly in different directions.\nA method to achieve this can be found in Schwefel's evolutionary strategies: adapt the probability of a mutation taking place depending on how well previous mutation attempts have done. If more than about a fifth of the new individuals are doing as well as or better than the parental generation, then increase the number of parameters being mutated. Conversely, if less than a fifth of them are performing as well as or better than the parental generation, then reduce the number of parameters being mutated."
    }, {
     "body": "Mike Bostock from By Postfix, with an ESMTP ID, has sent an email worth your attention. If you visit their website, it appears they are in the business of mass email marketing. Regrettably, their mailing to you bypassed SpamAssassin. Despite not receiving any communication from them for about a year, their headers indicate that they're still active. We suggest creating an Xmailer rule to filter similar emails and put it into testing. This SFNet email is sponsored; welcome to Geek Heaven - SpamAssassin Talk Mailing List."
   }, {
     "body": "Jason Quackenbush, it appears that you have set up Procmail on a gateway as an intermediary between your external sendmail box and internal Exchange Bridgehead Server. Currently, the system only receives inbound emails and the goal is to simplify the configuration by going back to two separate boxes. You have conducted a test that seems to confirm our understanding about Procmail, but the testing was limited due to your current configuration setup which causes confusion when set up as a gateway. Your question is about finding a way to separate inbound and outbound emails so that only inbound mail is checked for spam and outbound mail is ignored. You are using Sendmail with Procmail on the gateway to call SpamAssassin, but it seems that SpamAssassin doesn't get called for outgoing email messages sent to other machines. You want to know if there is a way to make Procmail act as a local delivery agent only for inbound traffic to local machines and ignore the outbound traffic. This might be more of a Sendmail question, but your Google searches have mainly turned up people trying to log all inbound and outbound email using Procmail and SpamAssassin."
   }, {
      "body": "Hi Cheryl Southard, \n\nIt appears that you're experiencing an issue with SpamAssassin and Procmail where your user preferences file is not being read when running spamc from the global etcprocmailrc file. Here's a possible solution:\n\n1. To make spamd load the per-user config files, run spamc as the user whose config files spamd should load.\n2. If you're running spamc as some other user (e.g., root, mail nobody, cyrus), you can still use this method but ensure that you set 'dropprivs yes' in etcprocmailrc before calling spamc from the procmailrc file. This will drop all privileges and execute the bottom half of the etcprocmailrc file on behalf of the recipient.\n\nHope this helps! Let me know if you encounter any further issues."
   }, {
    "body": "Justin Mason, the issue with defanged mime messages is significant, but if instead of removing the headers, you revert back to the xspamprev versions, it would almost work. I have fixed the downloads page, please check now. Regarding the un-defanging of MIME, it was causing issues with some of my masscheckresults where Samarkup was present. Previously, if there was a warning about Samarkup in masscheck, it never worked for medan."
   }, {
    "body": "Dear Doug, I hope this message finds you well. You've recently downloaded the Razor SDK and agents from their site and have been able to use the SDK without any issues as all tests have passed. However, you're encountering errors when attempting to create agents, specifically mentioning a missing DNS. It appears that the DNS is present, but the error persists. I would like to offer some assistance in troubleshooting this issue. Here are a few suggestions:

1. Ensure that your SUSE environment is correctly configured and updated. Check if there are any known issues with DNS resolution in the SUSE community forums or documentation.

2. Try creating agents manually, step by step, to identify where exactly the error might be occurring. This could help pinpoint a more specific issue.

3. If possible, try using different agents and see if you still encounter the same error. This can help determine whether the issue is agent-specific or a broader problem with your setup.

4. Verify that the SDK's DNS settings are correctly configured if it has its own DNS module. Check if there are any inconsistencies between the SDK and your system's DNS configuration.

5. If none of the above steps help, consider reaching out to Razor support for further assistance as they might have insights specific to their software.

Remember that this list is not exhaustive, and you may find a solution elsewhere in your troubleshooting process. I hope this helps you resolve the issue quickly. Let me know if you need any more information or guidance. Best regards."
   }, {
      "body": "Dear Daniel Quinlan, Allen Smith,\n\nI've been experimenting with Google Analytics (GA). Unfortunately, I don't have a large or easily processable corpus at hand, which makes GA fiddling part of my research but not the mail processing. To test out my changes, someone needs to send me copies of the 'tmpscores.sh' and 'tmptest.sh' scripts that are generated before GA takes action. I suggest starting with the MassCheck corpus results as they are easier to obtain - simply by getting a directory listing of the corpus server and doing some downloads.\n\nDone, you can generate your own 'tmpscores.sh' and 'tmptest.sh'. I will report back on my results.\n\nRegards,\n[Your Name]"
   }, {
    "body": "Please verify if the provided address is correct, and resend the email if necessary."
   }, {
      "body": "Discussing an alternative to spam phrases, the proposed strategy leans towards a database approach similar to white/black listing. The idea is to tie this method with XML retrieval from a central repository of lists. MySQL supports replication and could be used for this purpose. An organized XML format would allow both manual inspection and automated updates of the database. Additionally, there's a suggestion to create an RBL (Reversed Blacklist) for reverse lookup purposes, which could be named 'spamwebbugx'. Implementing this might get tricky due to specifying a randomized intermediate directory. In summary, it appears we are planning to store hash sums of URLs/phone numbers found in spam within a DNSBL (Dynamic Name System Blackhole List) for applications like SpamAssassin to look up. This concept resembles SpamCop's spamvertized URL list. The email is sponsored and dedicated servers are available only on Linux or FreeBSD, offering free setup and fast network. Get your own server today at spamassassintalk mailing list."
   }, {
    "body": "It appears that you have been receiving a significant amount of spam relayed through this group recently. Could others please confirm this? If it is indeed the case, I will devise a forgedhostname test for it. I typically receive them from 'dsltelespnetbr'. The number seems to be increasing per month and contains spam. Last month was randomly generated; I don't believe I have ever cuddled my colleagues Larry Wall in application. For your information, the email is signed with PGP signature. Below is the PGP key for verification."
   }, {
       "body": "Justin Mason, \n\nIs it possible to use the entire dataset for both training and evaluation once we've decided on the final method for any one release? If so, could we utilize the data for a final run?"
   }, {
    "body": "Justin Mason found it intriguing as some of these appear to be encrypted versions of the recipient's email address. To view this, search your spam archive using your email address and 'grep'. There will be at least one match: Theo van Dinter. I'm surprised by these results, especially considering I should see some false positives. However, not many matches were found, which is not that concerning. Overall, it seems worthwhile, not bad. The interesting aspect is that these hits all seem to be variations of the address. If we start encountering False Positives (FPs) or if anyone has concerns, we could make it an evaluation test for the address by turning non-word characters into characters in the regular expression at the same time. Additionally, it might be worth testing for usernames in HTML comments. I found some types in HTML comments, but haven't seen enough hits yet to bother. However, I did add a good test for email addresses in comments, suggested by Dan."
   }, {
    "body": "The CVS root of spamassassin, spamassassinlibmail and spamassassinpm in the directory has been updated. A fix for bug R in spamassassinpm's log has been implemented. Previously, r and w were not respecting autowhitelistpath. The revision and its differences have been retrieved (diffs b w u d). Non-public methods have been utilized (init sub functions like readcf, my self, path desc) to read and parse the current configuration. However, cuseuserprefs does not read user preferences or do cut sub init actions (like opening DNS cache, etc.). This email is sponsored by sfnet and welcomes you to the spamassassin commits mailing list."
   }, {
    "body": "An update regarding the cvsroot/spamassassin/ directory: The modification to spamassassin in the spamassassinraw log has revealed a bug where read and write operations were not respecting spamassassinrawrcs. This issue was found while retrieving revision. Diff b w u d reveals that spamassassinraw separates at sep and oct. If you encounter this, please be aware of the warning if doing a whitelist operation. Read the config for spamtestinit. If optaddtowhitelist is used, all addresses will be added to the whitelist. However, if optremovefromwhitelist is used, this SFNET email (sponsored by Geek Heaven's spamassassin commits mailing list) will be removed from the whitelist."
    }, {
       "body": "The modification of the cvsroot/spamassassin/spamassassin in directory dbbasedwhitelist has been updated. The log fixed a bug where r and w were not respecting autowhitelistpath dbbasedwhitelistt in rcs. The revision differences are being retrieved. The directories dbbasedwhitelist and dbbasedwhitelistipst have been separated. Libraries are being used for the tests. The test patterns are being run using satest, satinitdbbasedwhitelist, and sarun. The removeaddrfromwhitelist function is working correctly. All patterns in dbbasedwhitelist and dbbasedwhitelistipst have been checked. This email is sponsored and part of the geek heaven spamassassincommits mailing list."
   }, {
     "body": "I am writing to inform you about an update concerning the cvsroot/spamassassin/ directory. There appears to be a bug in the modified log where read and write operations were not respecting spamassassin/raw/.rcs as intended. Specifically, during revision retrieval, 'd' (diff between 'b' and 'u') was being compared with 'spamassassin/raw/sep' and 'spamassassin/raw/oct'. If this bug is encountered while performing a whitelist operation, it may produce a warning. To avoid this issue, please ensure to read the config spamtest_init, especially if you are using the optaddtowhitelist or optremovefromwhitelist options. This update has also been posted on the spamassassin-commits mailing list."
   }, {
       "body": "The CVSroot/spamassassin/spamassassinrules directory has been updated. There is a log bug where read (r) and write (w) operations are not respecting RCS. The issue involves retrieving revisions, diff b w u d (binary to unified delta), oct (Octal number), score (porn galleries, ratwarelcoutlook, shortreceivedline, safeguardnotice, mailmanconfirm, significant, ratwarediffond RCS), sep (Octal separator), friends reunited (popular UK oldschoolnetwork), whitelistfromrcvd (friendsreunitedcoukthis sfnet email is sponsored to geek heavenspamassassincommits mailing list)."
    }, {
       "body": "The CVSroot/spamassassin/spamassassin, dbbasedwhitelist, and related components have been updated. The log fix addresses a bug where r and w were not respecting autowhitelistpath. Changes can be retrieved using the RCS system in the CVS root directory. Tests are being run to ensure patterns are functioning correctly. A whitelist is being removed from the list, and the results are being displayed at 'patternsruncb'. The test suite is also being used to verify all patterns. This email is sponsored by SFNet and welcome to Geek Heaven SpamAssassin Commits Mailing List."
   }, {
    "body": "The Malte S Stretz issue has been resolved, but there is a cosmetic concern regarding adding notices about Irix and M to the docs in Cygwin's exe. This issue might be somewhat disturbing, but it has now been fixed. Additionally, there was a formatting issue that is considered broken but won't be fixed at this time. Regarding packaging, it seems everything else is okay. If no moderately serious issues surface tonight, I will release it tomorrow (GMT). This is regarding the sfnet email sponsored by Geek Heaven's SpamAssassin Talk mailing list."
    }, {
    "body": "There seems to be an issue with the system where messages from users regarding bugs are being held for moderation due to implicit message destination. This has been a source of frustration for both the users and myself, as well as Justin, since the messages were not always accepted. I apologize for any inconvenience this may have caused."
   }, {
      "body": "The changes you mentioned regarding the status of 'new', addition of comments, resolution, and fix for the bug were not reflected in Bugzilla yet. I have already committed a patch to address this issue on both head and provided an explanation in my last message about the problem and the solution the patch provides. Since you are either the assignee or are watching the assignee for this bug, I am sending this email as part of the sfnet email, which is sponsored by Geek Heaven and filtered through SpamAssassin Dev Mailing List."
   }, {
     "body": "Thank you for updating us regarding the removal of 'statusnew', 'assigned', 'additional comments' from the use of config. I appreciate this change, as I prefer to avoid such elements when they can be avoided. However, it seems that different Perl versions vary greatly in these aspects and Perl does not inherently know about the existence or location of rules unless they are in the perl libdir. Previously, 'usrshare' or similar directories were used for storing rules, but their use was much worse than the current state. Therefore, we need an out-of-band method to inform SpamAssassin where to find these elements, which is the problem. I recommend using 'perl makefilepl devnull' to enable bots to build it. I may have missed some details of your concerns; could you please elaborate specifically?"
   }, {
      "body": "I have given your concerns some thought, and it seems that you are encountering issues with the use of pmfilter and the :makemaker module. I understand your frustration as you have tried several methods to make it work but haven't succeeded. If anyone has any innovative ideas on how to resolve this issue, they are welcome to share. \n\nIt appears that some modules from CPAN include a line like 'use :makemaker', which is causing the failure on the use :makemaker command. The Perl error message suggests that the version of :makemaker required is not being met, but the makefile doesn't get a chance to reach the writemakefile line with the prereqpm :makemaker option. As a result, CPAN can't automatically upgrade this module.\n\nYou propose several potential solutions: removing the use line and adding the version to prereqpm after writemakefile; manually requiring :makemaker in the code; or overwriting pmtoblib in the makefile directly. However, each of these solutions has drawbacks and may not be ideal.\n\nIt seems that you are open to suggestions for alternative approaches. If this were an Apache project, this would likely be your veto vote. However, you suggest that the clear error message might indicate it's acceptable to require users to manually update :makemaker before SA installation."
   }, {
     "body": "Further comments on a potential solution suggest combining the preprocessor with pmfilter, provided we can sort out the :makemaker versioning issues. You are receiving this message as you are assigned or watching the assignee for this bug. This email is sponsored and related to the Geek Heavenspamassassin development mailing list."
   }, {
     "body": "The status 'new' has been removed, 'added' has been added, 'resolved' and 'resolution' are marked as completed, 'wontfix' remains unchanged, and additional comments have been appended. The RFC header you are receiving is a valid but seldom used one. You are the assignee for this bug or are watching it. This email is sponsored to the geek heavenspamassassin-devel mailing list."
   }, {
    "body": "Dear Geek Heavenspamassassindevel mailing list member,\n\nThis email is regarding a bug that was previously marked as 'Status New', 'Additional Comments' or 'Resolution' and its status has now been changed to either 'Removed' or 'Wontfix'. It appears you are the assignee or have been watching this issue on SFNet. I wanted to make sure you were aware of this change."
    }, {
    "body": "The email is informing you that certain statuses, comments, and resolutions such as 'new', 'resolved', 'fixed', and additional comments (possibly considered invalid) have been removed from the specified message ID. The purpose of this rule was to perform this action. Since you are either the assignee for the bug or watching it, you are receiving this notification. This email is part of the sfnet email that is sponsored by Geek Heaven and is related to the spamassassin-devel mailing list."
   }, {
           "body": "Subject: Caution Regarding bondedsendercom\n\nThe email suggests that bondedsendercom may be a scam. The sender warns that the default score for bondedsendercertified domains is set, but they do not trust them and advise changing the default. They have been spammed by their customers and express concern about the lack of documentation on their website regarding complaints and financial penalties for unsolicited emails. They question whether bondedsendercom actually takes action against such behavior, as their contract seems to be with their customers rather than the recipients. The sender warns not to trust them and adds that the recipient is either the assignee of a bug or watching the assignee. This email was sponsored to the spamassassindevel mailing list on sfnet and geek heavenspamassassin."
   }, {
    "body": "Could you provide instances of spam labeled with 'rcvd_inbound_sender'? I have only received one such email, which came from Amazon.com. You are the assignee for this bug or are watching the assignee. This SFNet email is sponsored to the Geek Heavenspamassassin-dev mailing list."
   }, {
      "body": "You are receiving this mail as you are either the assignee for the bug or watching the assignee. The email is regarding enhancements to SpamAssassin based on complaints about Allimage or Mostlyimage spam that's getting by SA. I have come up with three sets of rules that analyze the use of img tags in an HTML message. One rule looks at the total area of all images in the message (htmlImageArea). Another rule looks at the total number of images in the message (htmlNumImgs), and the third one looks at the longest total run of consecutive images (htmlConsecImg). The total area of all images is easy to calculate if an img tag has both width and height properties, as the running total will be increased by their multiplied product. Messages are ranked based on this score, with all messages labeled as spam if a majority of rules have a high number of img tags. This seems to do well because in my non-spam corpus, there are only a handful of messages with img runs larger than two. I am planning to see if there are any meta rules that can reduce the false positive rate for low scoring rules."
   }, {
       "body": "Your email is rephrased as follows: The additional comments look good, but do note that most image-only spam actually contains a few words at the top or a disclaimer at the end. The typical image spam that manages to bypass our filters usually consists of one large image followed by a bit more text. You are receiving this mail as you have been assigned for the bug or are watching its progress. This SFNet email is sponsored by Geek Heavenspamassassindevel mailing list."
   }, {
      "body": "I have proposed a modification to the current 'fromendsinnums' enhancement rules in SpamAssassin. As of now, any user name ending with two or more digits triggers these rules. However, I suggest we separate these rules based on the number of trailing digits, so that rules with different ratios can receive different scores. I have created test rules for from names ending with two, three, four, five, and six or more digits, as well as one for single digits for completeness. Please note that I get poor SOs for 'fromendsinnums' due to my corpus being primarily composed of Yahoo group traffic which seems to contain users who often append numbers at the end of their names. For reference, here are the normal stats for 'fromendsinnums' and my adjusted stats. You are receiving this mail as you are the assignee for the bug or are watching its progress. This SFNET email is sponsored by Geek Heaven SpamAssassin Devel mailing list."
   }, {
     "body": "Dear Daniel and Justin, I believe rsync is crucial as it's highly efficient in terms of bandwidth. It also allows for the selection of specific files similar to wget. Bandwidth is a significant concern for some of us Europeans involved in this project compared to your team. In my opinion, rsync is by far the most efficient and scriptable way to handle such tasks these days. If we can automate rsync submissions with good authentication, it should be fine. However, I need to point out that the current rsync method is not fully authenticated. I suggest we use rsync in conjunction with SSH and SSH keys for secure access. Since we already use the hughesfamilyorg server for rsyncing, I propose we submit the data in a separate subdirectory. I'll also look into setting up a nightly hit frequencies collation system. Let me know if there are any concerns."
   }, {
     "body": "Dear User,\n\nIt appears that there's an issue with your FreeBSD stable setup, specifically with SpamAssassin. The command 'rterpm line used to work until the upgrade, but now using spamd with the 'h' switch seems to be necessary as piping the message directly to SpamAssassin from within your mail user agent (VM under Emacs) is causing an error ('no such file or directory' and 'reporting requires authentication').\n\nPlease try registering for Razor, either through 'razorregister' or 'razoradmin register'. If my recall is correct, this should resolve the issue.\n\nBest Regards,"
   }, {
    "body": "In Emacs rmail, there are various techniques to sort your favorite correspondents from the mix. Here are a few methods:\n1. Creating custom groups and directing messages from specific senders to these groups.\n2. Using filters based on subject lines or headers to automatically sort messages.\n3. Utilizing tags for quick access to important emails.\nPlease note that hundreds of spam commercials can still be found in your inbox as a filter for the campus computer system only applies to subject lines and headers on many of these spam commercials. For better handling of spam, consider subscribing to the SpamAssassin talk mailing list."
   }, {
     "body": "Hello Kenneth Nerhood, \n\nI've been experiencing some peculiar issues with an AWL I recently installed. After setting up a fresh system and running multiple test spams through it from the same user, all messages should have scored over the AWL, but it kept adjusting them downwards. By about message number 10, I had a negative score. This is contrary to what's intended as per SpamAssassin. The idea is that legitimate senders who consistently score high will eventually be freed from 'AWL hell' after messages. \n\nPlease note that running a single spam through SpamAssassin at T will eventually whitelist the spammer, which is why the manual states not to do it. This is a discussion for the spamassassin-talk mailing list on SFNet, sponsored by Geek Heaven."
   }, {
     "body": "I'm unsure of your location, but there seems to be an event happening tonight at the DNA Lounge in San Francisco. The Electronic Frontier Foundation is hosting a benefit party and special guests, including Wil Wheaton and Wesley Crusher from Star Trek: TNG, will be in attendance (and perhaps in an unusual encounter with Barney the Dinosaur). If you're free, feel invited to drop by. This email is sponsored by OSDN - if you're tired of your current cell phone, consider upgrading for free. Be wary of unwanted spam or intrusive mailing lists."
   }, {
      "body": "Dear Team, \n\nOn Thursday at 8 AM, Justin Mason plans to determine the freqs tonight. I suggest dropping tests that are not essential and waiting for your comments. Tomorrow, drop tests that are ignored by everyone. This step is unnecessary unless you've made significant changes to the scripts.\n\nIt appears that the 'logsto' script has been altered and the part allowing us to specify immutable test scores at the top seems to be removed. I took a cursory look through the code, but couldn't fully understand how it has changed. We would like to be able to set immutable test scores somewhere in there or is that now handled by the 'tflags' stuff for the last couple of releases.\n\nAny test which occurred infrequently according to my subjective criteria will have immutable scores, as well as a few other rules. The ga will kick off shortly. However, I will be away this weekend at Linuxbierwanderung, so Craig might have to run the ga. This shouldn't be a problem assuming I can get the darned thing to compile."
   }, {
     "body": "The changes you suggested for the SpamAssassin bug have been understood. The best solution, as per your recommendation, will be to copy the modified rules from 'blib' and install them during build time instead of installation time. This modification will ensure that the rules files are altered before the build process rather than after. As you are the assignee for this bug or are watching the assignee, or are on the CC list for this bug or are watching someone who is, you are receiving this email. This message is sent as part of the sfnet email, which is sponsored by Geek Heavenspamassassin-devel mailing list."
   }, {
    "body": "Dear Steve Thomas,\n\nI have set up a honeypot user and configured an alias for it, along with a hidden link of the same background color at the bottom of my HTML pages. I have also created a procmailrc file for this user that submits the messages to Razor and saves them locally.\n\nThis setup has been in place for about a month now, but so far I have only encountered some Sircam viruses on it. The viruses are rejected at the MTA level, which means they aren't being saved or reported to Razor.\n\nI would now suggest using a user with a procmailrc instead of a system alias for a more secure and easier way to filter out junk like bounces, viruses, etc. that can make the corpus dirty.\n\nThis SFNet email is sponsored by Jabber, the fastest growing real-time communications platform. Don't just IM, build it in SpamAssassin Talk Mailing List."
   }, {
       "body": "Dear Bob, \n\nIt appears that your daily logwatch reports have been classified as spam by SpamAssassin. A recent report generated the following message: 'fixed in CVS (I think) or at least my logwatches get through fine'. If this issue is not resolved in CVS, please submit a bug using Bugzilla and attach a sample mail message with all headers intact as an attachment for further analysis.\n\nIf this problem is not related to the current state of the CVS, then it should be reported. Jabber - the fastest growing real-time communications platform worldwide - encourages you to discuss this in the SpamAssassin talk mailing list. \n\nBest,\n[Your Name]"
   }, {
      "body": "I understand your concerns about the issue with spamassassin and the 'spec' requirement. It seems it is causing problems due to its incompatibility with Perl, which you are still using due to reported issues with newer versions. As there appears to be a significant amount of legacy Perl code, you anticipate filing a bug report soon to address these compatibility problems. Additionally, spamassassin did not mention the need for a newer version in your initial examination. Regarding the cell phone, if you're tired of the same old one, there is an offer for a free upgrade available here: [link to upgrade offer]. This unrelated topic might be more suitable for a separate discussion forum, but since you are assigned to this bug or watching its progression, I thought it relevant to include in this email."
   }, {
      "body": "Your message was not delivered as it contained text that may be considered banned or potentially offensive. The sender of this email, in exchange for a license for the Habeas warrant mark, warrants that this is a Habeas compliant message and not spam. If you encounter the use of this mark in spam, please report it. However, there appears to be an issue with SpamAssassin on your server, as it is spewing errors like never seen before. To resolve this issue, I recommend deleting the contents of '/usr/local/share/spamassassin' and reinstalling SpamAssassin. Some files may be new, so they won't be overwritten when you downgrade."
   }, {
       "body": "Hi David, have you looked at and discussed this article and its approach? If so, I'd recommend checking out the Perl module 'bayesian' on CPAN and the subsequent discussion thread on sfnet email (sponsored by OSDN). I've noticed you mentioned being tired of the same old cell phone. You might want to consider getting a new one for free. Here's the link for the SpamAssassin development mailing list."
   }, {
    "body": "Dear Craig Hughes, I've rephrased your email as follows:\n\nCraig Hughes,\nAll headers have been preserved. Some addresses have been obscured and certain hostnames have been replaced with spamassassin.taintorg, which (to the best of my knowledge) should have a valid MX record.\nIf I recall correctly, in most cases the headers appear as they were initially received.\nCraig, you mentioned something about spamassassin.taintorg. Well, that's probably just as well anyway.\nThis SFNet email is sponsored by Geek Heaven and is part of the spamassassin-talk mailing list."
    }, {
     "body": "Dear Recipient, \n\nI'm writing to inform you that I would appreciate if this message could be shared with other potential parties. However, there are a few caveats: \n\n1. The results of these distributed tests may not be reliable when running over a public corpus, as they could potentially be falsely or incorrectly reported to various entities such as Razor DCC Pyzor, etc., certain RBLs. Consequently, I do not trust the results in any way, shape, or form. \n\n2. These messages could also be submitted multiple times to projects like SpamAssassin that rely on filtering results for GA tuning and development. Spammers might adopt elements of good messages to confuse filters. This issue could be alleviated somewhat by adding a nilsimsasignature or similar to the masscheck file, or by giving each message file a unique name. \n\n3. The third problem does not concern me significantly. \n\nThese problems, and perhaps others I have not identified, seem to be unique to spam filtering compression corpora. Other performance-related corpora have their own set of issues. In essence, I don't believe there is a replacement for having multiple independent corpora. Finding better ways to distribute testing and collate results seems like a more viable long-term solution. \n\nI'm glad we are working on exactly that for SpamAssassin. If you are going to focus on filter development, building a corpus of messages (half spam, half non-spam) is not too much work if you don't get enough spam. Creating multiple techniques for spam traps (web, Usenet), replying to spam, and receiving thousands of non-spam every week are straightforward tasks. \n\nBest regards,"
   }, {
    "body": "I would rephrase the email as follows: The emails being sent could potentially be mislabeled or incorrectly reported to Razor DCC, Pyzor, etc., certain RBLs. I do not believe that the results from these distributed tests can be trusted in any way, shape, or form when run on a public corpus. It is noted that these same emails could also be resubmitted multiple times to projects like SpamAssassin, which rely on filtering results for GA tuning and development. This issue may be somewhat alleviated by adding a nilsimsa signature or similar to the masscheck file, using unique names for each message file, or rewriting the message IDs to help distinguish them. It is also suggested that altering the message IDs may assist in this. Spammers might adopt elements of good messages to evade filters, and there will always be advancements in technology by both spammers and non-spammers. The second and third problems do not concern me much, but I believe that these issues, among others that have not been identified, are unique to spam filtering compressed corpora. Other performance-related corpora have their own set of problems. In other words, I do not think there is a replacement for having multiple independent corpora. Finding better ways to distribute testing and collate results seems like a more viable long-term solution. I am glad we are working on exactly that for SpamAssassin. If you're seriously involved in filter development, building a corpus of messages (half spam, half non-spam) is not too much work if you don't receive enough spam. Gathering multi-technique spamtraps, web, usenet, and replying to spam is quite easy, and who doesn't get thousands of non-spam every week? The primary reason I released this was to offer a substantial corpus for academic testing of filter systems. This enables comparison between filters using a known corpus for SpamAssassin development. Everyone must maintain their own corpus."
   }, {
    "body": "Subject: Razor Users Digest - Vol. msgs (Razor Users with Sendmail Fri Aug Rose) \n\n If you did not add it when compiling, there are two ways to check if your sendmail has Milter support:\n1. Another way would be to grep your sendmailcf for the word 'milter'.\n2. If your sendmail has been compiled with milter support, you can easily run 'smrazor'. We've been using it for a while without others on the list mentioning it as well.\n\n Is there an easy way to tell if Milter is compiled in? To see all the options compiled into and the version of sendmail, try the following:\necho $PATH_TO_SENDMAIL | grep sven\nThis SFNET email is sponsored by OSDN.\nTired of your same old cell phone? Get a new one for free here: [razorusers mailing list](razorusers.sf.net)\n\nRegards,\nBobby Julian Bond"
   }, {
    "body": "Dear Paul,\n\nYour Sendmail has been compiled with Milter support, and it's suggested that you can easily add smrazor to it. Many on the list have been using it without issues, and it's also been mentioned by others.\n\nHowever, there is a concern that forking a Perl interpreter for every incoming mail could potentially make your mailer vulnerable to a Denial of Service (DoS) attack. The question raised is whether there's a way to run smrazor without this overhead. Ideally, a smrazor you could communicate with over a Unix socket would be beneficial until such a solution can be found. Currently, I cannot allocate resources to run smrazor at all.\n\nRegarding the email sponsorship, the sfnet email is sponsored by OSDN. If you're tired of the same old cell phone, consider upgrading to a new one. For those interested in smrazor, there's a mailing list specifically for its users: freerazorusers."
   }, {
      "body": "Hello, I have written a Python script to use Razor with qmail. The script is complete but I want to test its output with some positive spam emails. Do you know where I can find such emails? I apologize for my poor English."
    },
    {
      "body": "Also, I noticed that you have been sponsored by OSBN and tired of the same old cell phone. You might want to check out the Razor Users mailing list for a new option."
    }, {
     "body": "Hello,\n\nI'm having trouble with my script when I run it manually in the console, everything works fine for me. However, when I try to integrate it into my general filter script running with qmailq uid, I encounter an exit status error and a log entry in my mail log: 'Can't call method log on unblessed reference at line'. My log file is located at homeuser/razor/razoragent/log and has write permission for the qmailq user. Any ideas? It seems like the email is scanned by the Procmail filter.\n\nRegarding your sponsored email, if you're tired of your old cell phone, check out our new offers for free Razor users mailing list."
   }, {
     "body": "Dear Joe Berry,\n\nIt appears that you are experiencing issues with your FreeBSD server, where you suspect it might be either a Razor problem or a Sendmail issue. The server supports your wife's website and various other services such as Apache Server, Jabber, etc. The machine occasionally becomes slow due to a surge of emails following an outage in your DSL-based ISP. You mentioned that you had no arguments associated with the call to razorcheck in your etc/procmailrc file, which led you to add home/etc/razor as an argument. Since then, you have not encountered any downtime, so it is unclear if this change has improved Razor processing speed. However, your main concern seems to be the slowdown caused by a backlog of email processing leading to multiple Sendmail processes.\n\nYou have inquired about possible ways to limit the number of Sendmail processes or any ideas that could help resolve this issue. Any suggestions would be welcome.\n\nRegards,\n[Assistant's Name]"
   }, {
       "body": "Dear Joe Berry, \n\nI have rephrased your email to better convey its content. Here's the revised version:\n\nSubject: Limiting Concurrent Sendmail Processes on Your Server\n\nHi Joe,\n\nI noticed that you're experiencing issues with multiple concurrent Sendmail processes affecting your server's performance, especially after a reconnection to the internet following an ISP outage.\n\nYou mentioned that you have switched to using Qmail but found some settings in your etcsendmailcf file that might be relevant. However, I couldn't help but notice that you are still running Sendmail processes, despite your transition to Qmail.\n\nYou also shared a possible solution of adding 'home etcrazor' as an argument to your etcprocmailrc file, which seems to have alleviated the issue thus far. Unfortunately, you haven't been able to confirm if this change has significantly sped up your Razor processing.\n\nI understand that this issue might not necessarily be a Sendmail or Razor problem but I thought it would be beneficial to share this information with the rest of the community. If anyone else has encountered similar issues, we'd love to hear your thoughts on potential solutions.\n\nRegards,\n[Your Name]\n\n"
   }, {
     "body": "Thank you Joe Berry for your valuable advice. One more problem solved! In dealing with some software issues, we had to work around them by employing tricks in another software. The solution appears to be an aggregator. Regarding the SFNet email, it's sponsored by OSDN and we're tired of the same old cell phone. If you're a RazorUsers mailing list member, consider upgrading to a new one for free."
   }, {
     "body": "The following Razor debugging sequence indicates that my email is being processed from bytes to bytes after the preproc phase. This results in an exit code which is not as expected. I have included the sequence below for your reference. No 'razoragentconf' was found, so defaults were used instead. Bootup logging initiated to stdout. The Razor home configuration was identified. The Razor identity was determined. The Razor agents are starting. A check was performed on the home directory. It was determined that I am using a Linux operating system (qmailmkeecom.mon.nov). The mail was read straight from the input. Preprocessing of the mail was done. The whitelist file for Razor was skipped. Items were read from the servers discovery, nomination and cataloguelist files. Defaults were assigned to honorcloudmark.com, truthcloudmark.com, firecloudmark.com and aptcloudmark.com. Items were also read from the server configuration files for truthcloudmark.com and firecloudmark.com. The mail was checked seconds before the closest server was discovered. truthcloudmark.com was found to be a catalogue server. The server was computed. The mail was skipped in the check as no queries or spam were detected. The connection to the server truthcloudmark.com was established and terminated afterwards. A check by Razor finished successfully. The Qmail invoked from the network. The 'HELO' command was received by an unknown host with SMPT. The Lyris web interface was accessed at a later point. A new freeware download for Diskeeper, a product manager executive software, was available. The mail was found to be a new freeware download for Diskeeper Lite, which includes the same advanced defragmentation technology used in Diskeeper. It is faster than previous versions and runs on all Windows operating systems from Windows NT onwards. The new Diskeeper Lite is manual-only and cannot be scheduled or run across a network. However, it is far superior to any built-in defragmenter and much faster. A full version of Diskeeper is available for purchase. We periodically send new product information electronically to those individuals who voluntarily provide us their email address. If you wish to remove yourself from this list, please do not reply to this email. To unsubscribe, send the email address listed below, along with your name on a separate line, to Executive Software International Inc. All rights reserved. Diskeeper, Executive Software and the Executive Software logo are either registered trademarks or trademarks of Executive Software International Inc. in the United States and other countries. Windows and Windows NT are registered trademarks of Microsoft Corporation in the United States and other countries. All other trademarks and brand names are the property of the respective owners. This email is sponsored by sfnet and a free here for a new RazorUsers mailing list."
   }, {
    "body": "Dear Jay,\n\nI hope this message finds you well. Regarding your inquiry about our previous considerations regarding OCR and forms scanning solutions, I believe Razor may have mistakenly assumed that we were currently grappling with this decision.\n\nTo answer your questions: Yes, it's correct that we had initially considered implementing OCR technology to cut down data entry costs and enhance efficiency. The primary motivator for us was the potential to streamline our processes and improve productivity.\n\nAs for the specific software we went with, I regret to inform you that I don't have the details readily available as it was a decision made by our tech team some time ago. However, if you are still in the research phase, I encourage you to explore various options, including the one we chose, and find what best suits your needs.\n\nShould you wish to stay informed about our final decision and its impact on our company, please feel free to keep in touch. If my team is not the right point of contact for this matter, I will forward your email to the appropriate individual within our company.\n\nBest Regards,\n[Your Name]"
   }, {
    "body": "Hello,\n\nDid any of you hear about a Razor plugin for Mozilla's plugin system that would allow users to report an email as spam directly on the server? This would be under the administration of Arnaud Arnaud Ablard, Administrateur RSEQS et Systèmes at the Faculté de Sciences de l'Université de Nantes (SFNET).\n\nThis SFNet email is sponsored by OSDN.\nTired of your old cell phone? Upgrade to a new one! Check it out for free here: [Razor Users Mailing List]"
   }, {
      "body": "Hello RazorUsers, \n\nDid any of you hear about a potential Razor plugin for Mozilla? This plugin would supposedly add a 'Report as Spam' button for users to report an email as spam on the server. Arnaud Abelard, Administrateur Réseaux et Systèmes at the Irin Faculty of Sciences, University of Nantes mentioned it in an SFNet email sponsored by OSDN. \n\nIn addition, we have a sponsor offer: tired of that same old cell phone? Get a new one for free with this SFNet email sponsored by OSDN! For more details, subscribe to the RazorUsers mailing list. "
   }, {
       "body": "We regret to inform you that revoking self-submitted content from our network, which may have been inadvertently blocked by you, results in the permanent deletion of said content. As a reminder, our network is focused on distributing content that users do not wish to receive, much less have intellectual property rights associated with it. To avoid any misuse or unintentional infringement, we advise you to carefully read the End User License Agreement (EULA) before submitting anything to Razor. Please be aware that according to the EULA, there is no allowance for commercial use and anything submitted becomes entirely their intellectual property. If you wish to retain intellectual property rights on any content, we strongly advise against accidentally hitting this 'submit' button as it would be considered spam. This email is sponsored by OSDN. For free Razor user offers, please visit our mailing list."
   }, {
     "body": "Dear Daniel Higgins, \n\nI was indeed serious about my admiration for the HTML graph you created. Unfortunately, I'm not proficient with Perl to replicate it myself. However, your custom Perl-based spam blocking framework seems quite impressive. The use of plugins for spam detection and maintaining stats in a MySQL database is intriguing.\n\nRegarding the Razor effectiveness stats you shared, I was wondering if there have been any false positives yet? I'm currently in the process of creating my own corpora for testing purposes. I'll share my findings with you after I've conducted some tests of my own.\n\nP.S. Apologies for the HTML formatting in the original message. For those still using non-GUI clients, I understand it might not be convenient to read it as text. The spam count refers to the total number of spam messages detected by various filters. 'Jammed' is a custom phrase ranking system, 'Razor'd' is the Razor Bayesian filter based on Paul Graham's work using statistical probability, and 'Blacklisted', 'Trollbox', and 'Bayesian' are categories of filtered messages. The SFNET email sponsorships were included in the message you sent.\n\nBest regards,"
    }, {
    "body": "Dear List, \n\nI have been working on porting code to run under Perl on Windows. The modifications needed are relatively minor and can be made to ensure compatibility with the existing code. My question is: how best can I get these changes merged into the main repository? Additionally, would there be interest in a Perl version of the current codebase, and if so, how can I go about getting those changes accepted? \n\nRegards,\n[Your Name]"
   }, {
       "body": "I found a script called 'rotate' for rotating log files, which can simplify the process. I believe it originated from my hosting provider PairCom, as they have it installed. Redistribution appears to be allowed. If you are looking for an official source or more information about this script, you might be better off asking on the spamassassin-talk list. I posted a solution for a similar problem and how to overcome it in spamassassin on the spamassassin-talk list. Good luck! David Rees\n\nFor those concerned with managing Razor agent log files that keep growing, it is possible to configure Razor log via syslog to make it easy to rotate logs. However, I could not find information about this in the man pages. If I don't find a solution elsewhere, I will have to write a script to periodically go through each user's home directory looking for Razor agent log files to rotate. \n\nThis email is sponsored by osdn, tired of that same old cell phone? Get a new one here for free (razorusers mailing list)."
   }, {
    "body": "Dear User,\n\nI have rephrased your email for better understanding and clarity:\n\nOn Thursday, September at Leland Woodbury, I came across a useful Perl script called 'rotate' which simplifies the process of rotating log files significantly. I could not find an official source for this script, but my hosting provider PairCom has it installed, and it seems that redistribution is allowed. Therefore, I have attached it to this email.\n\nAdditionally, I noticed that the standard logrotate tools included with many systems or at least Red Hat systems support wildcards when rotating files. So, specifying a pattern like 'home/razor/razoragentlog' can be used.\n\nAlso, it appears that the SFNET email is sponsored by OSDN, and if you are tired of the same old cell phone, you might want to check out the 'Free Razor Users' mailing list for a new one. Hope this information helps!\n\nBest regards,"
   }, {
    "body": "You might find a solution to your Razor concern more quickly on the spamassassintalk list. The community there is likely to have an answer for this issue. I provided a comprehensive response about the SpamAssassin Razor interaction and how to overcome it on the spamassassintalk list. Thank you for the post, as it answered all my questions regarding SpamAssassin Razor. \n\nHowever, if you're worried about your server filling up with Razor agent log files that keep growing, it might be possible to configure Razor log via syslog to make rotating logs easier. Unfortunately, I couldn't find any relevant information in the man pages. If a script needs to be written to periodically go through each user's home directory looking for Razoragent log files to rotate, that will be necessary. \n\nBest regards,\nDave\n\nP.S. This email is sponsored by sfnet, tired of the same old cell phone? Get a new one here for free: razorusers mailing list"
   }, {
    "body": "You were exactly the person I had in mind to address this issue on Thursday, September. Here's a suggestion: it might be better to ask this question on the spamassassintalk list. The community there is likely to have an answer for this problem and they have already provided a fairly lengthy, complete response to this problem and how to get around it in the sa forum.

   As for the unrelated topic, here's an opportunity for you: tired of that same old cell phone? Get a new one for free from the razorusers mailing list. This is not sponsored by sfnet or OSDN."
   }, {
    "body": "If that's the case, could someone please direct me to a resource that explains how to uninstall it from my system? I don't see the point in invoking it, especially when it seems to error out on me while trying to load 'permission denied at line: leaving helperapp run'. It appears you might want to check that path first, of course. Randomly generated a 'chicken finger device', Theo. For information about PGP/GNUPG, see the end PGP signature. This SFNET email is sponsored by OSDN. Tired of the same old cell phone? Get a new one here."
   }, {
      "body": "It appears that there is an issue with the write privileges for the 'razoragentlog' file. Setting group and owner to read and execute will not solve a write problem as insufficient write permissions have been encountered. A quick workaround would be to use the 'chmod g+w' command on the file. However, it is better to restrict access as much as possible in agentpm when creating an object. If the object does not have write permission to the log file, it will not succeed and later in the code, it will fail with an 'unblessed error'. This problem seems to occur with Razor, but I'm unsure if it's related to SpamAssassin as well. Since this is my first time running Razor and have also installed SpamAssassin, I am seeing the following messages: 'cant call method log on unblessed reference at line line'. Any ideas? Razor seems to run correctly over the command line. I will investigate further and get back to you."
   }, {
     "body": "Dear Mike Burger, \n\nYou might find it more beneficial to post your question on the SpamAssassin-talk list. The members there are likely to have an answer for this issue.\n\nI've provided a detailed response to this problem and how to bypass it in SpamAssassin on the SpamAssassin-talk list. It appears that your randomly generated judgment stems from bad experiences, which often results from poor judgement. For more information about PGP/GNUPG, please refer to wyzrend's PGP signature.\n\nThis email is sponsored by OSDN. Are you tired of the same old cell phone? Upgrade to a new one here for free.\n\nRegards,\n[Your Name]\n\nP.S: For more information on RazorUsers, please refer to the mailing list."
   }, {
      "body": "Dear Eugene, \n\nThank you for your assistance in resolving the issue. It appears that the problem was due to an insecure dependency in open while running setuid at line 'line' from 'thu sep'. It seems like you are running the script via Procmail. The permissions on Procmail should be set correctly to avoid such issues. When Procmail is setuid or setgid, the permissions should ideally be 755 (rwxr-xr-x). If this is indeed the problem, an easy solution would be to add 'dropprivs yes' in the Procmailrc.\n\nI hope this helps and resolves the issue. Let me know if you have any other concerns.\n\nBest,\n Theo van Dinter"
   }, {
      "body": "Dear Michael Duff and David Rees, \n\nI'm writing to inform you that I've encountered an issue while running Razor for the first time. The problem seems to be related to insufficient write privileges on the razoragentlog file. A temporary solution is to use 'chmod g+rx' command on this file. However, it would be best to set appropriate access restrictions within AgentPM when creating the object to prevent such issues in the future.\n\nIf the object doesn't have write permission to the log file, the operation does not succeed and later in the code, when the log object is used, it fails with an 'unblessed error'. I believe this problem might be related to Razor since it occurs with a freshly installed SpamAssassin and Razor.\n\nI'm seeing these messages: 'cant call method "log" on unblessed reference at line line'. Razor appears to run correctly over the command line. I also run SpamAssassin and would like to integrate the two, but I'm not sure if this issue is related to SpamAssassin or Razor.\n\nAny ideas are appreciated. Thanks, Dave\n\nNote: This email is sponsored by OSDN. Tired of your old cell phone? Get a new one for free at [razorusers mailing list](http://razorusers.mailinglist.com/)."
   }, {
       "body": "Hello all, I'm having trouble with a sitewide installation and was wondering if anyone has been successful in doing so. Here is an extract from my procmaillog: 'check bad file descriptor dependency in open while running setuid at line... from Thu Sep spam computer maintenance homeeugenecaughtspam in razoragentlog'. I simply get the bootup message and that's it. Sep logging initiated, please help! Thanks, Eugene"
   }, {
     "body": "It appears you have an issue with a bad file descriptor, insecure dependency, and an open while running setuid at m line in your current process. This seems to be happening when Procmail is being used, as suggested by the 'caughtspam' in your email address. I would recommend checking the permissions on Procmail, especially if it is setuid or setgid. In such cases, the permissions should ideally be 755 (rwxr-xr-x) to avoid potential taint mode issues. If this issue persists and Procmail is indeed the culprit, a simple solution would be to modify your procmailrc file by adding a randomly generated string at the beginning of your first line of code, as a workaround. Additionally, it seems there was an incident involving a VW bus that may have affected the application you're using. Regarding the PGPSignature, here are more details: gnupg gnulinux for info see end pgp signature."
   }, {
      "body": "Dear Josh Hildebrand, \n \n I apologize for any confusion I may have caused with my earlier message. To clarify, I was referring to the dccproc feature in your spam filtering software. It seems that this component is outdated and should be replaced with a newer version or possibly removed from the system entirely. If that's accurate, could you please guide me on how to remove it? \n \n Regarding the issue with 'helperapp run razor agents protocol version seconds before closest server agent terminated', I believe there was an error related to permission denied at line leaving helperapp run mode. This appears to have occurred when trying to load a permission. \n \n Thank you for your assistance, and I appreciate the sponsorship of this SFNet email by OSDN.\n \n Regards,\n [Your Name]"
   }, {
     "body": "Dear User,\n\nIt seems you are experiencing an issue with Razor and SpamAssassin. Given that it's unclear whether the problem lies with SpamAssassin or Razor, I would recommend posting your question on the spamassassintalk list. The community there is likely to have a solution for this issue by Thursday, September [Date].\n\nSince this is your first time using Razor and you also run SpamAssassin, you might want to integrate the two applications. However, before doing so, please ensure that the problem you're encountering is not specific to one of these tools.\n\nRegarding the error message 'cant call method log on unblessed reference at line [Line Number]', it appears Razor is unable to access or use a method due to a lack of blessing. This issue might be resolved by properly blessing the necessary objects before using them in your code.\n\nLastly, I noticed that your email contains sponsored messages from osdn and razorusers mailing list. These messages are common in free software communities.\n\nBest regards,\n[Your Name]"
   }, {
     "body": "You may find an answer to your question more quickly on the spamassassintalk list as the members there are likely knowledgeable about this topic. I have just posted a similar message there. In case you didn't know, this sfnet email is sponsored by OSDN and is part of the razorusers mailing list. If you are tired of receiving the same old cell phone offers, consider getting a new one here for free."
   }, {
    "body": "Hello Dave,\n\nThank you for reaching out regarding your issue with Razor and SpamAssassin. It seems you've encountered an error with the 'log' method within Razor, possibly due to a file or method not being found. Here are a few suggestions:\n\n1. Ensure that all necessary files are present in the correct locations.\n2. Check if there are any permissions issues preventing Razor from accessing these files.\n3. Verify that Razor is properly installed and functioning correctly when run independently.\n\nIf you've already checked these points and are still experiencing issues, I would recommend checking the logs for both SpamAssassin and Razor to see if any additional details about the error can be found. If the problem persists, please provide more specific details about your setup so that a more tailored solution can be provided.\n\nBest regards,\n[Your Name]"
   }, {
      "body": "The recommended action to your FAQ would be 'c' (all of the above) if you want to correct the permissions on procmail. You mentioned that you have done 'b' (add dropprivsyes to etcprocmailrc), and things seem to be working for now, but it is advisable to also change the permissions of procmail as suggested ('a' - chmod usrbinprocmail) to ensure security. Eugene Chiu provided this solution in response to your question on behalf of Theo van Dinter on September [date]."
   }, {
      "body": "I have reviewed your email. It appears that you have set up Razor and SpamAssassin, but are encountering an error about a 'no such file or directory' issue in your mail log file. From the information you provided, it seems like there might be a problem with calling the 'log' method on an unblessed reference at a specific line. \n\nYou have mentioned that you have gone through the archived list and found a possible permission problem on the log file. You followed the suggestions in the archives by changing the permissions on the file, but the issue persists. Any other assistance would be appreciated, as it seems like there might be something else you missed or forgot to do.\n\nBy the way, it looks like your email is sponsored by OSDN and you seem frustrated with the same old cell phone. I noticed that you mentioned a RazorUsers mailing list for users of razor phones. Perhaps, you would be interested in getting a new phone here as part of a promotion offered at this link."
   }, {
       "body": "Hello,\n\nI have reviewed your email and understand that you have set up Razor and SpamAssassin, but you are encountering an error related to a log file. The error message suggests a 'no such file or directory' issue and a possible permission problem on the log file. However, I couldn't find any relevant information about this error in the archived list. It seems this issue might be more common among SpamAssassin users, so I would recommend checking the spamassassinusers list for potential solutions. As you mentioned, you have already updated the spamd startup flags using the latest version of SpamAssassin.\n\nRegarding your cell phone, if you are tired of the current one and interested in a free upgrade, please check out the razorusers mailing list. They offer new phones at no extra cost.\n\nBest regards,"
   }, {
    "body": "Dear David Rees,\n\nI have set up Razor and SpamAssassin, but I keep encountering an error in my mail log file with the message 'cant call method log on unblessed reference at line'. After searching through the archived list, I haven't found a solution for this error. It seems that it might be a permission problem on the log file.\n\nHowever, I couldn't find any relevant information here. It appears that this issue is discussed on the spamassassinusers list, which I have recently asked last week. My suggestion would be to add 'h' to the spamd startup flags using the latest version of SpamAssassin.\n\nBest Regards,\n[Your Name]"
   }, {
    "body": "It appears you're encountering a permissions issue with the Razor log file used by SpamAssassin. The log file needs to be made world-writable. I suggest checking if the necessary changes have been made correctly and verifying the file ownership and permissions. If the problem persists, it might be helpful to ensure that the Razor and SpamAssassin services are properly set up and running. You may also want to verify that the log file path specified in your configuration is correct. Please let me know if you need further assistance."
   }, {
       "body": "Hello Team,\n\nI understand that the question regarding a user's trust rating has been frequently asked, but I haven't found a recent answer. Are there any updates on when this feature will be available? I'm particularly interested in knowing the plans for it - will it be integrated into the client (web-based or email), and if so, would it possibly be delivered nightly? If you could share your thoughts on this topic, I would greatly appreciate it.\n\nRegarding the sponsorship message in this SFNET email, sponsored by OSDN, I'm growing tired of the same old cell phone advertisement. Perhaps a new phone model or a different offer for Razor users mailing list could be considered."
    }, {
     "body": "It appears that the bug tracker on SF is not heavily utilized. Are there alternative platforms for reporting bugs in this community? Also, I recently came across an offer for a new cell phone; if anyone has recommendations for a better one or knows where to find deals, please share! Oh, and just a reminder: I've been considering switching from this old sponsored OSDN email. Have you heard of any good alternatives for the Razorusers mailing list?"
   }, {
       "body": "Dear User,\n\nI understand you're having trouble with your spamdspamcrazordcc setup, specifically with Razor logs showing 'not known spam'. To ensure that your Razor installation is functioning correctly, you can perform a test. Here's a brief hint: You can send an email to a specific address (usually provided in the documentation) for Razor to analyze. If the analyzed email is marked as spam, it indicates that Razor is working properly.\n\nI recommend checking the official documentation or user guide for detailed instructions on how to perform this test. If you need further assistance, feel free to ask.\n\nAlso, I noticed you mentioned 'sfnet email is sponsored osdn' and 'tired of that same old cell phone'. Here are some resources for Razor users mailing list and a link for a new, more affordable cellphone. Enjoy exploring!\n\nBest regards,\nSupport Team"
   }, {
       "body": "Dear David Raistrick,\n\nI have reviewed your email regarding the Razor check on samplespamtxt from SpamAssassin. After upgrading to RazorAgents yesterday, you mentioned that you're not seeing any positives from Razor including the samplespamtxts from SpamAssassin. Here are a few suggestions:\n\n1. Ensure that your RazorAgentConf file is correctly configured.\n2. Check if there are any issues with the rootrazor or razorhome directories.\n3. Make sure you have enabled logging in your Razor setup.\n\nI hope these suggestions help! Let me know if you encounter any further issues.\n\nBest,\n[Your Name]"
   }, {
     "body": "Regarding our previous topic, I'd like to address a personal matter that has been delayed due to it being caught in a server-wide spam filter. Here is the revised email:

    'Subject: Personal Update

    Hey Dad,

    Just flagging this as it seems unrelated, but I have an update on my schedule. I'll be staying after school today so I can work on the school newspaper layout. Nords will pick me up later than usual. I'm not sure how to explain this, but I'll let you know when I'm coming home.

    Oh, and by the way, I won't be able to sign in today as I'll be preoccupied with the school newspaper work.

    Best regards,
    [Your Name]

    P.S. This email is brought to you by SFNET - Welcome to Geek Heaven, RazorUsers mailing list.'
   }, {
   "body": "I'm forwarding all my spam emails today and calling any numbers I can find, to inform everyone who spammed me today that they should expect an increase in their business costs. I suggest you do the same, as this could tie up their phone lines and cost them a significant amount of money, making it unprofitable for them to continue with spamming activities. It's also fun to imagine 'let the spammer die'! This email is sponsored by Geek Heaven, specifically tailored for RazorUsers Mailing List."
   }, {
     "body": "I have not received any update regarding this matter, so please excuse my repetition of the topic. It seems that bugs should be reported elsewhere than on the SF bug tracker. This SFnet email is associated with the Geek Heaven razorusers mailing list."
    }, {
    "body": "It is possible to use Razor without filtering out empty emails as attachments alone don't necessarily indicate spam. However, it's important to note that an email with no content in the body may be considered spam if it only contains an attachment and no meaningful subject or content. If you want to send emails to yourself where the subject and body are empty for some reason, this is technically possible but could potentially be seen as spam if not handled correctly. Keep this in mind while using Razor."
    }, {
    "body": "Hello Vipul, \n\nIt seems that you are using an older version of Razor as it does not filter out empty emails. If a mail has an attachment, it is still considered spam by Razor. However, if you would like to send emails where the subject and body contain all important information (and the body is empty for the rest), this behavior can be seen as spam. I suggest using a more recent version of Razor or modifying your email sending practices accordingly. \n\nRegarding your question about sending emails to yourself, with only important information in the subject and body being empty, it's not recommended to do so as it may raise concerns about potential spam. \n\nThank you for your interest in Razor and Geek Heaven.\n\nBest regards,\nRazorUsers Mailing List"
   }, {
     "body": "After whitelisting all legitimate mailing lists, I encountered one false positive within the last four days. Razor tagged a message from an individual who used an ostrich-related image (possibly popular on the net). If my understanding is correct, LM refers to any single attachment in a message that is razored and if the whole message is razored due to it. I could not find documentation for 'razor' regarding this, but by default all my confiles in razor use LM. I am not maintaining an official count of false positives, however, I intend to develop an HTML interface for tracking them more effectively. This would allow me to provide the false positive rate per filter. I will begin working on it tomorrow and hope to have some statistics within a week. Comparing text classifiers (such as spam filters) without tracking false positive rates is not ideal, as 'cat devnull' can get a high hit rate but without the corresponding false positive rate figure, we wouldn't know if it was a good or bad thing."
   }, {
    "body": "In my experience, there are spam messages that slip past SpamAssassin but are detected by Razor. I'm suggesting that the collective judgment of Razor users provides better spam detection than a single program like SpamAssassin, hence, I can benefit from their judgment and enjoy more comprehensive spam filtering. I have observed instances where SpamAssassin does not mark the spam as high enough to reject it, but Razor does. If you haven't noticed, SpamAssassin scores are adjustable. If you want SpamAssassin to tag all messages listed in Razor, you can modify your spamassassinuserprefs file as follows: score razorcheck. The default score is and the default threshold needed is therefore. If you wish to have any Razor-listed messages tagged by SpamAssassin, setting a score for any Razor-listed messages above this would be sufficient. If you are already using SpamAssassin, this modification would be more efficient. Otherwise, you are running all of the mail through Razor twice, once for SpamAssassin and once again afterward. If you prefer to run Razor independently, set the score razorcheck so that SpamAssassin won't perform it and avoid the double network hit. However, one of the benefits of using SpamAssassin in combination with Razor has been the history of false positive reports in the Razor database. The current score is hefty but not enough on its own to mark as spam, but for real spam, it's usually enough to push it over the threshold. This helps address the false positive problem. However, this method is not yet as widely used as Bob application's PGP signature."
   }, {
       "body": "I recommend starting with a regular user once you're comfortable with Razor and understand its functioning. Once you're ready, tackle more complex tasks such as integration with the MTA and similar tasks. Regarding the command execution, it is not specified in this email whether it should be run as root or not. Thank you for your message to the Geek Heaven: RazorUsers mailing list."
   }, {
      "body": "Using Language Model (LM) is providing an extra advantage daily, but it's incorrectly marking emails as spam where it shouldn't. For instance, an email with a Word document and the IncrediMail advertisement signature below the Word document instructions was marked as spam by the LM. Upon examining the Word document directions to the sender's cabinet, I am convinced it misidentified the body that contains no next except the IncrediMail ad signature as spam. Consequently, I have to disable LM. Additionally, Razor has been encountering other unusual emails it shouldn't be receiving with LM on. The IncrediMail ad signature you are familiar with (e.g., 'Fox IncrediMail Email has finally evolved - Click here') is the one causing this issue. Furthermore, the sfnet email is sponsored by 'Geek Heaven RazorUsers Mailing List'."
   }, {
       "body": "Dear Flavio Boniforti, \n\nTo integrate Razor into your Postfix setup, it's recommended to use Procmail for delivery. If you have already set up Postfix to use Procmail instead of the internal delivery agent, then running it from Procmail should work fine. \n\nRegarding your question about interaction with Amavis or SpamAssassin, Razor can be used independently but it's often integrated with them for better spam filtering. If you have these tools set up in your Postfix environment, you might consider integrating Razor with them. \n\nThank you for your query.\n\nBest regards,\nGeek Heaven RazorUsers Mailing List"
   }, {
      "body": "Hi Sunil, \n\nIn response to your email, here's a rephrased version:\n\nSunil William Savkar wrote: Hi, I have recently installed and configured Maildrop with my virtual users. I am considering setting up Razor as a test for its filtering capabilities within Maildrop. While there is documentation available for Procmail integration, is there similar documentation for integrating Razor with Maildrop separately?\n\nAs I understand your question, it seems that you are already using or planning to use SpamAssassin. You asked if there's still an advantage to using Razor if you are also using SpamAssassin. It is worth noting that while Razor can help filter spam, it might have false positives, and some users do not trust it solely due to this issue. However, it catches certain types of spam that SpamAssassin may miss. Therefore, you might still find it beneficial to use both together.\n\nBest regards,\nJeffrey"
   }, {
    "body": "Hi Sunil, \n\nIn response to your email, I would suggest starting with setting up Maildrop and SpamAssassin separately. Here's a basic guide for integrating Maildrop with Razor: \n\n1. Install Razor and ensure it is functional. \n2. Create a Maildrop recipe for handling Razor checks. Your recipe seems to be correct, but please note that you might need to adjust some parts depending on your Razor version and the integration with Maildrop. \n3. Once you have Maildrop and Razor set up, you can start using SpamAssassin if needed. \n\nRegarding the documentation, while there is more information available for Procmail, there are resources for setting up Maildrop with Razor as well. You may find it helpful to look into those. \n\nIf you're using SpamAssassin, integrating Razor could still provide additional filtering capabilities, especially for false positives that SpamAssassin might miss. However, do remember to whitelist all the newsletters you receive in SpamAssassin to avoid false positives. \n\nHope this helps! Let me know if you have any further questions.\n\nBest,\nJeffrey Quoting Sunil William Savkar:"
   }, {
       "body": "Upon receiving a spam email that appeared to forge the 'From' header with your own email address, you forwarded it to the database using RazorReport. Consequently, your email address is now listed in the Razor database. To get it removed, please follow these steps:

      1. Contact the RazorReport support team and inform them about this issue.
      2. Explain that this ploy of forging headers has occurred several times since then.
      3. Suggest that they update their system to detect such occurrences and emit a warning when it happens.

   Note: This issue is related to the Razorusers mailing list, which is sponsored by sfnet email."
   }, {
     "body": "Vipul Ved Prakash, Here are some suggestions for addressing the issue in Razoragents. It would be beneficial if an unwritable log file error condition could be caught by Razor and handled gracefully by logging to syslog or devnull. As it stands, if the log file is unwritable, the Razor check falls over entirely due to the constructor returning undef, unblessed reference, and die error in Perl. This change would help avoid this issue."
   }, {
      "body": "It appears that you're encountering issues with server availability approximately half the time during the past few days, when using Razor. Could there be an issue with your installation requiring adjustments, or are the servers currently experiencing downtime due to overloading? Thank you for reaching out.\n\nRegards,\nGeek Heaven Razor User Support Team"
   }, {
    "body": "I have recently installed Razor on a FreeBSD box and am encountering issues with razorcheck. The problem persists whether or not arguments are used, and I get the following error: 'Use of an undefined value as a symbol reference' at line where razoradmin runs just fine. Previously, the make test before installation was successful. Has anyone experienced this issue before? The module sfnet email is sponsored to Geek Heaven, Razorusers mailing list."
   }, {
    "body": "Hi David Gastonguay, \n I recently installed Razor on a FreeBSD box and encountered issues with razorcheck. The error occurs regardless of whether arguments are used or not. It seems the issue might be due to an undefined value being used as a symbol reference at line [line number unspecified]. To troubleshoot, please try installing the latest Perl (at least through port on FreeBSD). Additionally, ensure your system is configured to use Perl from ports, for instance by running 'useperl' and reinstalling the necessary Perl modules required by Razor. After these steps, run razorcheck again.\n\nBest regards,\n Sven\nThis email is sponsored. Welcome to Geek Heaven - Razorusers Mailing List"
   }, {
    "body": "I've noticed a decrease in checks and have conducted some tests. It appears that when I move 'Truth' to the top of my catalog list, I receive a positive check; however, if I move 'Fire' up the list, I no longer get a positive response. It seems as though it's not syncing correctly with Hubris, which is where my reports are being sent to Bobby (SFNET email). This message is being sponsored for the Geek Heaven: RazorUsers Mailing List."
   }, {
    "body": "It appears that you have set up procmailrc for a spamtrap, but you are encountering an error. Additionally, you are reporting to Pyzor and DCC, but they are not registering the error. It's unusual because it works intermittently. You also mentioned that you received a response from honorcloudmark.com stating that your email was accepted by their special case ENG server. However, there was an error reported by their ERR server regarding the SFNET email which is sponsored to Geek Heaven and RazorUsers mailing list."
   }, {
    "body": "I have recently implemented a new system using SUSE and have successfully run SPAMAssassin and Procmail. I attempted to set up Razor, but I'm having trouble installing the SDK. Razor reports missing modules, however, they seem to be present according to the installation instructions. It appears there is an endless list of errors. Do you have any suggestions on what to do or where to start? This email is sponsored by SFNet and directed to the Geek Heaven Razor Users mailing list."
   }, {
     "body": "The textplain quotedprintableerror occurs when the server is unable to recognize a signature in an email, and it requests the full content of the message. This is an optimization feature beyond that; however, I am unsure how to interpret this specific output. In your case, you've set up a Procmailrc for a spamtrap but are encountering an error. It appears that Pyzor and DCC are not registering any errors, which is unusual since the issue seems intermittent. The email works fine sometimes. It seems this is a special case with the ENG server accepting the report, but the server wants the entire mail content instead of just the report. The sfnet email you received is sponsored and welcomes you to 'geek heaven' RazorUsers Mailing List."
   }, {
    "body": "Upon closer inspection of the log, you will find debug messages from the content reporting process. These occur when an error happens on Wednesday, October at Jordan Ritter's location. The error is triggered when a signature is reported, but the server is unaware of the signature, causing it to request the full content. This seems to be an optimization issue beyond which I am uncertain how to interpret. \n\nOn the same day, Vipul encountered an issue at Rose Bobby's location with setting up procmailrc for a spamtrap. However, neither Pyzor nor DCC are registering this error, which is strange because it works occasionally. \n\nIt appears that HonorCloudMark.com responded to the original email regarding a special case involving an ENG server accepting the report but wanting the mail instead. The ENG server seems to be encountering an error, desiring the mail from Vipul and Prakash. \n\nWilliam Gibson's quote 'The future is here; it's just not evenly distributed yet' seems appropriate for the current state of software design artistry, widely distributed but not uniformly optimized or problem-free.\n\nThis email is sponsored by Geek Heaven and intended for the RazorUsers mailing list."
   }, {
    "body": "Dear Whit Blauvelt,\n\nI have been observing Razor reporting intermittently failing with various error messages.\nReinitializing Razor might help in this case, however, it's not clear if Razor handles that automatically, or if you need to do it manually.\nThis issue seems to be originating from the servers, so it could be a server-side problem.\nSince these reports are being generated within Mutt, it is quite annoying when the error messages slightly disrupt the X Window. If there's no immediate solution for the Razor failure, I was wondering if it's possible to turn off the failure messages at least.\n\nIn addition, over the past few days, I have been experiencing 'No servers available' about half the time while using Razor.\nThis issue may require adjustments in your installation or perhaps the servers are simply overloaded.\nLet me know if there is anything specific I can assist with regarding this matter.\n\nBest regards,\nThe Geek Heaven Team"
   }, {
    "body": "Attempting to report an issue with Razor, as Hubris timeout occurs on a seemingly slower connection today. The error message received is 'error reading socket' and 'i then try to run razoradmin discover and receive the same error'. Today, there appear to be problems with the servers, as only one discovery server is available. This issue has been reported through the SFNet email sponsored for the Geek Heaven RazorUsers mailing list."
    }, {
      "body": "Dear folks, this morning there have been several major internet outages affecting providers such as UUNET, Genuity, and others. Routes across the internet backbones have been vanishing, repopulating, and disappearing again, which has worsened several issues that we are currently addressing. We apologize for the inconvenience. \n\nRegarding Razor, I've been experiencing timeout issues on the connection, and it seems to have slowed down throughout the morning, resulting in the following error: 'razorreport error reading socket error reading socket'. Trying to run 'razoradmin discover' also yields the same error. It appears that only one discovery server (Sven) is operational today. \n\nThis SFNET email is sponsored and welcomes you to geek heaven - razorusers mailing list."
   }, {
     "body": "Dear All,\n\nI am writing to inform you about the current issues with Uunet's North American backbone. The problems, initially concentrated on the east coast, have now spread nationwide and are affecting Uunet's network as a whole.\n\nUunet is working with their hardware vendor to resolve this issue. However, as a result, a large number of Internap's connections to Uunet remain shutdown, and traffic is being routed over alternate providers.\n\nThis widespread outage has caused a significant amount of congestion at many peering points with Uunet and other providers due to the large volume of traffic shifts. If you are experiencing problems reaching specific sites, please send an email containing a traceroute and source-destination IP addresses for investigation.\n\nWe will attempt to move specific prefixes onto an alternate provider if that improves performance.\n\nRegards,\nAndrew\nNetwork Operations Center\nInternap Network Services"
   }, {
     "body": "This issue seems to be caused by insufficient write access to the 'razoragentlog' file. When using 'agentpm', you can temporarily solve this problem by executing 'chmod g+w razoragentlog'. This change grants write permissions to the group, allowing the logger object to create the logfile without checking its writability by the current user. However, if a write attempt is made later, it might still error out with an 'unblessed reference' due to access issues. I noticed some related log entries in your syslog after upgrading/downgrading razoragents, but the problem persists. Any ideas on why this might be happening? This email was sent through sfnet mailing list sponsored by geek heaven."
   }, {
       "body": "This email appears to be a personal correspondence between two individuals, sent as HTML if that's the case. The background of the email might have been included in a separate attachment named 'spamcmeclax'. This email is sponsored by SFNET and pertains to the RazorUsers mailing list."
   }, {
       "body": "Dear Vipul Vipul Ved Prakash,\n\nI hope this message finds you well. Regarding your inquiry about the email sent on Thursday, August [redacted] to CMECLAX POU LE CMeviu Keumri:\n\n- Yes, it was an HTML email.\n- If it had a background image, that part might have been blocked as spam by SpamRazorAgents for them to make a positive decision. However, please note that with the next release, this issue will be resolved so a background could potentially not have been a problem in this case.\n\nIn light of this information, I kindly request you to send me the debug log if possible. Looking forward to your response.\n\nBest regards,\n[Your Name]\nThis SFNet email is sponsored to Geek Heaven - RazorUsers Mailing List"
   }, {
    "body": "I have been testing Razor invoked from sendmailprocmail and so far it seems quite satisfactory. Last night's spam to the provided list served as a good test, both for the spam itself and several of the responses. Some of the messages were flagged as spam by other list members, who reported this morning. I piped the messages out from Pine, being careful to use the raw mode to Razor check d. None of the messages came back as spam even in the spam. Since folks revoked the false positives, I understand why they would not come up, but I am puzzled about the spam itself unless that was also revoked. Is this spam just a poor choice for testing against or is there some setting in Pine or Razor that I am missing? This SFNET email is sponsored to Geek Heaven RazorUsers Mailing List."
   }, {
      "body": "I have rephrased your email for clarity and formatting. Here is the revised version:\n\nDear Samuel Checker,\nI have been testing Razor from SendmailProcmail, and so far it appears to be functioning well. Last night's spam to the list provided an excellent test, both for the spam itself and several of the responses. Several members reported this morning that some messages were flagged as spam. I piped the messages out from Pine, being careful to use the raw mode to RazorCheck d none of the messages came back as spam, even the spam. I understand why the false positives would not come up, but I'm curious about the spam itself, unless it was also revoked. Is this spam just a bad one to test against or is there some setting in Pine or Razor that I may be missing? Are you using SpamAssassin on the input side?\nI recently changed my Sendmail installation and am looking for the proper way to pass it through the system before accepting and sending it to users. It's challenging to set up Procmail scripts for every user when their home directories are NFS mounted, and the source is on my own machine where I try new things and it's the only machine with sufficient drive space. Brian Fahrlnder - Linux Zealot, Conservative and Technomad Evansville - my ICQ ID has been an endless snake as of late since it's quite a long journey, but I think I've got it figured out now.\nWelcome to Geek Heaven - RazorUsers Mailing List"
   }, {
    "body": "I have been testing Razor, invoked from sendmail/procmail, and it appears to be working well. Last night's spam test to the list provided a good test of both the spam itself and several of the responses. As some list members reported, certain messages were flagged as spam. Are you using SpamAssassin on the input side? I recently changed my sendmail installation and am looking for the proper way to pass it through the system before accepting and sending it to users. It's somewhat problematic to set up procmail scripts for every user when the users' home directories are NFS mounted, and the source is on my own machine where I test new things. I have not used SpamAssassin, but I am only using Procmail to add an xheader and optionally modify the subject if Razorcheck comes back positive. This SFNET email is sponsored; welcome to Geek Heaven - Razorusers Mailing List."
   }, {
    "body": "I have been investigating a phone call our CIO at the ISP received from an individual claiming to represent Cloudmark. The essence of the conversation was that, since we are using Razor and checking our mail against the Razor servers, which contain information proprietary to Cloudmark, we will soon be required to pay for Cloudmark's SpamNet service on a yearly basis. I am seeking clarification as I am curious if anyone else has received such a call. My concern is whether this might be an attempt by a spammer to contact Razor users with the aim of getting them to stop using Razor, or if the open source aspect of the Razor project is shifting towards a more commercial approach like Brightmail and others."
   }, {
      "body": "Hello,\n\nI was inspired by a mode of operation supported by VMware, where a base disk image can be shared among multiple virtual machine (VM) instances. This base image is never altered by a VM instance; instead, each VM instance writes changes to its own redo log. Future hard disk reads from that VM instance incorporate both the base image and the appropriate redo log to present the current disk image for that specific virtual machine.\n\nThis concept could potentially be used to create self-healing client-server applications that efficiently and automatically recover from most attacks even before those attacks are discovered. Here's what I envision:\n\nThe physical architectures of most production client-server systems are layered, for example, a basic web application might have a web server running Apache connected to an application server running some or net business logic connected to a database server for persistence. The only one whose disk image really should evolve over time is the database server, and even here, you often put the static RDBMS software on one partition and the changeable datafiles on another partition. It is only the partition with the volatile datafiles that must be allowed to change from one boot to the next; other partitions may need to be writable for say swap space, but these changes could be eliminated on each reboot.\n\nWhen someone cracks this system, they will probably change an image that shouldn't be changed, such as leveraging a buffer overflow in IIS or Apache to install a trojan or a backdoor on the more exposed web server. What if the web server ran off a base image writing changes to a delta or redo partition and then what if every night it automatically erased the redo partition and rebooted? The downtime involved for each machine would be minimal because it is only deleting data rather than restoring from backup. In a system with redundant web servers for load balancing or high availability, this could be scheduled in a way such that the system is always accessible.\n\nThis base redo partition concept could be implemented at the same level as a feature of hardware RAID, allowing for greater performance, reliability, and hack resistance. This concept could also be applied to application servers and even database server partitions, except for those partitions which contain the table data files.\n\nDoes anyone do this already or is this a new concept? Has this concept been discussed before and abandoned for some reasons that I don't yet know?\n\nThanks for any opinions."
   }, {
     "body": "Your email made me ponder about the level of security provided by smart cards, as they contain an internal processing unit. Could we consider them as trusted hardware? The idea that we could ship smart cards periodically upon payment of a monthly subscription fee seems feasible and may not significantly increase the cost of renting the system. These smart cards have the ability to encrypt data themselves and can be used to decrypt information required by the system. Additionally, they can keep a record of their duration in service. However, I must mention that my assumptions might be incorrect, and there could be potential safety issues associated with using smart cards. Similar to using hardware locks (either the old parallel or new USB), the problem lies in the trustworthiness of the hardware itself, but the rest of the system may not be secure. A hacker could potentially simulate the smart card lock or peek at the executable after the lock has been deactivated. What are your thoughts on this matter? Best regards, Luciano Rocha"
   }, {
      "body": "I have come across a concept similar to the one you described, which was inspired by VMware's shared base disk image model. This model allows multiple virtual machine instances to share a base image, with each instance writing changes to its own redo log. The current disk image for a specific virtual machine is a combination of the base image and the appropriate redo log. This concept could potentially be used to create self-healing client-server applications that efficiently and automatically recover from most attacks even before they are discovered.\n\nIn a typical production client-server system, the disk images should evolve over time only for certain components, such as the database server. By allowing only the partition with volatile data files to change from one boot to the next, the risk of unauthorized changes can be minimized. This concept could potentially be implemented at the hardware RAID level for improved performance, reliability, and security.\n\nI am not aware if anyone currently does this or if it is a new concept. I will appreciate any insights on this idea."
   }, {
      "body": "Scott Mackenzie is a software package that was utilized, or still is, on Microsoft platforms for this purpose. The software essentially takes a snapshot of the machine's configuration and replaces it with the correct version either on a schedule or demand. This process overwrites the entire disk drive, making it particularly useful for student access machines in libraries or similar environments. In some environments with public workstations, it's common practice to wipe and reinstall Windows machines on a weekly or even daily basis instead of maintaining them. On the other hand, Crispin Crispin Cowan Ph.D. is the Chief Scientist at Wirex, where a security-hardened Linux solution is available."
   }, {
       "body": "The sole means of ensuring a secure key is by utilizing all available storage space across the universe, a capacity too immense to decrypt. My argument is that there will never be an utterly safe key. Instead, consider the duration for which the data requires protection. If your goal is to protect the data beyond several months, it should not be disclosed to the public. If you aim to prevent your customer base from copying the data, make use of existing solutions on the market. If you wish to deter piracy, refrain from releasing the data to the public. I have yet to encounter a lock that cannot be unlocked; in unlocking the key, its secret is revealed. The more complex the lock, the more dissatisfied your customers will become, as exemplified by Microsoft's xp and subsequent mac sales. With the increasing popularity of software, there is a higher likelihood that it will be cracked."
   }, {
     "body": "To make 'usr' a separate partition and mount it, attackers who wish to trojan your software will have to reboot at least once, while bad administrators who want to update your software do not require a reboot. However, no reboot is necessary as you only need to remount or unmount the 'usr'. This action requires root access, but even so, usr should be safe from non-root users. The only way to disable this process is either to compile the kernel with features that compartmentalize capabilities (like LIDS on Linux) or to remove capsysadmin with lcap, which would indeed require a reboot and may potentially disrupt other functionalities during boot."
   }, {
      "body": "There is a software package, previously used on Microsoft's Ghost or similar, that takes a picture of a machine's proper configuration and replaces it upon schedule or demand. This is particularly useful for student access machines in libraries, as it overwrites the entire disk drive. I came across this during my webappsec security work with SecurityFocus under the SecProg group. My dissertation focused on optimistic computing, which led me to consider applying it to this security problem. However, a challenge arises when determining a state as 'good', as committing too early can lead to corrupted states and committing too conservatively affects performance and storage. If corruption is discovered mid-redo log, a method is needed to remove the corruption while saving the rest. My dissertation solves this problem, but it requires rewriting everything in C, which imposes significant performance penalties. I am a fan of VMware and use it daily, but it isn't very fast. To address the first two problems, I suggest being less ambitious; instead of committing, simply revert to base state on reboot. This would allow for quick and easy frustration of certain attacks without requiring extensive software changes or additional applications-specific coding. The first two problems only become relevant when we become more ambitious and try to apply these techniques to partitions where state changes remain important across reboots. The third problem, performance penalty, could be mitigated by implementing this in hardware, similar to hardware RAID. This would also increase hack resistance, as modifying the base instance would require physical access."
   }, {
       "body": "Regarding your query, I recommend the following for protecting an online requirement system:

1. Regularly update and patch the system to ensure it is secure against known vulnerabilities.
2. Implement strong authentication and access controls to restrict who can access the system.
3. Use encryption for data at rest and in transit.
4. Conduct regular security audits and penetration testing.
5. Keep backups of critical data and have a disaster recovery plan in place.
6. Monitor system logs for suspicious activity and set up intrusion detection systems.
7. Follow best practices for secure coding, such as using parameterized queries to prevent SQL injection attacks."
   }, {
      "body": "Dear Ben Mord,\n\nI appreciate your interest in discussing web app security and the use of base/delta images for automated recovery from attacks. Your research on optimistic computing, particularly in relation to state recovery from intrusions, is fascinating.\n\nUnfortunately, as you've pointed out, finding a balance between committing states too eagerly or too conservatively poses a challenge. When committing too eagerly, one risks committing corrupted states, while committing too conservatively leads to performance and storage penalties.\n\nIn case of corruption in the middle of your redo log, it's necessary to remove the corruption and save the rest. Your dissertation seems to offer a solution to this problem, although it requires significant rewriting in your programming language, which imposes substantial performance penalties.\n\nI share your admiration for VMware and its daily use in my work. However, I understand that it's not very fast for your proposed solution.\n\nIn light of this, I suggest a less ambitious approach: instead of committing states, you could simply revert to the base state on reboot. This would require a machine configured to boot from CD-ROM and use a RAM disk for scratch space. Linux distros that allow booting a stateless but functional system from CD-ROM are available.\n\nIf some state needs to persist, a mountable writable partition could be used to protect it. Access control management would be necessary to decide who can make changes to the writable partition.\n\nI hope this simplified approach addresses the challenges you've mentioned. It's important to remember that even with this setup, conventional server-like security concerns still apply, such as keeping user data separate for protection.\n\nBest regards,\nCrispin Cowan PhD, Chief Scientist, Wirex Security"
   }, {
      "body": "Dear Ben Mord, \n\nRegarding our discussion on webappsec security on SecurityFocus.com SecProg, I'd like to propose a solution for the issues you mentioned concerning the use of base and delta images for automated recovery from attacks.\n\nMy proposed solution is to be less ambitious by not committing changes but rather reverting to the base state on reboot. This can be achieved using a machine configured to boot from CD-ROM and utilize a RAM disk for scratch space. There are several Linux distros available that allow you to boot a stateless, yet functional system from CD-ROM.\n\nHowever, RAM is expensive and the directory structures of many systems, especially Windows, are not sufficiently organized and standardized to make this combination of bootable CDs and RAM drives practical. Even if you're fortunate enough to be using Linux or another FHS-compliant system, you still can't fit a lot on a CD. It's not unusual today to have gigabytes of static multimedia content on the web server. This particular problem can be alleviated somewhat by using DVDs, but this is a temporary solution at best and will become outdated quickly as our data requirements grow and hard drives become cheaper.\n\nObviously, you can't do this with partitions that accrue important state, such as a partition that stores database table data. However, if you do want some state to persist, you need a mountable writable partition to protect it. You also need some kind of access control management to decide who can do what to the writable partition.\n\nThis is why you would consolidate all state of any long-term significance on just a couple partitions and why you would not put static application code on these changeable partitions. Fortunately, most large client-server application physical architectures do this anyway because these are two fundamentally different kinds of state with two very different sets of administrative security, RAID, and backup requirements.\n\nI use the word 'static' versus 'changeable' instead of 'writeable' versus 'unwritable' because the unchangeable partitions might be written to for temporary swap space who knows what Windows does internally. My point is that there should be a market out there for a hardware RAID device that can split designated partitions into a permanent base image partition and a temporary delta image partition that has some simple but solid security measures to prevent the unauthorized remote modification of base images and that can be configured to clear the delta image when the server is rebooted.\n\nIf any vendor were to implement this, they could market it as a mechanism to help frustrate broad classes of attacks that rely on the permanent modification of system or application files via buffer overflows, platform and middleware bugs, etc. The prevention of unauthorized modification of application data, of course, would not be addressed by this particular product, but there are many other techniques out there to defend application data.\n\nI believe these features would be relatively easy for a hardware RAID vendor to implement. If anyone knows of such a product, I'd love to hear about it.\n\nBest regards,"
   }, {
      "body": "Hi Yannick Gingras, \n\nI wanted to express my gratitude to everyone who provided insightful information. Currently, I'm experimenting with a database disassembler but I'm not sure it's what a typical cracker would use. I'm seeking some hints on Unix cracking tools. Besides objdump program and Biew hex viewer/disassembler, do you have any other good starting points for searching? \n\nIt seems that cracking and reverse engineering tools are less common on Unix platforms compared to Windows. This is primarily because the main customers of commercial Unices like Solaris, HP-UX, AIX, SCO are respectable companies who are willing to pay big bucks for software. They prioritize reputation over free or open-source software. However, software for Linux and BSD can also be used on commercial Unices, although it's often open-source as well.\n\nBest regards,\nArtem Frolov, Software Engineer and System Administrator, Institute for System Programming, Russian Academy of Sciences"
   }, {
     "body": "In that case, you can opt for a less potent solution than VMware. All you require is a machine configured to boot from CD-ROM and utilize a RAM disk for temporary space. Several Linux distributions permit booting a stateless yet functional system from CD-ROM. However, RAM is costly, and the directory structures of many systems, like Windows, are not sufficiently organized and standardized to make the combination of bootable CDs and RAM drives practical. Even if you're fortunate enough to be using Linux or another FHS-compliant Unix, you still can't fit a lot on a CD. It's common today to have gigabytes of static multimedia content on a web server. This particular issue can be partially addressed by using DVDs, but this is a short-term solution at best, which will become obsolete quickly as our data requirements grow and hard drives become cheaper. Instead, consider write-protecting the hard disk for partitions that are static. I believe there was an article on this topic in early Byte Magazine, perhaps for BBS systems or for testing unknown software, including potential Trojan horses. As George George Dinwiddie once said, 'The gods do not deduct from man's allotted span those hours spent in sailing.'"
   }, {
       "body": "Dear Allan Jensen, \n\nIt appears that you have a customer who is developing printer driver code to save custom driver settings (such as booklet mode, duplex) on the server for retrieval by other users. The data is being written to a specific registry key HKLM\System\CurrentControlSet\Control\PrintEnvironments\Windows NT\Name\Custom Keys on the client workstations, which can then be modified and rewritten back onto the server. My understanding is as follows: \n\n- A registry key is being loaded from the server to the client workstations where users can modify it, and then write it back onto the server's own registry. The server does not use this data directly unless someone knows a method to travel out of the hive bypassing the permissions set.\n\n- The primary concern is twofold:\n\t1. The risk of a compromise to the server through this registry key, although unlikely as the server itself does not use this data, only client PCs do.\n\t2. The risk of a compromise to the client due to a potential buffer overflow caused by a malformed or excessively long string in the key value.\n\n- Other concerns include:\n\t1. Ensuring that multiple users are not overwriting each other's keys to avoid undesirable effects.\n\t2. Preventing unauthorized users from creating excessive keys under this key, potentially filling up the registry.\n\nIf I have misunderstood anything, please clarify and let me know where I may have gone wrong. Looking forward to your response.\n\nBest regards,"
   }, {
     "body": "Bryan Feir mentioned that when one player key was broken, dealing with the rest became a known plaintext attack, similar to dominoes falling. However, the actual follow-up to the Xing player break was more intriguing. The simple knowledge of known plaintext and its corresponding input and output doesn't necessarily make it easy to break a well-designed system or algorithm. The CSS key being easily broken was primarily due to it being vulnerable to exhaustive search attacks. This was speculated because of a misunderstanding of the government cryptography export rules at the time. What followed was an increased interest in studying the CSS algorithm itself, and rapid discovery of serious design flaws that reduced its strength significantly. This underscores the need for caution when using proprietary cryptography algorithms. Yannick Gingras's comment made me wonder about the relative protection of smart cards. While they have a processing unit that can be considered trusted, they are not infallible. Smart card manufacturers are usually one step behind potential attacks. A well-designed system assumes that a smart card will be compromised at some point. The cryptography industry has developed techniques to reduce the impact of a compromise, such as unique keys per smartcard and forward security techniques. However, once the encrypted material goes outside the trusted hardware, it is impossible to provide unbreakable protection for it. There may be some mitigation steps you can take, like SDMI watermarking, but most schemes to date have been easily broken. The value of what you are trying to protect is also a consideration. While there's no such thing as unbreakable, adding more cost and hassle factor can greatly improve the protection. Since you are discussing the use of standard PC workstations, the value of the information you are trying to protect may not be high enough to justify extensive security measures."
   }, {
       "body": "On Thursday, September Michael McKay mentioned his thoughts about the relative trustworthiness of smart cards. These devices have an internal processing unit and are often considered as trusted hardware. Unlike general processors, smartcards do not have fixed clock rates, but for security purposes, they usually have built-in crypto coprocessors which make clock rate irrelevant. Smartcards can perform triple DES faster than general processors clocked at ten times the speed. However, clock rate does not determine the trustworthiness of a card as Michael pointed out. Instead, there's an ongoing 'arms race' between manufacturers and attackers, which is independent of clock rate and time. The security of smartcards is rarely absolute; it's more about assessing, quantifying, and managing risk. The trustworthiness of a smartcard depends on the application and the attacker as well as the timeframe. For instance, a smartcard may be secure enough to prevent undergrad EE students from committing mass fraud in the cafeteria, but it might not be suitable for protecting ICBM launch codes. The risk-cost ratio must justify the use of any protection measure. In either application, the smartcard is likely trustworthy or unsuitable based on the specific risks and costs involved."
   }, {
    "body": "Dear Ben, \n Greetings! I hope this email finds you well. The concept you've mentioned seems to be about partitioning application servers and potentially the database server for data protection purposes, while excluding partitions containing table data files. I'm curious if anyone is already practicing this or if it's a new concept. I've observed a similar implementation on a shell server, where they stored the root on a CD-RW in a CDR drive, allowing them to switch disks when a root exploit was found, thereby protecting other users' data. Let me know your thoughts and feel free to blaze your own trail with Red Hat. Best regards, Blaze."
   }, {
      "body": "Hello everyone,\nI'm developing a web application using Java, Tomcat, JSP, Servlets, and PostgreSQL. The application will be released under the GPL and can serve as a foundation for other web applications. While the primary focus is e-commerce, it's not limited to that.\n\nI'd like to incorporate some form of cryptography for data protection in the database, but I'm having trouble figuring out the best approach, especially when it comes to storing passwords and keys on a shared web server. One problem I haven't solved is how to store keys for encryption/decryption, as using the JCA API and saving generated keys in keystores always fails.\n\nOne idea I had was to serialize the object and store it in the database, but this doesn't seem secure since the key would be needed to decrypt data in the database, which is accessible from the web application.\n\nIf I could find a safe and secure place to store the database password, I could use a different database with separate user credentials. However, this doesn't really solve the problem.\n\nI'd appreciate any guidance or suggestions on this topic. Another approach I thought of (though it might be insecure) is using a small Java bean application that runs as a normal user, not Tomcat, so it's separate from other web services. This app could open an SSL connection and retrieve database passwords via code signature during server startup.\n\nThis would help keep keys and passwords out of shared directories, and an attacker would need root access to the bean user account to read data. However, this solution only works if your provider allows configuring a separate Java application running in the background.\n\nYour input is greatly appreciated. Thank you,\nMario Torre"
   }, {
     "body": "Dear Team, \n\nTim Peters and Greg Ward are currently working on capturing a stream coming into PythonOrg. I hope we can eventually extract a more modern and clean test set from this data. However, the required config changes are not yet complete. \n\nI have a strategy for achieving this, which involves filtering out non-suspected junk mail by checking if the number of recipients is greater than one and if the folder is 'personal' or 'none'. If you and Guido Barry et al prefer, I could modify that last condition to 'none' so the email won't be saved at all. Additionally, I might add a clause to this condition such as 'and sender does not look like a bounce request or admin'.\n\nI am seeking a large shareable ham sample apart from public mailing lists. While everyone seems eager to share their spam, it's the non-spam (ham) data that poses a challenge due to its diversity. I understand that the SpamAssassin maintainers have a scheme whereby the corpus of non-spam is distributed. Several people contribute their bodies of non-spam for collectively evolving the spam score set. If this sounds vague, it aligns with my current level of understanding.\n\nGreg 'reality is for people who can't handle science fiction'"
   }, {
      "body": "It appears that the SpamAssassin maintainers may have a system where they collectively refine the spam score set using personal collections of non-spam emails. If this understanding is accurate, I recommend reaching out to them to discuss the possibility of organizing a fair competition between our systems."
   }, {
    "body": "Dear Anthony Baxter,\n\nI hope this email doesn't trigger your spam filters. One effective method to bypass SpamAssassin is by including an 'In-Reply-To' header, which most list traffic should have. Alternatively, I can whitelist your email address, but it might take a few months until spammers get hold of the list address.\n\nUnfortunately, I cannot assist with your satellite dish payments at the moment, Greg Ward. You seem to be feeling light-headed now."
   }, {
    "body": "Tim Peters, I've given your spam and ham test sets some thought, and it would be great to incorporate them into the SpamBayes project. Having multiple people work with the same test data seems beneficial. However, my current data subtree contains over a million bytes of files, which might be too large to email all at once. I'm not sure if my ISP allows such large messages. If you could check it into the SpamBayes project instead, that would work well. SSDs are relatively inexpensive these days, Barry."
   }, {
       "body": "Please add the pickles generated by Tim's training runs into the spambayes project. This will allow others to compare how Tim's training data performs against their own corpora. Additionally, this could serve as a starting point for a self-contained distribution. To initiate, using Python list data seems as good as any other method. - Guido van Rossum"
   }, {
      "body": "Greg Ward, if you and Guido Barry et al prefer it, I can modify my previous statement to 'folder: none', so the email won't be saved at all. However, this change will apply to personal messages regardless of who they're for, unless specifically approved by both the recipient and sender. Additionally, please note that we are more liberal about traffic in PythonOrg and ZopeOrg mailing lists compared to most, but we should exercise caution with personal emails. Unlike some lists where strict copyright is asserted over collections and traffic is fiercely protected, our approach here is less restrictive. I'm not suggesting we emulate such strict measures, but for personal emails, we should be more careful."
   }, {
      "body": "I would like to discuss a different approach from testing and fine-tuning the algorithm, focusing on eventual deployment. Both individuals and postmasters should have the ability to download the spamBayes software distribution. They will need to answer a few configuration questions about their mail setup, training data, false positives, and install it as a filter. \n\nA more modest initial goal might be the production of a tool that can easily be used by individuals since we are more likely to find individuals willing to risk this than postmasters. Here are a few ideas for such a tool:\n\n1. A program that acts both as a POP client and a POP server. You configure it by telling it about your real POP servers. Then, you point your mail reader to the POP server at localhost. When it receives a connection, it connects to the remote POP servers, reads your mail, and gives you only the non-spam to train it. You would only need to send it the false negatives somehow. It can assume that anything is ham (not spam) that you don't say is spam within hours.\n\n2. A server with a custom protocol where you send a copy of a message and that answers spam or ham. Then, you have a little program that is invoked (e.g., by procmail) that talks to the server. The server exists so it doesn't have to load the pickle with the scoring database for each message. I'm not sure how big that pickle would be; maybe loading it each time is fine or maybe marshalling your idea here has potential.\n\nI'm curious about how spamBayes, Bogofilter, and SpamAssassin are packaged, as well as the Perl Bayes filter advertised on Slashdot. I also found a mention of Guido van Rossum's homepage."
   }, {
      "body": "Maybe it would be helpful if Tim could examine the GVR pickles produced by one of his training runs. This way, others can compare Tim's training data performance with their own corpora. He is also welcome to share this information."
    }, {
    "body": "Dear Guido van Rossum,\n\nI am writing to discuss an idea for training your email spam filter. If I were to only send you the false negatives (emails mistakenly classified as non-spam), your system could learn to recognize them as spam over time.\n\nCurrently, I have individuals who leave their email programs running for hours a day, constantly polling for mail. If they are away for an extended period, such as a long weekend, Friday night spam will be automatically classified as ham (non-spam) by Sunday night. It appears that Friday nights are the most popular time for this occurrence.\n\nIn order to address this issue, I propose two potential solutions:\n1. Integration of your idea into the most popular email clients as a temporary measure to reduce autoham (automatic classification of legitimate emails as spam).\n2. Adding an IMAP server with separate 'spam' and 'deletedham' folders. Most email clients can handle IMAP users, so they should be able to quickly move spam into the spam folder instead of deleting messages or by reprogramming the delete function they can quickly move ham into the ham folder.\n\nIn either case, the message would then be processed and destroyed.\n\nBest regards,\nBrad Clements"
   }, {
      "body": "My current data subtree exceeds a million bytes, even if I had space to store it, my ISP might not allow me to send it as one email. Do you have a more modern connection such as a cable modem with a small upload rate cap? The reason less modern uncapped services went out of business is because of messages like this, zipped would probably compress well and could be split into sets to upload individually over an afternoon. However, I'm not sure where to upload it as SourceForge is not suitable for large datasets. Random sampling from public mailing lists via Gmane or similar, manually cleaning it, and distributing the load among multiple people might work, but this could potentially create more problems than solutions. The classifier we are training is based on Graham's scoring scheme which assumes that the hamvsspam task is easy, with a lot of commonality in the ham data. However, the problem lies in the fact that the ham tends to be tied to one person, unique rather than the spam which is more generic. I save all incoming email for ten days in gzipped mbox format before it rolls over and disappears. At any given time, I have approximately 10 million messages, most of which isn't particularly personal and would be culled before passing along anyway. Much of it is machine-generated so would be of marginal use. It's all hamnspam mixed together, so it's neither an omelette nor a Denny's Grand Slam. Unless you're volunteering to clean, tag, package, and distribute it, I'd call it irrelevant."
   }, {
     "body": "Thank you for your email, Guido van Rossum. I understand that you are suggesting a solution for training our spam filter. You propose to send only the false negatives (spam labeled as ham) and the system will assume that anything not explicitly marked as spam within hours is considered ham. Furthermore, you suggest tight integration into popular email clients and a temporary stopgap to the autoham (auto-labeling as ham).\n\nTo explain 'autoham', it refers to the automatic labeling of non-spam emails as ham. You propose an IMAP server with separate spam and ham folders, which should allow most email clients to handle this configuration easily. Messages can be quickly moved from inbox to the spam or ham folder as needed.\n\nRegarding your comment about IMAP, you believe that it does not have a bright future but for those who continue to use it, adding an IMAP server with spam and ham folders would be a good approach. Instead of deleting messages or reprogramming the delete function, users can move ham emails into the ham folder quickly."
   }, {
   "body": "Anthony Baxter, I've got a test set here that is from the past few years and includes an assortment of emails. Currently, it's a messy collection of spam, ham (non-spam), and unclassified messages. These addresses are scattered across various ekiteknoisiconnect websites, making them susceptible to a lot of spam, along with the usual type. The set also includes customers complaining about credit card charges, people interested in the service asking questions about long distance rates, and a lot of commercial speech. In other words, it's the kind of corpus that SA gets wrong quite badly. Can this corpus be shared? I suppose not, as I'm currently mangling it by feeding all parts (text, HTML, etc.) into the filters, also considering both selected number of headers (to, from, content-type, xmailer), and a list of header countofheader. This seems to be bringing up some interesting findings, such as the xuidl that stupid spammers blindly copy into their messages. If we ever have a shared corpus, an easy refactoring of TimeTest should allow us to plug in different tokenizers. I've only made three changes to Graham's algorithm so far; however, only three of them survived testing as proven winners. All the rest has been refining the tokenization to provide better clues. I did have a version in there, but it's currently out for the moment as it causes rates to drop (ambiguous whether this refers to accuracy rates or error rates, ham or spam rates). I'm also stripping out HTML tags except for href and src. There's so much goodness in them, note that I'm only keeping the contents of the attributes. Mining embedded thingies cut the false negative rate in half in my tests, not keying off href just scanning for anything that looked like one. That was the single biggest fn improvement I've seen. It didn't change the false positive rate, so I'm unsure whether src added additional power or if you did both at once."
   }, {
       "body": "Dear Guido,\n\nI hope this message finds you well. I'd like to clarify some points regarding the usage of ESR's Bogofilter packaged SpamAssassin, which you mentioned in your previous email. \n\nSpamAssassin is indeed a popular tool for filtering spam, and it can be effortlessly incorporated into a Procmail environment. Many users employ it in various ways due to its performance benefits. A common practice among them involves running a 'spamd' process and then invoking a small program called 'spamc'. This program sends the message over to 'spamd' for processing, with the results being returned back.\n\nHowever, I believe that in incremental mode, SpamBayes is fast enough not to require such tricks. While I'm unsure about the other tools you mentioned, I do suggest considering a change from pickle to an anydbm file for performance reasons. \n\nRegarding Procmail usage, it typically works as follows: spamassassin p yes spam, which simply tells SpamAssassin to process the message and reinject its output into the processing stream. If the resulting mail has a header 'yes', it is tossed into the folder indicated by the variables.\n\nSpamAssassin also adds other headers that provide details about how its tests fared. I'm looking forward to seeing Spambayes operate in a similar manner - doing its thing, returning a message to stdout with a modified set of headers that further processing downstream can key on, without the need for 'skip'.\n\nBest,\n[Your Name]"
   }, {
      "body": "Regarding your email, you suggested a system that automatically marks an email as 'ham' (non-spam) after a given timeout. However, there is concern about the number of potentially accepted spams becoming unacceptable before the false negative rate becomes unacceptable. You also proposed adding an IMAP server with separate 'spam' and 'ham' folders for easier handling by email clients. Despite some reservations about IMAP's future, this seems like a good approach for users who prefer it. Instead of deleting messages or reprogramming the delete function, users could move ham into the ham folder more quickly. You also mentioned that you view IMAP as a temporary solution until tighter integration with various email clients is achieved. You expressed a preference for requiring classification feedback from the recipient rather than making assumptions after a certain period of time, acknowledging it's an end-user issue and still at the algorithm stage."
   }, {
      "body": "The system you're referring to is an auto-ham classifier that automatically labels something as ham after a specified timeout, regardless of its duration. To minimize the impact of forgetting to mark non-spam messages as spam (ham), we suggest a refinement where only a small percentage of newly received ham emails are selected for new training purposes. This can be achieved by randomly selecting a sufficient number of saved, non-spam messages and asking the user to validate this selection. This process could be set up on a daily or weekly basis. \n\nTwo configuration parameters are proposed: the maximum number of spams and hams that can be accepted before the false negative rate becomes unacceptable; and the method of IMAP being used as a temporary solution until tighter integration with various email clients is achieved. Although it's better to require classification feedback from the recipient rather than make assumptions after some time elapses, this is primarily an end-user issue since at present, there's no contribution that can be made to the algorithm in terms of deployment. I am attempting to consider end-user issues because I have little to contribute to the algorithm at this stage."
   }, {
       "body": "The email describes a method of incorporating SpamAssassin into a Procmail environment, and also mentions using spamd process along with spamc, an incremental mode of spambayes, and various headers that SpamAssassin adds. The sender expresses a desire to see spambayes operate similarly but return a message to stdout with the modified headers. The sender also asks if you feel capable of writing such a tool."
   }, {
    "body": "I would like to achieve seamless integration with the most widely-used email clients. The 'kitchen sink' refers to a tool that is highly programmable. To clarify, an email package such as Emacs or Vim offers customizable key bindings and allows writing small amounts of Elisp (for Emacs) or PyMacs (for Vim), which can direct messages appropriately – either spam or ham. For this purpose, Spambayes would need to function incrementally when given a single ham or spam message. I'm not familiar with the term 'autoham', it might be a misinterpretation of 'auto-hammer' (a machine used for hammering). I'm looking for a solution that allows me to train the system gradually, similar to how you might gently introduce a dog to a new toy or treat – YRS (Yield, Skip) is an option. However, there's no need to worry about an actual pig being run over by a car."
   }, {
   "body": "Regarding spamassassin, it appears to be quite straightforward and also provides additional headers for more detailed information. I was wondering if you might consider writing a similar tool, as it doesn't seem overly challenging. However, I need to step away from reading emails for a while and attend to some real work. I'll check if I can adapt gbayespy appropriately over the weekend."
   }, {
      "body": "Dear Guido van Rossum, I respectfully disagree with your view on IMAP's future. However, for those who continue to use it, writing an IMAP server is undeniably a challenging task given the extensive specification and the diverse behaviors of clients. In comparison, POP seems relatively straightforward. As a potential solution, we could consider forwarding messages to a designated address or saving them in a specific folder to mark them as false negatives. Another approach could be developing a separate protocol and client for daily review of additions to the training set. A few random spam and ham messages could be selected as candidates each day. Someone would periodically start the client, review the candidates, reclassify or remove any unwanted messages, and add them to the training set. Sincerely."
   }, {
   "body": "Neil Schemenauer is considering developing an IMAP server or a separate protocol and client for reviewing additions to a training set each day. This approach involves grabbing random spam and ham messages as candidates, allowing someone to periodically start the client, review the candidates, reclassify or remove any unwanted messages, and add them to the training set. The idea is that people will be more motivated to report spam than ham. Neil believes copies of messages should be sequestered for some time before they are assumed to be ham, making the system dynamic and requiring little effort. Additionally, Neil proposes a Pop Proxy which classifies messages as they are pulled from the server. The Pop Proxy could notify of spam by saving it in a special folder or file which the proxy would periodically consult."
   }, {
     "body": "Dear Team, \n\nOn Friday, I'd like to consider the deployment of ASPAMbayes software distribution. The goal is to create a tool that can be easily used by individuals, as it's more likely we'll find people willing to try this than postmasters. \n\nIndividuals should collect their own corpus and answer a few configuration questions about their mail setup, training, false positives, and install it as a filter.\n\nInitially, a less ambitious goal could be the production of a tool that individuals can use without requiring extensive setup time.\n\nA potential challenge is that a pre-collected corpus may not fit most individuals well. However, each individual or group should collect their own corpus.\n\nOne concern that arises is individual laziness. If I currently have to delete spam messages once a day, I'd be happy to mark them as spam instead. However, if I also have to press a 'ham' button for each non-spam message, it doesn't seem like a win to me, especially considering the time needed for installation and setup.\n\nThe suggestions so far have been to hook something onto the delete action that adds a message to the ham corpus. However, I see two problems with this: first, the 'ham' corpus may be skewed as messages I keep around without deleting won't be counted. Secondly, if by force of habit I press the delete key instead of the spam key, I could end up with spam in the ham corpus.\n\nI would like to explore a way to deal with spam in the ham corpus. The obvious solution is to trigger on the spam button and at that time look for messages similar to the deleted one in the ham corpus and simply remove them.\n\nTo do this, we need a way to compare two word count histograms to see how similar they are. Do you have any ideas or suggestions for this?\n\nAdditionally, I personally prefer not to see the spam at all. Ideally, it should be bounced already in the SMTP stage. False positives then become the sender's problem to rewrite to remove the spam smell.\n\nIn a well-tuned system, the spam corpus will be much smaller than the ham corpus, so it would be possible to be slightly overaggressive when clearing potential spam from the ham corpus. This should make it easier to keep it clean. Having a good way to remove spam from the ham corpus is crucial as there's less need to worry about it getting there by mistake.\n\nLastly, it might be useful to have a way to remove messages from the spam corpus in case of user mistakes (oops).\n\nBest regards,\nPaul"
   }, {
     "body": "It seems that multi-level filtering is primarily a backup for individuals who do not have an intense, all-consuming loathing of spam and do not have the administrative access or the technical know-how to modify their mail servers, including installing an MTA with every possible adjustment to block spam. However, for most people, changing their company's or ISP's server can take years of negotiations while they have immediate control over their own mail system. I agree that we should provide a suitable solution for postmasters and I am confident that your ideas are well-aligned."
   }, {
      "body": "It appears one step towards deployment involves creating a reusable tokenizer for mail messages. The current codebase lacks an easy-to-use or customizable tokenizer. It seems the test module contains a wealth of practical knowledge about how to parse mail messages, but it wasn't designed for reuse. I would like to see a module that can take a single message or a collection of messages and tokenize each one. Additionally, I would like this tokenizer to be customizable. Tim had to exclude some headers from his test data due to specific biases in the data. If other people have test data without those biases, they should be able to customize the tokenizer to include them or exclude others. Jeremy"
   }, {
      "body": "Barry A Warsaw explains that there are certain headers (e.g., 'received') in the messages, which may appear due to artifacts from list management software like Mailman or as byproducts of gating a message off an NNTP feed. He suggests ignoring these headers for now and any other similar ones as they are not MM artifacts but byproducts. He also mentions that RFC-recommended generic listserve headers injected by Mailman should be ignored. The first line in the code counts messages with instances of a 'Received' header, while the second line counts messages with instances regardless of case. Warsaw implies that indirect mail paths may result in seeing more of these headers. He suggests considering if case is significant for further investigation, as unusual case could potentially be generated by specific spam mailing packages or misconfigured senders. He advises getting better test data instead of trying to outthink the flaws in the current data."
   }, {
     "body": "Dear Anthony Baxter, Regarding the task on my to-do list for tonight's tram ride home, I plan to incorporate code that will extract all headers from non-text parts of multipart messages. This should significantly reduce false negatives in identifying virus emails quickly. The modifications I made last night to timtestpy include adding this code: if x is not yield xlower (x msggettype, x msggetparamtype, x in if x is not yield xlower (x msggetcontentdisposition, x msggetfilename), for x in for y in yield y x if x is not yield xlower for t for x in for w in yield t w t). I'm uncertain if most of these changes made a difference, but I combined them all into one blob since I'm unsure which parts were effective. I'll follow up once I have more information."
   }, {
      "body": "The long text of a Nigerian scam letter that was mistakenly labeled as legitimate email seems to be one of the two instances that triggered this false positive. It's interesting to note that the system discriminates words differently if they start a line with certain characters, such as 'or', to catch styles like the one used above. The first occurrence of 'or' on a line is often used to eliminate HTML. However, it may not be worth attempting to correct this Nigerian scam quote."
   }, {
      "body": "Dear [Recipient],\n\nGuido van Rossum's basic Procmail usage seems to be similar to a tool like SpamAssassin, where 'spam' is marked for further action. I am curious if you feel capable of writing such a tool as it does not appear to be overly complex. Your 'spamcan' package seems to have performed a similar function before your knowledge about Tim's work. You can download it from [link], but you mentioned that you will no longer work on it. Instead, you are currently developing a new one based on classifier and Timtests bootykicking tokenizer. You anticipate having something soon, possibly within half an hour. It doesn't seem too difficult, but the challenging part is finding a suitable place to store the data. You prefer something that can be easily dropped in with a default Python install, so anydbm seems like your best option. Your current setup uses Xavier Leroy's spamoracle, which performs the same function and can be called from Procmail, adding a new header for easy filtering. \n\nHere is how I envision this working: Everyone receives four new 'traineggs' and 'trainedspam'. You copy all your spam and eggs into the 'train boxes' as you receive them. The frequency of doing this would depend on you, but more frequent updates would yield better results. Anything misclassified should also be copied over. Every night, the 'spam fairy' reads through your folders to learn about what sorts of things you consider spam and what sorts of things are eggs. This system could work for anyone using IMAP on a Unix box or those who read their mail directly from the server. Some colleagues at work have suggested that exchange might also support this functionality. Advanced users could stay ahead by reprogramming their mail client to bind the key 's' to move to 'trainspam' and 'h' to move to 'traineggs'. Eventually, if enough people use this system, it may start showing up in mail clients as the 'delete as spam' button that Paul Graham mentioned. The Hormel Company might not appreciate the use of the word 'ham' as the opposite of 'spam', but they have been tolerant so far regarding the use of their product name for other purposes. I propose we call non-spam something more innocuous and more Monty Pythonic such as 'eggs'.\n\nBest regards,\n[Your Name]"
   }, {
     "body": "Dear Jeremy Hylton, a potential step towards deployment involves creating a customizable tokenizer for email messages. Currently, our codebase lacks an easily usable or customizable tokenizer. With the current implementation, tokenizing could not be easier; it takes a string argument and produces a stream of tokens. The existing tokenize functions in gbayespy and timtestpy are interchangeable, making this process flexible. However, we have no evidence to suggest that a customizable tokenizer would be beneficial or in which ways customization could be helpful - that's a research issue yet to be explored. \n\nThe timtest module appears to contain a wealth of practical knowledge about parsing mail messages, but it was not designed for reuse. Extracting all the knowledge of tokenization as a standalone, reusable block would require substantial refactoring. \n\nReplace 'from timtoken import tokenize' at the top with any other suitable tokenizer. If you wish to make this process even easier, feel free to check in something better. I envision a module that can take a single message or a collection of messages and tokenize each one. The msg and msgstream classes in timtestpy provide a starting point for this, but their utility is limited due to the diversity of physical representations used for email messages. Defining interfaces for these classes should be done. \n\nI would also like to see the tokenizer become customizable as well. Tim had to exclude certain headers from his test data due to biases in the data. If others have test data without those biases, they should be able to customize the tokenizer to include or exclude them as needed. This seems like a complex task and there appears to be no simpler way to customize than by editing the code itself. However, a massive refactoring would help improve this."
   }, {
     "body": "I believe that when evaluating a solution, one that supports all Python platforms rather than just Linux is preferable as Mac and PC users are more likely to be using a commercial MUA. Such a solution may not offer hooking ability easily, even for Linux users; however, an MUA might be simpler to use than getting it added to their MTA's sysops. Programmers may come across as flaming liberals in this regard. \n\nRegarding the solution for Windows, I have been considering Outlook described as a client-server model: the client side fetches messages and initially, I will only implement this functionality potentially on multiple hosts. The spam is hamsterized (spamhammed) in the ethunk and accessed by the server by the MUA to obtain all the ham. Spam and ham are retained in the ethunk. A simple viewer would be used for manual oversight on the spam, with the option for ultimate rejection and training of the spam filter. The ham will go forward after being used for training on the next MUA fetch. \n\nThe spam fetching and ethunk access would sit on a timer for always online users, but I am unclear on how to support dial-up users with this scheme. Outbound mail would use a direct path from the MUA to the MTA. Ideally, all MUAs could split the host fetch/send URLs. \n\nEnd users may be more interested in N-way classification if available. The simple viewer could be enhanced to support viewing via folders. For me, the Outlook nightmare is over; I would use this as my only MUA. According to my recent readings, the best way to classify spam is by using something called a Support Vector Machine (SVM), which is more accurate than Naive Bayes."
   }, {
       "body": "I was thinking, should the focus of Spambayes not be on developing a classifier that can be integrated into various user environments by auxiliary code? This way, it could be easily dropped into whatever harness that suits the user's situation. I don't see any reason to limit the project to just the development of the classifier and leave the deployment to others. Real-world attempts at deployment will undoubtedly provide additional feedback for the classifier. Sincerely, Guido van Rossum"
   }, {
    "body": "Regarding Tim Peters' note from September, it suggests that header names are case-insensitive. However, whether ignoring case in your list may or may not help is an experiment to decide. It's plausible that the case of headers could be significant in certain scenarios, such as when a specific spam mailing package generates unusual case or a particular clueless spammer misconfigures his package. SpamAssassin has a rule for this if headers like 'Date' or 'Subject' are used, resulting in a few more points. According to the label, Greg Ward claims that 'God is omnipotent, omniscient, and omnibenevolent.' Please note that I have removed the quote marks from the body of this message."
   }, {
    "body": "Dear Greg,\n\nIt appears that you are a strong advocate for filtering junk mail at the earliest possible stage, specifically immediately after the SMTP DATA command. I share your sentiment as filtering spam at the MUA level seems unwise to me, since by the time it reaches my inbox, the spammer has already utilized my bandwidth. However, I see two potential issues with this approach:\n\n1. Everyone using the same server will contribute 'ham' to the Bayesian classification, making it less effective due to false positives.\n2. Since there must be a place to store the mail that cannot simply be deleted, putting it somewhere where it can't be reviewed by anyone seems impractical.\n\nAs for the issue of replying with instructions on how to reach you more effectively, I understand your concern as it places an extra burden on your correspondents. Instead, I would prefer that spammy messages are placed in a location where I can review them at my convenience, not a system administrator whom I might not trust with my personal email.\n\nPlease note, this is not a reflection of any issue with you personally, Greg. I prefer managing such matters at the user agent level as it is less costly in terms of bandwidth compared to my time.\n\nBest regards,\n[Your Name]"
   }, {
    "body": "The email discusses the preference for filtering spam at the User Agent level, rather than at the MTA level. The author finds it inefficient and costly to filter spam early as it may result in false positives that waste bandwidth. They also prefer not to burden their correspondents with instructions on how to reach them. A personalized corpus for Bayesian classification is suggested instead, along with the option of downloadable corpora and merge functionality. Harrips has recently joined the list, so the author apologizes if this topic has been discussed before."
   }, {
    "body": "The software you're referring to functions as both a POP client and server. You set it up by providing details about your actual POP servers, and then you direct your email reader to the POP server on localhost. When it receives a connection, it connects to the remote POP servers, retrieves your mail, and provides only non-spam messages. However, due to your lack of trust in such systems and your intolerance for false positives, you have no spam blocking mechanisms in place on any of your email accounts. Instead, the software delivers all suspected spam to a spam folder. Additionally, you express a preference for this functionality."
   }, {
    "body": "You are describing a software that functions as both a POP client and server. It requires configuration by providing it with information about your actual POP servers. Once configured, you should direct your mail reader to the localhost POP server. When it receives a connection, it connects to the remote POP servers, retrieves your mail, and only delivers non-spam messages to you. It's understood that you have no tolerance for false positives, so any suspected spam is delivered to a spam folder instead. If preferred, this software can also add a header or footer to the subject line in the style you mentioned (i.e., 'Guido van Rossum home')."
   }, {
    "body": "Hi Guido, I'm unsure about the size of that pickle. Loading it each time might be acceptable, or perhaps marshalling my tests could train on messages and a binary pickle of the database, which is approaching a million bytes. I haven't attempted to reduce its size yet, but character representations of long words containing highbit characters seem to generate many database entries, and I suspect they are largely worthless. On the other hand, adding more headers will increase the size. Let's consider this as megabytes."
   }, {
    "body": "Your email describes the process of using ESR's Bogofilter, packaged as SpamAssassin, which includes a Perl Bayes filter. This setup was discussed on Slashdot. The package is a small collection of Windows executable files, where these exes are command-line programs. One of them acts as a proxy. If you have an email server named mail.comcast.net with a username 'timmy', you can change your email reader to indicate that the server is mail.comcast.net and that the user on that server is 'timmy'. In this way, the proxy retrieves both the actual server and user names from what the mail reader provides. This setup functions as an NWAY classifier, such as iFilter, where it inserts a 'OneOfTheClassNamesYouPicked' header into your email before forwarding it to your mail reader. The user is then responsible for creating text files containing appropriate examples of each class of message and running the command-line tools to train the classifier. Eventually, the user modifies their mail reader to look for such headers and takes appropriate action. Even Outlook can handle this much. The user must generate text files with appropriate examples of each class of message and run the command-line tools to train the classifier."
   }, {
      "body": "I apologize for the oversight regarding Spam management. To clarify, spam is stored in the ethunk and can be viewed using a simple viewer for final disposition. Although you could use Pythonwin to move spam into the Junk Email folder, doing so would prevent further training on the user-classified hamspam. \n\nYou mentioned SpamBayes, a program that functions as both a POP client and server. To set it up, provide the details of your real POP servers and then direct your mail reader to the POP server at localhost. Upon receiving a connection, it will link with the remote POP servers, read your mail, and only deliver non-spam messages. For your information, I have no trust in such programs due to their potential false positives. Therefore, all suspected spam should be delivered to a Spam folder instead. I would appreciate being added to the SpamBayes mailing list."
   }, {
     "body": "It seems that Tim Peters is all Guido, I'm not sure about the size of the pickle. Loading it each time might be fine or maybe marshalling my tests train on messages and a binary pickle of the database is approaching a million bytes. My paltry training set makes a where bytes pickle using Hammiepy which I just checked in, will optionally let you write stuff out to a dbm file with the same message base. The dbm file weighs in at a hefty size and also takes longer to use when compared to a real user system. This is on a piii, and I'm not sure what its supposed to be based on proc_cpuinfo for comparison. SpamOracle currently is the gold standard in my mind at least for speed on the same data. It blazes through a real user system, its data file which appears to be marshalled hash is however compiled OCaml and it uses a much simpler tokenizing algorithm written with ocamllex, so we'll never be able to outperform it. However, this is something to keep in mind. I don't have statistics yet for scanning unknown messages, but I do have data, and the database significantly outperforms the pickle, although it scores every word. Each user is probably too large and is questionable on the other hand, my pickle compresses very well with gzip, shrinking down to a negligible size."
   }, {
           "body": "Dear Tim, \n I wanted to discuss the size of my test data. Currently, it trains on approximately a million messages and a binary pickle of the database, which is approaching a million bytes. However, this size shrinks significantly if I delete all word info records with spam probabilities exactly equal to 'unknown'. These records are not necessary when scoring an unknown word gets a made-up probability of 'unknown', as they are only needed for training purposes. \n Previously, I mentioned that a scoring-only database can be leaner. The current bloat is partly due to character size and partly due to the fact that the database is brand new and has never been cleaned via clearing junk records. Additionally, there may be some 'gremlins' causing the excess size.\n Sincerely,"
           }, {
    "body": "Tim Peters is mainly discussing about messages and a binary pickle of the database that's approaching a million bytes, which shrinks to under a million bytes when deleting all records with spamprob exactly equal to unknownspamprob. These records are not needed during scoring, as an unknown word is assigned a made-up probability of unknownspamprob for scoring purposes. However, these records are crucial for training. Previously, it was mentioned that a database used only for scoring can be leaner. The author wonders about the potential improvement if a custom pickler were to be employed. The author has examined their small dbm file and found a lot of what they call 'import anydbm hammie', etc., data, noting that the pickled version of the wordinfo object is over twice as large as the string representation. This suggests a decrease in size could be achieved by using the string representation instead of the pickle. However, something about this logic seems incorrect to the author, but they can't quite figure out why. They suggest that pickling might be good for heterogeneous data types, but all values in their big dictionary have the same type, leading to a lot of redundancy, which could explain why it compressed so well."
   }, {
    "body": "It appears that embedding your email address at the bottom of the email suggests a different approach for header tags compared to body text. Skip this practice."
    }, {
    "body": "It appears that the email suggests a different approach to tagging email addresses when they are in the ToC (Table of Contents) headers compared to the message body. However, I'm not certain if this is the case, but it implies that if email addresses were tagged in the ToC, they might be treated differently. For instance, if I were currently tagging them, the tokens could look like '[email]' whenever an email-like entity is found in the body. The question of whether email addresses should be combined into a single blob or kept as separate entities as they are now hasn't been tested."
   }, {
   "body": "Here is the binary pickle of my trained classifier after using it on my initial spam-ham corpora pair. All records with unknown spam probability have been removed. It is stored in a zip file and is approximately half a megabyte. I thought you might be interested to try it out on your data, as it could potentially improve the false negative rates across your other test sets when run against this."
   }, {
       "body": "Dear Tim Peters, The false positive rate has significantly decreased after I removed numerous unnoticed spam messages from my inbox. Both collections contain approximately 100,000 messages each. This suggests that you trained on around 100,000 messages in total. However, I can't definitively determine the number of messages you used for training as it wasn't explicitly stated. \n\nYou are now in a good position to start incorporating more TP headers into your analysis. A simple starting point could be to uncomment the headercounting lines in tokenize_tp.py. Additionally, looking for 'Anthony' might be the most valuable addition as it appears to be missing. However, I found that adding 'Anthony' didn't make any significant difference in reducing the false negative rate. \n\nI also tried a simple tokenizer for headers that tokenize words within the header and output like this: s hdr word. This method worked well, particularly with the 'received' and 'date' headers which helped the classifier discover that most of my spam is old and most of my ham is new. \n\nA slightly more complex tokenizer was also attempted, skipping 'received', 'xfrom' (which contained timestamps), and 'xvm' headers. This did moderately better in terms of false negative rate. The false positive rate over the tests performed so far is higher compared to the previous test run that used the 'timtest' header tokenizer. \n\nIt's interesting to note that the best discriminators are all ham discriminators, with no spam indicators in the list. Most of the discriminators are header fields. The presence of mail-generated headers is a strong non-spam indicator. Additionally, I receive a lot of ham from people who use xEmacs, which might be Barry, Guido, Fred and me. \n\nOne final note: it appears that many false positives are from people I've never met who ask questions about Shakespeare. They often start with phrases such as 'Dear Sir/Madam, may I please take some of your precious time to ask you to help me to find a solution to a problem...' which seems like spam."
    }, {
       "body": "Dear Neale Picket, \nI've implemented a modification to convert WordInfo into a tuple before pickling and back after unpickling. This is what WordInfoGetState and WordInfoSetState do respectively. This optimization results in saving data storage which I believe could be beneficial. I suspect that you might be storing individual WordInfo pickles, if so, most of the administrative pickle bloat is due to this. If you pickle an entire classifier instance directly, this issue doesn't arise. \nMy question is, would it be too challenging to abandon WordInfo in favor of a straightforward tuple or list? Using a tuple would also have the advantage of aligning with my dbdict class. However, if you prefer, we could make it a tuple.\nI hope that this sort of optimization won't deviate too much from the goal of this project as mentioned in READMEtxt even though it isn't explicitly stated as a priority right now. \nI find the code easy to work with due to the use of utterly vanilla Python instance objects. Many parts of the code dissect these for display and analysis purposes. Few people have tried this code yet, and there are still many unanswered questions about it (for example, Jeremy's write-up of his disappointing first-time experiences today). Therefore, I believe it's best to keep it as easy as possible to modify for now. If you're eager to save memory, feel free to write a subclass. Of course, others are welcome to vote in other directions.\nBest,\n[Your Name]"
   }, {
     "body": "Here's an interesting suggestion: let's differentiate words based on whether they start a line with 'or'. This could help in filtering out certain styles like the one used in this example. Could you please modify timtokenpy to include this feature? I would be more than happy to test it. However, it might not be worth trying to eliminate false positives from phrases like 'Nigerian scam' quotes, if there's any sanity in the world, even the original poster would appreciate his knee-jerk response being blocked. On the other hand, you know there are many messages on clpy and Usenet that do nothing but quote a previous post and add a one-line comment. In such cases, it would be beneficial to remove the quoted sections, leaving perhaps only the headers for judgment. This could potentially nudge the stats in either direction. The only way to find out for sure is for you to write some code."
   }, {
    "body": "Dear Jeremy Hylton, I understand that the total collections are messages you've trained with, and they primarily consist of spam and ham. However, it appears that these sets are smaller than usual for your training process. I suggest you retrain using an equal amount from each category (spam and ham), then test them against one another. This should be done several times with a random split each time. Using directories of individual files makes such tasks trivial, as a simple random shuffle can ease the process significantly."
   }, {
      "body": "Dear Jeremy, \n\nThe total collections are messages I trained with; however, since this isn't a lot of training data, I selected random subsets from my corpora and observed significantly improved behavior. Here is the ratespy output for each run: \n\n|FP Rate|FN Rate|\n|------|-----|\n|Hams Spams|Hams Spams|Hams Spams|Spams|Total False Positives|Total False Negatives|\n\nAnother full run with a randomly chosen but disjoint set in each subset was quite similar. The score distribution is skewed towards ham for all items, and spam for all items. It's unclear at this point whether we need more ham or spam data, but I suspect the need for better spam data. The most powerful discriminators appear to be html-related spam indicators, particularly the presence of certain HTML tags in non-multipart/alternative messages and clues like 'python click' and 'money'. However, these findings don't account for stripping the HTML tags from messages. If I strip the HTML tags out of those messages too, the rates only slightly improve. Here are the updated numbers: \n\n|Total False Positives|Total False Negatives|\n\nRegards,"
   }, {
      "body": "Please note that header names are case insensitive, and this doesn't necessarily aid in your analysis. It might be an experiment to decide if case is significant. For instance, some spam mailing packages may generate unusual case or a careless spammer might misconfigure his package. However, for my testing it made no difference. Anthony Baxter's 'just count them' scheme, which doesn't require any thought, can't be fooled. Header lines that are evenly distributed across spam and ham will prove to be worthless indicators, hence they probably do no harm. I started off doing complex things but found that simplicity often triumphs over complexity. Anthony Baxter, it's never too late to have a happy childhood."
   }, {
    "body": "It appears that your ham corpus generally lacks a header, while your spam corpus does not, but surprisingly, this email does. Interestingly, one of the strongest indicators of spam for me was the name of the mail host that delivered the spam, so the 'mail to' field seems to be a reliable indicator for our filters. Anthony Baxter, it's never too late to have a happy childhood."
    }, {
    "body": "Jeremy Hylton described a basic tokenizer he implemented for headers that splits words in the header and emits it as shdr word. This method worked well, particularly with the received and date headers which helped the classifier determine that most of his spam is old and most of his ham is new (heh). However, he encountered the same issue but from a different perspective when he first started experimenting. He had collected spam for a week or two, then mixed it up with randomly selected messages from his mailboxes. Consequently, the software instantly identified this as non-ham, which was too smart for him. Despite this, he noted that it's important to mention in the software documentation when collecting spam and ham, ensure you attempt to collect from the same source (Anthony Baxter). He added, it's never too late to have a happy childhood."
   }, {
   "body": "Dear Anthony Baxter, I hope this message finds you well. The subject line seems to indicate that you've received an email about a course that identifies non-spam emails and suggests that it's never too late to have a happy childhood."
   }, {
      "body": "It appears that there are two classifiers, Neale Pickettshammiepy and the original gbayespy. The readme for gbayespy indicates it hasn't been updated recently. There is a feature in gbayespy, 'u', which calculates spamness for an entire mailbox. This feature can be easily added to hammiepy. Additionally, gbayespy has a large collection of tokenizers, but the use of these seems less relevant given timtokenpy rules. Therefore, I propose to add the 'u' feature to hammiepy and then discontinue the use of gbayespy. It seems that Tim has moved all his working code into other modules. Guido van Rossum is known to have a stake in gbayespy, but it is unclear if Skip or Barry might also have a stake. "
   }, {
    "body": "I appreciate Neale's xspamdisposition header, but I was thinking we might consider a different prefix to avoid confusion with SpamAssassin, since all its headers start with that prefix. Also, adding some version information could be beneficial. Perhaps the CVS version number for the classifier module could be included in the header."
   }, {
    "body": "Skip Montanaro expressed his liking for Neale's xspamdisposition header, but suggested that perhaps we should consider a different prefix than 'xspam'. This is to prevent confusion with SpamAssassin, all of whose headers begin with the same prefix. In general, it seems fine as long as nothing is checked in that might put it into my test corpus or alternatively, whatever is chosen should be ignored by the tokenizer. Skip also mentioned that while Interlink runs SA, he also runs it with his own set of rules and scores. He does not want his spam filter to be affected by an upstream spam filter."
   }, {
    "body": "Given that, I suggest we terminate gbayespy after incorporating the 'u' feature. If anyone is against this proposal, I assume Skip or Barry might have a vested interest in gbayespy. Tim seems to have moved all the code he was working on to other modules. No argument here. (Skip)"
   }, {
    "body": "If the regularity of my laptop's disk chirps is any indication, I would say Hammie is running faster than SpamAssassin Skip."
   }, {
    "body": "It appears that you've been listed as a developer on SF, and you have the spambayes CVS module checked out using your SF username. However, you're unable to write to the repository (cvs add, unheaderpy, cvs server add) as it requires write access to the repository. It seems like you might not have the necessary permissions. You should reach out to the repository administrator to request write access."
   }, {
      "body": "It appears Tim Peters is unsure of your current approach, but suspects you're storing individual 'wordinfo' pickles. If this is the case, most of the administrative pickle bloat arises from this method and can be avoided by pickling an entire classifier instance directly. However, the goal of this project isn't primarily to create the fastest or smallest implementation. Since you're aiming for speed and size reduction, you've been storing individual 'wordinfo' pickles into an anydbm dict keyed by token. This has resulted in significantly faster message scoring, particularly in a procmail setup. The current speed (seconds) is likely sufficient for users to incorporate it into their procmailrc. If memory savings are crucial, consider writing a subclass as a solution. Regarding finding ways to casually discuss administrative pickle bloat, I'm not sure how that would work in common conversation."
   }, {
    "body": "It appears that you were unknowingly increasing administrative 'pickle' bloat by storing individual word info pickles in an anydbm dict. However, you have discovered that this method significantly speeds up and reduces the size of the implementation for scoring messages one at a time compared to using procmail. While it is not the main goal of the project to create the fastest or smallest solution, if the objective shifts towards performance optimization in the future, your findings will prove valuable. For now, since seconds might be fast enough for users to incorporate into their procmailrc files as intended, and batching messages using fetchmail seems reasonable, it would seem best to hold off on further performance tuning until the project's focus aligns more closely with speed optimization."
   }, {
    "body": "Hi Skip, I'm listed as a developer on SourceForge and have the SpamBayes CVS module checked out using my SourceForge username. However, I'm unable to write to the repository. The 'cvs add' command requires write access to the repository. It seems that about half of the developers on the Spambayes project were missing some permissions or other. I've gone through all of them and ensured that every possible permission is granted according to SourceForge. If the problem persists, I would suggest upgrading to a higher access level."
   }, {
    "body": "Approximately half of the developers on the Spambayes project seem to be lacking some permissions or settings. I've gone through each of them, ensured all necessary boxes are checked, and clicked on every available dropdown option in SF (Salesforce). At this point, you appear to have God-like access rights, so if the issue persists, I recommend upgrading to the latest version as it seems to be time for an upgrade. Additionally, I suggest adding 'unheaderpy' to CVS and granting write access to the repository for the server. I will try to checkout the project into a new directory."
   }, {
    "body": "Dear Anthony Baxter,\n\nPlease review the script 'unheaderpy', which appears to be a derivative of a recent post to either pythondev or clpy. If it wasn't for my advanced age, I would suspect you were the original source. As previously mentioned, this script removes sagenerated headers unless one is mistakenly losing one's faculties tonight.\n\nKindly commit it to our project and include a brief description in the README.txt file."
   }, {
    "body": "Regarding your suggestion for a new prefix for our classifier, I propose 'xspambayesdisposition' or 'xhammiedisposition'. These names are different from 'spamassassin', reducing the chances of confusion with SpamAssassin. The name 'xhammie' is reminiscent of your frontend 'hammie', as it was there first and is expected to dominate the 'front end roosts'."
   }, {
     "body": "I attempted to checkout into a new directory, but it didn't resolve the issue at least. I believe it's time for me to move on and try a different approach."
    }, {
    "body": "In response to your request, I have written a tool called unheaderpy which is largely inspired by something that was recently posted on pythondev or clpy. The purpose of this tool is to remove the automatically generated headers from a file named tim, unless I have become forgetful tonight. You received it from Anthony. Please check it into the project and include a brief description in its README.txt file. Once I can write to cvss, I will add that information as well."
   }, {
      "body": "It seems Guido van Rossum is considering using fetchmail to batch messages, adding seconds per message for a batch. This waiting period feels too long to him (yikes). What he might benefit from is a mechanism that can be triggered once to process an entire mailbox. If you have spare memory available, it could potentially improve performance in this case by utilizing the pickle store since it only writes to disk once. However, when all data is loaded into memory, I cannot think of any obvious ways to speed things up beyond profiling which, as you may recall, was the optimization task I mentioned I wouldn't be pursuing."
   }, {
    "body": "Perhaps you batch messages using fetchmail and find adding seconds per message for a batch to be a lengthy process. It seems like what you require is a solution that can process an entire mailbox with a single command, right? I guess that's why you were seeking my assistance. If memory allows, using the pickle store might yield better performance since it only needs to go to disk once. However, it does indeed go to disk quite a bit. I can't think of any obvious ways to speed things up post-loading into memory, as that would require profiling - which is exactly the kind of optimization I stated earlier I wouldn't be doing. By the way, someone mentioned a server mode for this, described as an SA option."
   }, {
        "body": "Dear Tim Peters and Jeremy Hylton, \n\nI'm writing to discuss the collections I've been training on. As it turns out, the size of these sets is smaller compared to the ones I've used previously for both spam and ham messages. I suggest you try training on larger datasets, specifically one each for spam and ham, and test them against each other. This should help improve the performance significantly. I've included some preliminary results below, along with information about the tokenizer that considers all headers except 'Date Received'. I've been training on hams and spams, then testing against hams and spams respectively. Here are the total false positives, total false negatives for each case.\n\nIt appears that not paying much attention to header details might be beneficial. I recommend you test this a few times with random splits each time. It won't take long until we understand why organizing messages in individual files is more convenient. For your information, 'randomshuffle' makes handling such tasks quite straightforward for me.\n\nBy the way, have you had a chance to look at mboxtestpy? I'm currently using randomshuffle with it. You don't necessarily need many files to randomly select messages from an mbox. I'll provide more results once they're ready.\n\nBest,\n[Your Name]"
   }, {
     "body": "I understand that you've been working on a classification problem where 'tp' (possibly 'true positive') is trained on a smaller dataset compared to what you're used to. It would be beneficial if you could train 'tp' using both types ('ham' and 'spam') separately for testing. This might help improve the results, especially in terms of false negatives. I also made a change in ClassifierPy last night which removed 'mincount', significantly improving the false negative rate. The stock tokenizer is unclear; it might refer to the tokenize function or 'mboxTest' with your own tokenizer applied. I've attached results using the tokenizer that processes all headers except 'date received'. It seems that the numbers remain higher compared to when only 'ham' and 'spam' were used, suggesting a mystery regarding this issue. The meaning of 'that' in 'results from the tokenizer that looks at all headers except date received' is unclear; it might mean you enabled Anthony's countthem gimmick or that you're tokenizing them yourself. If my assumption is correct, then you've overlooked a carefully tested treatment of just a few header fields while adding many others, which may not have been beneficial if your testing corpora don't allow for the addition of more headers without major improvements for bogus reasons. You mentioned skipping 'received by several accounts', which might be valuable. If 'tokenizertokenizertokenizeheaders' is skipping them too due to the reason explained above, then it may be worth considering enabling it again offline for a week or two. Neil Schemenauer reported good results from using 'ipre for header in msg.getAllReceived() : for ip in parts.ipsplit() for n in yield this' which makes sense to me; I've checked it in but left it disabled for now."
   }, {
     "body": "Dear Guido, It might be more beneficial if Tim could share one of his training-generated pickles for others to compare against their own corpora. I did this yesterday, but it seems no one has taken notice yet. Just in case, I have uploaded a new version just now as 'mcount' went away and 'unknownspamprob' is significantly reduced. Almost nothing can be pruned from the file anymore, making it larger than before. This could potentially serve as the starting point for a self-contained distribution. Training with Python list data seems just as effective as any other method here. The only way to know anything for sure is if someone tries it."
   }, {
     "body": "Here is the explanation for the test results using tokenizer (tokenize, headers, unmodified training on ham and spam, training on both ham and spam multiple times, training on both ham and spam until reaching a total of false positives and false negatives). The second test results were obtained using mb-x-test with mytokenize (this method uses all headers except for 'received' data and 'x-from'). For the record, Jeremy"
   }, {
    "body": "Dear Guido, it might be more beneficial if Tim checks the pickles produced from one of his training sessions, allowing others to compare his training data with their own. I performed this task yesterday, but it appears that no one has taken notice yet. I downloaded and briefly explored the data, but couldn't dedicate time for a systematic analysis. The model correctly identified a spam message that had been missed by the spam filter, however, it also flagged all messages in my inbox with any MIME structure or HTML components as spam, and several messages from my Zope geeks list that happened to use MIME or HTML. This suggests that I may need to retrain the model. As you mentioned, I should upload a new version since 'mincount' went away, and 'unknownspamprob' is less likely now. The file size has increased as there's almost nothing that can be pruned away. I will revisit this when I have more time. Best regards."
   }, {
    "body": "It seems that there's a suggestion to create an 'aspambayes' package which would include both the classifier and tokenizer. The intent here appears to be to reduce clutter in site packages by skipping these components in other packages. Is this a proposal you would like feedback on?"
   }, {
     "body": "Jeremy Hylton, here's the clarification regarding my previous assumptions. Thank you for the first test results using 'tokenizer_tokenize_headers' unmodified. For the second test results, please try 'mboxtest_mytokenizer_tokenize_headers'. This method uses all headers except for 'received data' and 'x-from'. However, for the latter, also call the base tokenize_headers as well."
   }, {
    "body": "Before we proceed, I'd like to gather everyone's thoughts on creating a 'spambayes' package that includes both the classifier and tokenizer. This is intended to declutter 'sitepackage' as I believe it's too early for this. If our intention is to exclude other tools from this package, we might want to adopt Barry's trick from the email package to make the package itself the top-level directory of the distribution, rather than requiring an additional directory level. This way, the 'spambayes' package can be a subdirectory of the distro, following Guido van Rossum's home style."
   }, {
    "body": "I have had a chance to explore the downloaded classifier pickle on SF, but due to lack of time I haven't been able to perform any systematic analysis. However, it correctly identified a spam message that slipped through SA's filter, which is a plus. Unfortunately, it also labeled as spam everything in my inbox with any MIME structure or HTML parts and several messages in my saved Zope geeks list that happened to be using MIME and/or HTML. \n\nIt seems strange that the classifier might dislike MIME, independently of HTML, for example the Spam_prob in this pickle is low but that's not a conclusive clue and one piece of good content will more than offset it. As for hating HTML, possibilities could be that it has something to do with its clpy heritage. These are multipartalternative messages, but the textplain part doesn't contain the same text as the texthtml part. Perhaps, it is the presence of HTML tags that the classifier despises. \n\nAnthony reported similar issues and suggested adding an optional bool argument to tokenize even if it is pure HTML. Stripping the tags might help in this case. I would like to do that and default it to true. The extreme hatred of HTML on tech lists appears excessive, so I will have to retrain it. \n\nAs you mentioned earlier, retraining it would be a different experiment. I am indeed curious to see whether Jeremy's muchworsethanmine error rates are typical or aberrant."
   }, {
     "body": "I have reviewed your email and it seems there is a problem with the spam filter you are using. It appears to be incorrectly flagging emails with MIME structure or HTML parts as spam, even if the content is not necessarily spam. This includes messages in your saved Zope geeks list that happen to use MIME or HTML. The reason for this could be due to the filter's programming, as it seems to have a bias against MIME independent of HTML. For example, an email with spam clues related to HTML will not be flagged even if there is an HTML alternative, while an email without HTML but with MIME structure will be flagged. This is strange and could potentially lead to important emails being incorrectly marked as spam. I suggest reviewing the settings of your spam filter or consulting with its developer to address this issue."
   }, {
   "body": "I examined some FPS from my Geeks traffic in more detail, and found one particularly challenging – the term 'doozie' seems to fit. This traffic includes numerous HTML clues that appear to be ignored, as it contains snippets unique to HTML. However, I made an error in my statement; these HTML clues were not cancelled out by other clues but rather seem to have overwhelmed the classifier. It appears I haven't fully grasped this part of your code yet. This particular FPS had an excessive amount of clues, and it seems the classifier ended up counting many more than clues, with no others making it into the list. I assumed it was looking for clues with specific values in between, but it found none that weren't exactly that. This set a record for the longest list of cancelling extreme clues. There were quite a few similar ones. I wonder if there's anything we can learn from analyzing these clues and the HTML as this traffic was heavily marked up HTML with ads in the sidebar, but the body text was a serious discussion about OO and soft coding with many highly technical terms as clues including Zope and Zeo. If there are any clues here, it means the scheme ran out of anything interesting to look at. Adding more header lines should help solve this issue. Are there any unmined header lines left in your corpus, or do we need to start with a different corpus to make progress? The seventh case was similar. I scanned through many more until I became bored, and most of them were either brief text with URLs followed by quoted HTML from websites. If these were textplain, the HTML tags should have been stripped. I'm still puzzled about this part. No, I apologize, these were all multipart/mixed text/plain messages consisting of brief text plus URLs and HTML copied from websites. The fact that the HTML tags aren't getting stripped remains a mystery to me. It seems Jeremy didn't use my trained classifier pickle; instead, he trained his own classifier from scratch on his own corpora. This is an entirely different kind of experiment from what you're trying. Indeed, I am the only one so far to report results from trying your pickle on their own emails. I never expected that to work well. It's a bigger mystery to me why Jeremy got relatively worse results from training his own classifier and is the only one so far to report results from this experiment. I think it could still be due to corpus size."
   }, {
            "body": "Dear Guido,\n\nI apologize for any confusion I may have caused regarding the part of your code that deals with clues. I realize now that I was incorrect in my previous statement, and it seems that I haven't fully understood this aspect yet. The current implementation appears to be counting more than just 'clues', and other items are not making it into the list as expected.\n\nFrom what I can gather, the classifier is looking for clues with probabilities between minspamprob and maxspamprob and saving them in min and max lists. It also feeds other clues into the nbest heap. If a shorter list (either min or max) cancels out the same number of items from a longer list, whatever remains is then fed back into the nbest heap, but no more than maxdiscriminators of them. No more than maxdiscriminators' worth of clues are ever entered into the final probability calculation. However, all items from both the min and max lists are kept in the list of clues.\n\nThere seems to be a significant cancellation of extreme clues occurring, which may indicate that manual review is needed in your specific case. It appears that the excess of clues in the longer maxspamprob list pushed everything else out of the nbest heap, explaining why you didn't see anything other than 'clues' before this change.\n\nI recently implemented a tokenization scheme (a:tokenization scheme that folds case and ignores punctuation and strips a trailing s from words and saves both word bigrams and word unigrams) which turned up a low-probability, very long spam with a list of 'clues'. I'm wondering if there's anything we can learn from examining the clues and the HTML. However, it seems that the assumption of conditionally independent word probabilities is not valid in this case.\n\nI've been investigating what would work best for mailing lists hosted at pythonorg, but html decorations have so far been too strong a clue to justify ignoring them in that specific context. I haven't done anything geared toward personal email or non-mailing list emails that pass through pythonorg yet.\n\nRegarding the potential for finding minable but unmined header lines in your corpus, it appears that most of them have already been removed, except for mime decorations that appear in both headers and bodies (like content-type). The only header lines the base tokenizer currently looks at are subject, from, x-mailer, and organization.\n\nI would need different data to make progress in this area, as my current corpus is polluted with mailman header decorations which I may or may not be able to clean out. Fudging the data is a mortal sin, so I haven't made any changes thus far.\n\nSincerely,\n[Your Name]"
            }, {
    "body": "Dear Team, \n\nI prefer to strip HTML tags from everything, but in my previous attempt, it had adverse effects on the error rates in my corpora. The attached test results with and without HTML tag stripping are included in the 'What about HTML' comment block. As the comment block also suggests, if another method is found to reduce false negatives (fn), the decision not to strip HTML from HTML-only messages should be revisited. Since then, we have made significant improvements on the fn rate, but the presence of HTML tags still serves as a significant clue for clpy traffic. Therefore, I am left with the same dilemma. If another way is found to slash the fn rate, the decision not to strip HTML from HTML-only messages should be revisited. \n\nIf we wish to divert our focus away from clpy traffic, I cannot predict the effect HTML stripping would have as I do not possess suitable test data to measure it on."
   }, {
    "body": "It seems there's a suggestion to create a 'spambayes' package containing only the classifier and tokenizer. This is proposed to reduce clutter in site-packages. Guido, it may be premature if you intend to leave out other tools. The classifier and tokenize were mentioned because they seemed to be the only importable modules, with the rest representing script-level code. If and when we decide to package this, using Barry's trick for making the package itself the top-level directory of the distribution instead of requiring an extra directory might be beneficial. This would allow the package to be a subdirectory of the distro. I attempted this approach last night but ended up with all python files in the package, which was not my intention."
   }, {
       "body": "The results are from timtestpy. I have three sets of spam and ham, each with approximately messages. Here's what happens when I disable the latest received header: False positive percentages were tied (Won, Won, Won), times Tied, Times Lost, Total unique FP went from XXX% to YYY%. False negative percentages were also tied (Won, Lost, Lost), Times Tied, Times Lost, Total unique FN went from AAA% to BBB%. Anthony's header counting code does not appear to be helpful. Neil"
   }, {
      "body": "Dear Neil Schemenauer, I've attached the results from timtestpy. There are three sets of spam and ham messages each containing approximately the same number of messages. If you still have the summary files, please re-run cmppy again by CVSing them up. Enabling the latest received header seems to make cmppy skip half the lines. In your case, with n sets, you should get pairs for each error rate: pairs of false negative rates and pairs of false positive rates (false positive percentages). The latest changes look promising, however, getting lines of output for each block would give a clearer picture. It appears that Anthony's header counting code does not seem to help as it assists my test data too much."
   }, {
   "body": "Neil trained a classifier using sets containing approximately equal amounts of ham and spam. A bug in the company's software caused him to miss half of his test run results, but this issue has since been resolved. The previous custom fiddling figures on reported runs only provided false positive percentages (total unique fp), false negative percentages (total unique fn), and did not include individual run fp and fn percentages. However, Jeremy had reported these figures before customizing the analysis on sets containing about ham and spam. \n\nSince then, significant improvements have been observed in both false positive (fp) and false negative (fn) rates as more header lines were incorporated into the base tokenizers. Neal added 'headeranalysis' to the base tokenizers, while Jeremy omitted the base tokenizers' header analysis completely but added 'basesubjectline' with nearly all header lines except for received data x from being case-folded. I suspect that all those starting with 'xvm' are also being case-folded. \n\nWhen I experimented with random pairs of subsets in my test data, the false positive percentages (total unique fp), false negative percentages (total unique fn) were much closer to what Neal observed, but still appeared slightly better. Another run on a disjoint random pair produced similar results. In a third run with another set of disjoint random pairs, both false positive and false negative rates behaved in the same way. I am therefore confident that the random subsets I choose from my data will not significantly impact the results. \n\nHowever, given Jeremy's much worse results compared to Neil's, I suspect that I may have overtuned the algorithm to statistical quirks in my corporate data."
   }, {
    "body": "Eliminating 'mincount' results in a stronger attachment to infrequent clues, which can be unique to the corpus. For instance, when testing Ham trained on Gryndlplyx and a follow-up quote from another Ham referencing it, this may indicate a systematic bias in our testing setup as messages come ordered in time. In our test environment, we train on a random sampling throughout the entire lifetime of a message thread, so a new Ham situated within this thread gains benefit from messages that appeared both before and after it. However, in real life, it's likely that the false positive rate would increase without this effect. This is because at any given time, some number of Ham threads will be just starting their lives, and if they're at all unusual, our trained data will know little to nothing about them."
   }, {
    "body": "The use of all caps for headers such as 'Date' or 'Subject' is indeed beneficial, as SpamAssassin has a rule for it. Including headers like these can earn a few more points in its scoring system. Interestingly, I have observed that only spam collections contain these all-caps headers, whereas they are rare in legitimate messages, with less than 1 out of every spam message having at least one of these all-cap header lines. Although these all-cap headers may not appear frequently, they can still be useful clues when dealing with false negatives (fn rates). Even though the instances may be rare, such clues can help."
    }, {
      "body": "Dear Neale Picket, \n If it's feasible for you, consider utilizing the pickle store as it only writes to disk once, which can enhance performance significantly. However, I must admit that the data writing process is quite extensive on my end at the moment, and I can't think of any obvious ways to speed things up after the data has been loaded into memory. On my system, the current setup scores approximately messages per second, starting from a memory-loaded state. This initial wait for a full test run to complete might be inconvenient, but during that time, it processes one message more than times and trains more than times. Since I am not using this for personal email, I have no immediate need for speed optimizations. Guido will surely complain about the extra second waiting for his batches to score, but as he is the boss, he complains about everything. However, heed my words, profiling and making such optimizations are not on my current agenda. While I haven't profiled yet, I suspect there aren't any significant hot spots of long words with high-bit characters, which can be costly when it occurs, but it doesn't happen frequently. As a solution for non-English languages, this approach seems ineffective as it needs to be replaced entirely."
   }, {
       "body": "Hi Guido,\n It appears there are two classifiers, Neale Picketts' Hammiepy and the original GBayespy. According to the READMEtxt, GBayespy has not been updated for some time, and it seemed that way to me when I extracted the classifier from it. I don't believe anyone has touched it since. As for any features in GBayespy that aren't covered by Hammiepy, someone else would need to answer that as I don't use either GBayes or Hammie at least not yet. The only useful feature of GBayespy that Hammiepy currently does not copy is the 'u' function, which calculates spamness for an entire mailbox. This feature can be easily incorporated into Hammiepy, and it has been done now. GBayespy also has a large collection of tokenizers, but Timtokenpy rules the roost, so I'm not sure how interesting that is. If these tokenizers are found to be useful, they can be easily rewritten from scratch if needed. The small spamham collections in GBayes are also worthless. The self-test feature in GBayespy didn't do anything except print its result; since testerpy became doctested and verifies that some basic machinery actually delivers what it's supposed to deliver, I propose to eliminate GBayespy after adding the 'u' function. Is anyone against this proposal?"
   }, {
     "body": "I was wondering if the capitalization of a subject line can be used as an indicator, specifically for either the percentage of characters that are in capital letters or percentage starting with a capital letter if number of words > 1. For example, 'XXBrad Clements BKClements'."
   }, {
     "body": "Brad Clements is simply wondering if the capitalization of subject lines can be utilized as an indicator, either by the percentage of characters that are capitalized or the percentage starting with a capital letter. If you could provide a modification to the tokenizerpy for this purpose and test it later, that would be great. Note that the tokenizer already preserves case in subject line words because it was found to be better than converting case in this specific context. However, the experiment also showed unexpected results, as preserving case everywhere didn't significantly affect either the error rate. The subject line seems to be a unique factor for this."
   }, {
       "body": "Dear Tim Peters,\n\nIf you still have the summary files, please upload them via CVS and try running cmppy again. During the process of generalizing cmppy, it seems that I made it skip over half the lines (oops!). Since I didn't have the summary files earlier, I regenerated them using a slightly different set of data.\n\nHere are the results:\n- False positive percentages: won won won tied tied tied tied\n- Times: won won times tied times lost times total\n- Unique false positives went from x to y\n\n- False negative percentages: won tied won won won tied won\n- Times: won times tied times lost times total\n- Unique false negatives went from z to y\n\nPlease note that my test set is different from yours. In this case, all the email was received by the same account and it contains emails sent to me, not to mailing lists.\nI use a different address for mailing lists. If anyone comes up with more ideas, I will be happy to test them.\n\nBest,\nNeil"
   }, {
    "body": "On my box, the current system processes approximately 1 message per second (a rough estimate, as I didn't have a clock at hand). Surprisingly, without making any changes, there appears to be a speedup in processing."
   }, {
      "body": "Dear Neil,\n\nI apologize for the oversight regarding the summary files. I have regenerated them using a slightly different set of data and here are the results.\n\nThe false positive percentages have improved as follows: won (X times), tied (Y times), lost (Z times) with total unique fp reduced from A to B.\n\nRegarding the false negative percentages, improvements were observed as follows: won (X times), tied (Y times), lost (Z times) with total unique fn reduced from C to D. However, it's important to note that while there was a significant improvement, these results may not be entirely accurate due to differences in our test sets (my set includes emails received by the same account and emails sent to me, not to mailing lists).\n\nEnabling the received headers works better for me and I noticed a substantial reduction in false negatives when I used this method. However, it's worth noting that the received headers feature is particularly powerful on one of my training sets and may not be directly related to 'BruceG'. It is also a strong spam indicator across all my training sets.\n\nJeremy reported improvements only when using 'mboxtestmytokenizertokenizeheaders' instead of 'tokenizertokenizertokenizeheaders', and suggested trying this approach. I would recommend testing both 'mboxtestmytokenizertokenizeheaders' in lieu of 'tokenizertokenizertokenizeheaders' and also in addition to it.\n\nBest regards,\n[Your Name]"
   }, {
       "body": "Regarding the packaging of the project in September, Guido van Rossum suggests we consider Barry's technique from the 'email package'. This method makes the package itself the top-level directory of the distribution, eliminating the need for an extra directory level. This is not a trick, it simply requires the 'packagedir' to be specified in the setup script. As Greg Ward humorously put it, 'a committee is a life form with six or more legs and no brain'."
   }, {
    "body": "I prefer to strip HTML tags from my data, however, I encountered issues with error rates in my corpora when I tried this last time. Interestingly, your corpora seem biased towards retaining HTML, unlike newsgroup posts which have a social taboo against it. However, many people's personal inboxes are quite abundant with HTML. Acquiring a good 'ham' corpus appears to be a bigger challenge than I initially thought. My own saved mail doesn't reflect what I receive as I save and discard selectively, more so than in the past. The presence of multipart/mixed messages, text/plain brief texts with URLs, text/html long HTML copied from websites might explain why the HTML tags weren't stripped. I would again suggest adding an optional argument to tokenize so that they get stripped as well. If this suggestion is overlooked for a third time, it would feel like a loss. However, I am willing to try this approach. Let's see how stripping the HTML affects the false positive rate on this corpus."
   }, {
       "body": "Tim, I prefer to remove HTML tags from everything except in the last attempt it still had negative effects on error rates in my corpora. Your corpora are biased in this respect, but newsgroups have a strong social taboo on posting HTML. However, many personal inboxes contain a significant amount of HTML. We agree that comments in tokenizerpy emphasize this point strongly and I've repeated it frequently here as well. The issue was dubious while I was the only one doing serious testing, making the code clumsy for me to use on the clpy task. Getting a good ham corpus may prove to be a bigger hurdle than expected. My own saved mail doesn't reflect what I receive since I save and discard selectively more so than in the past. The system picks up on everything in the tokens. Graham proposed deleting messages as ham and spam, which might work very well for motivated geeks, but Paul Svensson pointed out they probably wouldn't work nearly as well for regular people. This explains why the HTML tags didn't get removed. I would offer to add an optional argument to tokenize so that they could be removed here as well, but if it gets ignored a third time, it would feel like a loss. It sounds like a good idea to remove HTML in this case. Let's see how this improves the false positive rate on this corpus. I will soon check in this change. In the 'tokenize_body' function, if a multipartalternative section has both text/plain and text/html sections, the text/html section is ignored by default. This may not be a good idea, for example, if the sections contain different content. HTML tags are always stripped from text/plain sections by default and from text/html sections as well, but this hurts the false negative rate on my complangpython tests where HTML-only messages are almost never legitimate traffic. If the optional argument 'retain_pure_html_tags' is specified and set to true, HTML tags should be retained in text/html sections. You should do a 'cvs up' and establish a new baseline first, as I checked in a pure Win change in the wee hours that cut the false positive and false negative rates in my tests."
   }, {
     "body": "If we decide to package this, it might be beneficial to utilize Barry's method you mentioned, Greg. However, please note that it's not a trick, but rather a process involving the 'packagedir' in the setup script. This approach unfortunately has a side effect of including all .py files within the package. For executable scripts such as 'timtest' or 'hammie', could we find a way to exclude them from being packaged? I suggest skipping them from the packaging process."
   }, {
    "body": "Regarding your concern about the automatic inclusion of py files within a package, it's important to note that this behavior is intentional. However, for scripts like 'timtest' or 'hammie', which are clearly executable, you might want to exclude them from the package. One way to achieve this could be by properly classifying these scripts as 'entry_points' in your setup file instead of regular module files. This would allow users to access these scripts directly without including them in the installed package. As for your question about adding a few extra files, while they are inside a package, it is indeed essential to ensure that the addition does not compromise the overall structure and functionality of the package."
   }, {
    "body": "Regarding your concern about scripts like timtest and hammie being included in the package, I suggest creating a 'scripts' folder for such files. By doing so, they will be excluded from the package and maintained separately."
   }, {
       "body": "Since I receive emails through multiple email addresses, I often get repetitive spam messages. In an attempt to save these spam messages for later analysis, I have not always been meticulous about avoiding duplicate saves. I wrote a script earlier to help minimize duplicates by calculating a loose checksum; however, there are still some duplicates present. My question is, should I delete the duplicates before training or not? I am open to sharing the script if people find it interesting. If you're interested, I can extract it from my local modules and post it on cvssk."
   }, {
     "body": "The first test results using tokenizertokenize were unmodified, while the second test results used mboxtestmytokenizertokenize and utilizes all headers except received data and xfrom. I suggest you try the latter again, but also call the base tokenizeheaders. I apologize for not having found the time to conduct any more test runs; perhaps I can do so later today. Jeremy"
   }, {
      "body": "Dear Team, \n\nI would like to request that we exclude Skip Montanaro from our data set. I receive emails through multiple addresses and often get duplicates or multiplicates of spam messages. I have written a script in the past to minimize duplicates by calculating a loose checksum but still encounter some duplicates. \n\nI am considering deleting the duplicates before training, however, some argue that the classifier should work best when trained on a random spattering of real life data, including duplicates if they exist in real life. \n\nI believe my script could be beneficial to the team, though perhaps for another purpose. Paul Svensson may find use in approaches that identify closely related spam as some amount of spam will inevitably end up in the ham training data. Any similarity score to a piece of known spam might aid in finding and purging it.\n\nBest,\n[Your Name]"
   }, {
     "body": "Your concern about installing additional files, even if they're within a package, is understandable. For me, it doesn't appear to be an issue at this time, but I can see how it might not seem clean or organized from your perspective."
    }, {
       "body": "I developed a script to reduce duplicates by calculating a checksum and although it has helped, I still encounter some duplicates. I am unsure if I should delete the duplicates before training or not. The classifier is believed to perform better when trained on a random sample of real-life data, even if that data contains duplicates. In my case, these duplicates represent the real-life situation. A more detailed explanation follows: I originally created a slightly different version of the 'loose_checksumpy' script to identify and avoid saving the same spam multiple times for later review. The term 'loose checksum' refers to the method used to try and prevent the saving of identical spams several times. The script is relevant, but it may have a different purpose. I am planning to share this script if anyone finds it useful. Paul Svensson might be able to use these approaches to identify closely related spam, for instance, some amount of spam will end up in the ham training data in real-life use, and any similarity score to a piece of known spam may aid in finding and purging it."
   }, {
    "body": "Regarding the script, Tim Peters has suggested extracting it and checking it into CVS if people are interested in September. I believe it might be relevant for a different purpose. Paul Svensson is considering real-world applications more than others, and he may find use for methods that identify spam resembling other spam. This could be particularly useful since some amount of spam will end up in the ham training data in actual usage, and any similarity score to known spam might aid in finding and removing it.\n\nAdditionally, Paul is also considering DCC (Distributed Checksum Clearinghouse), which uses fuzzy checksums. It's likely that DCC's checksumming scheme is superior to anything we could cobble together for personal use, no offense intended. However, I have no personal experience with it.\n\nLastly, Greg Ward states that if something cannot be expressed in figures, it is not science; it is opinion."
    }, {
    "body": "Hi Greg,\n\nI've been looking into DCC (Distributed Checksum Clearinghouse). It appears that the checksumming scheme used by DCC is likely superior to something we might put together for personal use. No offense intended, I wrote my script before I was aware of DCC and now it seems like overkill for my current needs.\n\nBest,"
   }, {
       "body": "After significant modifications to the mail PythonOrg setup, I am now confident that I can instantly gather all incoming emails. The process functions similarly as before, with some changes in the absence of etceximharvest: 1) No longer checking for characters in the From header (most hits were bounces from Asian ISPs). Remaining issues should be handled by SpamAssassin. 2) Implementing Header Sender Verification to ensure a verifiable email address exists in either From, Reply-to or Sender fields. 3) If etceximharvest is present, ACLs add an xreject header instead of rejecting recipients or messages; these messages are then handled by localscanpy which saves them to the specified folder and subsequently rejects them with the error message provided in the xreject header. Localscanpy continues to check for viruses and spam (Scan for attachments resembling Windows executables, SpamAssassin), applying the following logic: Virus -> Reject | Spam -> Reject | Not Spam nor Virus -> Save. The largest folder will be accepted. Some adjustments need to be made to save messages effectively and distinguish personal emails. The delay in rejecting messages after reading headers and body could be problematic, especially for broken MTAs used by spammers that do not consider 'after data' as a permanent error but keep retrying. To mitigate this issue, I have developed an Automated Sender Blacklist (ASBL). This is a Berkeley DB file that stores sender IPs and addresses along with expiry times. When localscan rejects a message from a known sender, it adds a record to the ASBL for future reference. If a current sender has an active record in the ASBL, all recipients are immediately rejected without examining headers or body, potentially reducing server load and bandwidth. However, this may result in only one copy of each message if a spammer uses one SMTP connection per address. This could be beneficial for reducing server load but might not aid in training spam detectors."
   }, {
    "body": "In my recent tests, we've managed to decrease both false positive (FP) and false negative (FN) rates. Additionally, we've made the score distributions significantly sharper. Unfortunately, this means that the already scarce middle ground is becoming even less evident for Greg. The distribution of items remains as usual: Ham for all items, Spam for all items. This result is an aggregate of multiple runs, each involving training and prediction on clpy, ham, bruceg, spam. At present, scores for the nonexistent items like 'if aol were a car' are above the cutoff, so they are still classified as Ham. I have not removed anything from the Ham corpus since removing 'if AOL were a car' would not have affected the FP rate at all. Dropping the spam probability cutoff from its current value to a lower one would only add false positives, and dropping it further would only add more of them."
   }, {
    "body": "Tim Peters informed us that not only have we decreased both False Positive (FP) and False Negative (FN) rates in my test runs, but we've also made the score distributions significantly sharper. This is unfavorable news for Greg because the already non-existent middle ground is becoming even less present. Tim has begun downloading the SF code with no local modifications. He has observed the Ham and Spam distribution for all items. His next task is to complete the corpus, which currently consists of Ham, Spam, and some unsorted items. He's contemplating using either Hammie or SpamAssassin for the initial sort. In the past, he used various forms of grep for keywords and a GUI tool to prompt a message and let him label items as spam or ham, but this method has become too tedious. He can't make it available on a large scale at the moment, but he will look into finding some of the more interesting cases. An anecdotal observation he's made is that skip tokens tend to appear in many False Positives, mentioned by Anthony."
   }, {
     "body": "After the latest run of cvs up timtest fails with a traceback, the most recent call is in files 'homeskip/src/spambayesestimtest.py' line in 'drivensets' file, also in 'homeskip/src/spambayesestimtest.py' line in 'drive' driver file and 'homeskip/src/spambayesestimtest.py' line in 'init self' global 'hamhist' histoptionsnbuckets' options class object has no attribute 'nbuckets'. Running it as timtest from mail directory instead of src/spambayes directory causes this issue. However, if I create a symlink to src/spambayes/bayesini it works again. Shouldn't there be an 'nbuckets' attribute with a default value already set in the class?"
   }, {
    "body": "Dear Team,\n\nI am writing to inform you that my latest CVS run of timtest is failing with a traceback. The most recent call file appears to be homeskipsrcspambayestimtestpy, specifically the lines in drivensets, drive d driver, and init selfglobalhamhist histoptionsnbuckets optionsclass object have no attribute 'nbuckets'. I am running it as timtest datatimtestout from my mail directory, not from my srcspambayes directory.\n\nTo resolve the issue temporarily, I created a symlink to srcspambayesbayesini which works once again. However, I believe that there should already be an 'nbuckets' attribute with a default value.\n\nI have not used configparser before, but from what I read it silently ignores files that don't exist. In this case, if bayesini is not found, none of the options will be defined. As you want to run this from a directory other than my spambayes directory, I recommend checking in changes to make this possible.\n\nBest Regards,"
   }, {
      "body": "Dear Tim, I have not used configparser before, but from what I've read, its read method silently ignores files that don't exist if 'bayesini' is not found. Since none of the options will be defined in this case, please note this. However, since you've mentioned that 'bayesini' is now embedded in 'optionspy', searchpath issues related to it should no longer cause problems here. The recommended way to customize the tokenizer and testers is by creating your own 'bayescustomize.ini'. Be cautious about potential searchpath issues with this method instead."
   }, {
     "body": "Dear Anthony Baxter,\n\nI've finished pulling down the SF code, starting with 'it', and no local modifications were made.\n\nIn your output file, it appears that each run summarizes the number of ham/spam in the training set, prediction sets, and the error rates/run rates. However, the effect of set sizes on accuracy rates is not conclusively known yet. I've informally reported some results from controlled experiments suggesting improved accuracy by doubling the training set size, but this wasn't a fully controlled experiment as factors other than just training set size were changed between before and after.\n\nThe ham distribution for all items and spam distribution for all items also differed in this period. My current task is to complete the corpus, which currently contains ham, spam, and approximately unsorted data. I'm considering using either Hammie or SpamAssassin for the initial sort, as my manual sorting (keywords and GUI) is becoming too tedious.\n\nTagging data is indeed very tedious, and mistakes can be detrimental. I expect that Hammie will do a better job on this than manual sorting.\n\nPlease pay close attention to the false positives and ensure the spam is removed from there. I cannot make the entire dataset available, but I will look into finding some of the more interesting and 'ugly' examples for you.\n\nOne anecdotal observation I've made so far is that the skip tokens end up in a lot of false positives with probabilities favoring ham or spam. A skip token is produced instead of a word if it is more than characters long and does not contain any high-bit characters. It's possible that they helped me because raw HTML produces many of these, but if you're using the current CVS tokenizer, retain pure HTML tags by default now, so HTML decorations should disappear before body tokenization."
   }, {
      "body": "Dear Tim, \n I'm rephrasing your email for better clarity and brevity. Here it goes:\n\n In the recent training session, half of my spam and ham (non-spam) samples were used for training and scoring against the other half. However, some issues with HTML tags led to inconsistent results. I've fixed a bug that was causing 'ham' and 'spam' to be dropped, so this isn't a difference between runs. The distribution of 'ham' and 'spam' for all items remains unchanged, along with the false positive and false negative rates. Interestingly, the same false positive occurs in both the current run and the one reported earlier. It seems possible that the 'Nigerian scam' false positive found its way into the training data.\n\n Regarding your inquiry about Python training courses in the UK, Vickie Mills, a training analyst at our company, can provide more information. Standard Life Assurance Company offers these courses. For details, please visit our website: [Standard Life's Website]. We are registered in Scotland (registration number) and regulated by the Personal Investment Authority. Please note that calls may be recorded or monitored for quality assurance purposes.\n\n Lastly, regarding your email's HTML clues, it appears that Python is prevalent in them, with Anthony's trick accounts for nearly a third of these instances. This suggests that Python was found within URLs containing embedded images (gif or jpg). Two HTML clues remain, and the capitalization pattern in this email could be a potential spam indicator. Capitalization sensitivity matters as some unusual capitalization patterns are rarely seen in regular emails.\n\n Regards,"
   }, {
        "body": "I've been using Hammie on all my incoming messages and I noticed that multipartalternative messages have no content, just the MIME boundaries. For example, 'Somebody Booga multipartalternative boundary' is a multipart message in MIME format, not textplain 'Hi there', not texthtml 'Hi there'. It seems to be coming out like 'Somebody Booga multipartalternative boundary' in my system. I fixed it with the following patch to Tim's tokenizer but I am baffled as to why it works. Perhaps there's some subtle interaction between generators and lists that I can't understand or something. In any case, be advised that Hammie will eat multipartalternative messages until this patch is applied. The patch seems rather bogus though so I'm not checking it in, in the hope that there's a better fix which I couldn't discover. Here is the patch to Tim's tokenizer:

        import email
        from html.parser import HTMLParser
        stack = []
        def part_getpayload():
            while stack:
                subpart = stack.pop()
                if subpart['ctype'] == 'text/plain':
                    return subpart['content']
                elif subpart['ctype'] == 'text/html':
                    html = EmailHTMLParser(subpart['payload'])
                    text = html.get_text()
                    return text
                stack.append(subpart_stackpop())
        def part_stackpop():
            top_of_stack = stack[-1]
            if len(top_of_stack) == 0:
                raise IndexError('Stack is empty')
            last_item = stack.pop()
            return last_item['subparts']
        def part_getcontenttype():
            if stack:
                return stack[-1]['ctype']
            raise IndexError('Stack is empty')
        email_message = email.message_from_string('<YOUR EMAIL MESSAGE>')
        top_of_stack = {'payload': email_message, 'subparts': part_stack()}
        stack.append(top_of_stack)
        return part_getpayload()"
   }, {
      "body": "It appears that Neale Picket has encountered a possible complex interplay between generators and lists which he is struggling to comprehend. Given his confusion, any theory he comes up with might be quite far from reality. Just as he was about to doze off, he suddenly figured it out - the tokenizer now includes an extra ':' and everything seems fine now. He feels a bit foolish for not realizing this earlier and is blaming it on staying up past his bedtime."
   }, {
     "body": "On the subject of September, Tim Peters raises an interesting point regarding spam emails possibly having two instances of 'Return-Path' in their headers. This could be due to Bruce Gunter's Qmail collection or perhaps Anthony is correct that spammers are often unintentionally copying these headers. However, Tim questions the specific aspect of their lack of intelligence on this matter. Greg Ward humorously suggests that if you're a telepath, feel free to honk."
   }, {
     "body": "Anthony Baxter has completed training on the Hams and Spams datasets using RateSpy. The Hams and Spams sets were broken up, and there seems to be a problem with some of the other sets causing severe issues and inflating the False Negative rate across all predictions. The variance in results within each training set is considerable, suggesting possible systematic bias in the selection method. If the sets were chosen based on arrival time, it would be beneficial to randomly reshuffle them instead. If they were partitioned randomly, the unexplained variance across runs is puzzling. Hammie's performance is expected to outperform manual sorting. However, there appears to be a chicken-and-egg problem; we need data that is known to be correct for testing purposes. The current method has nonzero error rates for both kinds of messages, so using the SpamBayes code to determine whether a message is spam will not help significantly. It does aid in reducing human effort, though. Upon examination, many of the bad skip tokens seem to originate from uuencoded viruses within the Spamset. For some reason, there appear to be fewer of these in BruceGS's spam collection. Code has been added to strip uuencoded sections and replace them with uuencode summary tokens, but this did not make a significant difference on your usual test run. Only one spam message in your dataset is now incorrectly labeled as Ham by the other sets. This change shrinks the database size slightly."
   }, {
       "body": "The division of these messages into specific sets seems to be causing issues with the other sets, severely impacting the function rate for everything it's predicting. The rates across runs within a training set vary significantly (up to a factor), suggesting systematic bias in the method used to select the sets. If sets were chosen by arrival time, consider re-shuffling them randomly instead. If they were already partitioned randomly, the extreme variance across runs is perplexing. I am planning to develop a reshuffler and mix up the sets as a precaution. The files are organized in mh style folders with numbered files, making it easy for you to manipulate them using mh tools. It appears there are few such tools in BruceGS's spam collection. I have added code to remove uuencoded sections and replace them with uuencode summary tokens instead. This didn't make a significant difference during my usual test run, but it did reduce the database size by a few percent. Please let me know if this helps you. I will try it out Anthony Baxter. It's never too late to find happiness in childhood."
   }, {
    "body": "Neale Picket, I just figured out the issue with the tokenizer – it had an extra colon. Now everything is in order and I feel like a real fool for not realizing this sooner. Thanks for pointing it out Neale, good catch! Blame it on staying up past bedtime, or blame it on Barry."
   }, {
    "body": "Dear Tim, I'm looking into an issue regarding the occurrence of two instances of 'Return-Path' in the headers of some emails. Greg Ward suggests it might be due to a Qmail configuration from Bruce Guenther's spam collection, but it seems unusual as it appeared in about one-third of his spams rather than being typical across the entire collection. It could potentially be specific to one of his bait addresses, though this is unconfirmed. The interesting thing about statistical inference is that you don't necessarily need to understand why a phenomenon occurs, just whether it does or doesn't. Anthony's theory about spammers being 'stupid' and blindly copying headers may hold some truth, but the specific aspect of this stupidity is debatable. I will leave it for now as it seems another instance of being pointlessly baffled by a mixed corpus, half of which I don't fully understand."
   }, {
    "body": "Anthony, it seems that they were not organized according to any specific scheme. Anthony will likely develop a reorganizer and redistribute them all. How about you move all your files into a 'DataHamsterReservoir' folder and then run the 'rebalpy' script to randomly assign messages to the respective directories? I believe you can achieve the same result with your 'dataSpam' stuff as well, skipping the step."
    }, {
       "body": "Could you consider moving all your files into a single 'datahamreservoir' folder and then use the os.listdir() function to randomly shuffle their names in Python? After that, it would be straightforward to split the resulting list into 'n' slices and move the files into different directories accordingly. This method might help improve the performance of rebalpy since it seems to struggle with quadratic time complexity when dealing with a large number of messages. I believe this approach could also apply to your data spam task."
   }, {
       "body": "The files were not organized in any specific pattern. I think I'll create a reorganizer and move everything around for safety, just in case. I'm currently using MH style folders with numbered files, so you can manipulate the set using MH tools. It seems that there were some patterns to the 'on hams spams' dataset before the shuffle. For comparison purposes, here's what I observed: Partitioned into 'on hams spams', total False Positives, total False Negatives. For future reference, I had a False Positive Total and False Negative Total prior to the shuffle. Let me know if you need more information later."
   }, {
    "body": "Damian Conway has published an exegesis on Perl, which was posted by hfb on Friday. Additionally, Ziggy announced the Open Source CMS Conference also on Friday. For any changes or adjustments to your subscriptions, please visit your user page and log in to change your preferences."
   }, {
      "body": "This email concerns Damian Conway's publication of exegesis at the open source CMS conference, which was also discussed by hfb on Friday, August [anonymous coward] requests a discussion about this story. Additionally, J Rothfuss announced that there will be a second open source CMS conference this fall in Berkeley, featuring presentations and workshops from various CMS platforms. They are particularly welcoming Perl functions (Perl Fu) at this event. Previously, an open source CMS conference was held in Zurich back in March. For more information or to participate, please visit our list or our website: the open source CMS conference. You have received this message because you are subscribed to it. To stop receiving messages from us, change your preferences on your user page. You can log in and modify your preferences there."
   }, {
    "body": "The latest strategy to oust the Taliban and Al Qaeda from the Afghan mountains involves deploying the ASF Alabama Special Forces. The following operatives are being sent: Billy Bob, Bubba Boo, Scooter Cooter, and Junior. Here's some information about them: They have no limits; their hunting season opened last weekend, they resemble chicken in taste, dislike beer, pickup trucks, country music, and Jesus. Some are gay, they don't enjoy barbecue, and notably, they were responsible for Dale Earnhardt's demise. We anticipate the operation to be completed within approximately two days."
   }, {
       "body": "Rob Windsor, Dave Bruce forwarded an email to Gary Williams regarding a peculiar promise made by three sisters who were all getting married in quick succession. Their mother had expressed concerns about their upcoming marital life, and as a result, she requested them to share a postcard from their honeymoons with some insights about their first experience. The first sister sent a card from Hawaii two days after her wedding, but it contained no message other than the brand name 'Maxwell House'. This left the mother puzzled at first, but upon finding Maxwell House coffee in the kitchen, she realized the daughter had used the coffee jar as a postcard. The second sister sent her card from Vermont a week later, and it bore the Benson Hedges logo, indicating her husband smoked that brand of cigarettes. Again, the mother felt a bit embarrassed but still pleased for her daughter. However, the third sister, who went on her honeymoon in the Caribbean, did not send a postcard until a month had passed. The card, written with shaky handwriting, revealed it was from British Airways. The mother then found an ad for the airline in her latest Harpers Bazaar magazine, confirming her fears. She fainted."
   }, {
    "body": "This week's newsletter on Slashdot is taking questions to be asked to Larry Wall on August. The summary of this story discusses the event where questions will be taken by pudge on Monday, August. Please consider submitting your questions if you are interested. This story is copyrighted by pudge, all rights reserved. If you wish to unsubscribe from this newsletter or make changes to your subscriptions, please visit your user page and change your preferences from there."
   }, {
    "body": "This week's Perl daily headline mailer has been posted on August, initially shared by Rafael on Monday. The summaries can be found at slashdot and questions are being taken to ask Larry Wall, as announced by Pudge also on Monday. Please note that the copyright belongs to Pudge, all rights reserved. You have received this message because you are subscribed to it. To stop receiving these and other messages from Perl, or to add more messages, or change your preferences, please visit your user page. You can log in and adjust your settings from there."
   }, {
           "body": "The duty for a hammer (auction) at Langtrees Brothel, a well-known establishment in Kalgoorlie, Western Australia, has been won by conservative Member of Parliament Barry Haase from the Liberal Party. The highest bidder was the madam of the brothel, and he will be spending a day there as a slave for charity. It is hoped that this experience will provide him with an informed perspective on Australian brothels, thereby enabling him to make more informed decisions in his political career. Ms Kenworthy commented that Mr Haase, a member of Prime Minister John Howard's party, appeared relaxed about the prospect of working in a brothel, suggesting that he is capable of playing the fundraising game effectively for significant charities."
          }, {
      "body": "This email is regarding the post 'use perl daily, headline mailernet and perl working together' made by pudge on Tuesday, August [insert year here]. It has been copyrighted by pudge, all rights reserved. This message was sent to you as you are subscribed to it. If you wish to stop receiving this and other messages from 'use perl', please take the necessary steps to unsubscribe. To add more messages or change your preferences, please navigate to your user page and log in to make any changes."
   }, {
     "body": "This email discusses an article on 'Porting Existing Code' using CPAN Perl modules, which can be made automatically available to the Net framework. The technique involves creating small Perl-Net mediators and knowing when, where, and how to modify them. Pudge shared this story on Tuesday, August links can be found at devx. This email is copyrighted by Pudge, all rights reserved. If you'd like to unsubscribe from this and other emails from Use Perl, or add more messages or change your preferences, please visit your user page where you can log in and make the necessary changes."
   }, {
      "body": "This email is about Perl daily headlines. It was posted by 'gnat' on Friday, August (specific date required) and is copyrighted under 'pudge'. All rights reserved. This message has been sent to you because you are subscribed to it. To stop receiving this and other messages from Use Perl, please change your preferences through your user page. You can access your user page by logging in, and then modify your preferences accordingly."
   }, {
      "body": "The first two OSCON Lightning Talks are now available online from the perl.org website. The talks are by Dan Brian on 'What Sucks and What Rocks' and Brian Ingerson on 'Your Own Personal Hashbang'. To continue reading this story, please visit the link provided. This newsletter is copyrighted by pudge. You have received this message because you are subscribed to our use-perl service. If you no longer wish to receive messages from us, or if you would like to change your preferences, please log in to your user page and make the necessary changes."
    }, {
      "body": "This is a reminder that you are subscribed to the 'use perl' daily headline mailer. This post on the Perl ports page, shared by hfb on Saturday, August, was covered under CPAN copyright (Pudge - All rights reserved). To stop receiving this and other messages from 'use perl', or to add more messages or change your preferences, please visit your user page. There you can log in and adjust your settings accordingly."
   }, {
     "body": "CPAN, one of the lesser-known services, offers a page that provides links to ready-packaged binary distributions of Perl for various platforms, as well as other related Unixy software links. If your platform isn't supported, you might find links to IDEs and editors. We welcome any feedback on this page, either here or by sending an email. However, feel free to ignore any feedback that doesn't resonate with you. To unsubscribe from this and other messages from Use Perl, or to change your preferences, please visit your user page and make the necessary adjustments."
   }, {
      "body": "This week's Perl Daily Newsletter will focus on The Perl Review, posted by Rafael on both August and September. Summaries are back to our regular schedule as usual. A big thank you to Elizabeth Mattjisen for providing the previous reports while I was away. The story continues with a discussion on the latest issue of The Perl Review, which includes topics like 'Extreme Mowing', Andy Lester's article on Perl Assembly Language, Phil Crow's piece, what every Perl programmer should know about Java, Beth Linker's Filehandle Ties, Robby Walker's The Iterator Design Pattern, and a contribution by Brian D Foy. For more discussions, please check out the link provided. Copyright Pudge, all rights reserved. You are receiving this message because you are subscribed to use Perl. To unsubscribe or manage your preferences, please visit your user page."
   }, {
    "body": "This week's Perl Daily Headline Mailer for August and September has been posted by Rafael on Monday, September XX. The Perl review discussed by Ziggy on the same day is included in the newsletter. Please note that the content of this mailer is copyrighted under Pudge, all rights reserved. You are receiving this message because you subscribed to it. If you wish to unsubscribe or manage your preferences for future messages, please visit your user page. From there, you can log in and change your settings as needed."
   }, {
     "body": "Subject Line: Daily Perl Headlines and More\n\nThis email contains news about Perl CMS systems posted by Ziggy on Tuesday, September [date], Perl Conference CD online posted by Gnat also on Tuesday, September [date], News about Bricolage escapes posted by Chip on the same day, and a reminder that all rights are reserved for the 'tools' copyright under Pudge. To stop receiving this and other emails from Use Perl, or to add more messages or change your preferences, please visit your user page and log in to modify settings."
   }, {
    "body": "Here are the rephrased contents of your email:\n\n1. Title: Discussion on Perl CMS Systems and Perl Conference CD Online\n\nZiggy posted a newsletter discussing two other Perl Content Management Systems (CMS), Perl CMS Systems and LJEngines, which makes for interesting reading.\n\n2. Title: Bricolage Escape from CVS Repository\n\nChip announced that Bricolage, a full-featured enterprise-class content management and publishing system, has finally broken free from its CVS repository. Offering a user-friendly browser interface, a robust templating system with complete programming language support, and many other features, it operates in an Apache mod_perl environment and uses PostgreSQL RDBMS for its repository.\n\n3. Title: Perl Conference CD Online and Damian's First Public Appearance\n\nGnat wrote about the online availability of the Perl Conference CD on perl.org. The email mentions that this was Damian's first public appearance, thanks to Daniel Berger for preserving the CD disc.\n\n4. Title: Copyright Information\n\nThe story also includes a copyright notice by Pudge reserving all rights.\n\n5. Action Items:\n\n- To stop receiving emails from 'Use Perl', visit your user page and change your preferences.\n- To add more messages or modify preferences, go to your user page."
   }, {
    "body": "This email is regarding the Perl Daily Headline Mailer. Ziggy posted about a Perl meetup on Thursday, September [Year]. Please note that this copyright belongs to Pudge (all rights reserved). You have received this message because you are subscribed to it. If you wish to stop receiving this and other messages from Use Perl, or if you would like to add more messages or change your preferences, please go to your user page and log in to make the necessary changes."
   }, {
    "body": "This email is regarding a Perl meetup that has been set up by Ziggy and posted on Thursday, September [X]. The first meeting will take place in September. I plan to attend the one in London to see how it goes, but I'm also interested in hearing any opinions on what this achieves that our existing Perl Mongers groups don't. Here is the related news story. Copyright Pudge, all rights reserved. If you no longer wish to receive messages from Use Perl or wish to modify your subscriptions, please visit your user page and change your preferences from there."
   }, {
    "body": "On September at Port San Luis, California, a whale suddenly breached and collided with a fishing boat, fatally injuring Jerry Tibbs, a restaurant owner from Bakersfield, California, who was on board. The incident occurred five miles off Port San Luis. The damaged boat was kept afloat by the remaining three fishermen on board, eventually being towed to shore by the US Coast Guard. The group had been fishing for albacore when the accident took place. After a search lasting over several hours, Tibbs' body was found. This is reportedly the first instance where a whale striking a boat has caused an accident according to Coast Guard officials."
   }, {
      "body": "This email is regarding the Perl Daily Headline Mailing List that Rafael posted on Monday, September. The summaries are copyrighted under Pudge, all rights reserved. You have received this message because you subscribed to it. If you wish to stop receiving these and other messages from Use Perl, or add more messages, or change your preferences, please visit your user page where you can log in and adjust your settings."
   }, {
      "body": "This week's newsletter on Perl will be published on Monday, September [xxxx]. Rafael has summarized some of the recent developments in Perl as September begins. Despite the changing weather, continue to work on some small tasks and a few bigger ones. The report is attached below for your reference. This story continues the discussion from last week. Copyright Pudge, all rights reserved. You have received this message because you are subscribed to it. To stop receiving messages from us about Perl or to add more topics or change your preferences, please visit your user page and log in to modify your settings."
   }, {
    "body": "Dear User,\n\nYou are receiving this message because you subscribed to our Perl daily headlines. The article 'dydnsorg offers free DNS to Perl sites' was posted by km on Tuesday, September. Please note that the copyright for this newsletter belongs to Pudge and all rights are reserved.\n\nTo stop receiving this and other messages from us, please visit your user page and adjust your preferences accordingly. If you wish to add more messages or modify your preferences, you can do so from there.\n\nBest regards,\nUse Perl Team"
   }, {
       "body": "This email is about Dyndnsorg's offer of free premium DNS services for Perl sites. Starting today, primary and secondary DNS hosting will be provided to any domains associated with the Perl community. For full details, please read the press release. With this offer, you can prevent traffic loss to your Perl site due to failed DNS. Thanks for subscribing to Use Perl updates. To unsubscribe or manage your subscription, visit your user page."
   }, {
    "body": "The Perl Journal's Daily Headline Mailing has been posted online by pudge on Wednesday, September [year]. The copyright for this content belongs to pudge and all rights are reserved. You have received this message because you subscribed to it. To stop receiving this and other messages from Use Perl, or to add more messages, or change your preferences, please visit your user page. From there, you can log in and adjust your preferences accordingly."
   }, {
       "body": "The Perl Journal has returned online as an monthly magazine in PDF form, posted by pudge on Wednesday September. It will now be available digitally, and the subscription rate is annual. They require subscriptions to move forward, though it's unclear if existing subscriptions will be honored or included on the site. Some interesting aspects of this change include a healthy dose of opinion, broadening of coverage including languages other than Perl, and potential expansion to platforms beyond Unix. This could potentially lead to a name change since diversity has always been one of TPJ's strengths by covering a wide variety of platforms. For more details, please visit the site. Copyright Pudge, all rights reserved."
   }, {
    "body": "You are receiving this message because you have subscribed to 'use Perl' daily headline mailer. If you wish to stop receiving these and other messages from 'use Perl', or add more messages, or modify your preferences, please visit your user page. You can log in and change your settings there."
   }, {
      "body": "Leon Brocard has made available the slides from his lightning talk at the London Perlmongers, which showcases the current compiler in action. You can access these slides right now by following this link. This story is copyrighted by Pudge, all rights reserved. If you wish to unsubscribe or manage your subscriptions for Use Perl messages, please visit your user page and make the necessary changes from there."
   }, {
    "body": "Here are the daily highlights from Perl Mongers web site. A new post was made by km on Monday, September [x], titled 'Perl Mongers web site'. Also on Monday, pudge posted a debate group named 'Groups: Java vs Perl'. On the same day, rafael shared 'This week on September' update. Please note that these summaries are copyrighted by pudge and all rights are reserved. You have received this message because you subscribed to it. If you wish to unsubscribe or modify your preferences, please visit your user page where you can log in and change settings accordingly."
   }, {
       "body": "This week on the new Perl Mongers web site, the debate between Java and Perl continues. Leon Brocard has been working diligently to update the site, but we're still in the process of cleaning up data about the Perl Monger groups. If you notice anything that isn't quite right, please let us know. In the 'Java vs Perl' post by Pudge on Monday, it was suggested that older versions of Perl are often perceived as subpar without any solid evidence. You may have seen the article discussing Java technology outperforming Perl in pattern matching with large files. This has sparked some discussion both within Perl and on comp.lang.perl.misc. One of the main criticisms of the article was that the author failed to provide the Perl code he's comparing his Java results with. This story will continue this week. \n\nAlso, despite many taking a break for Europe, smoke tests were running, bug reports were flying, and an appropriate number of patches were sent. Read about printf formats, serialized tied thingies, built-in leak testing syntax oddities, et cetera. This story continues.\n\nCopyright Pudge. All rights reserved. You're receiving this message because you subscribed to it. To stop receiving messages from Use Perl or to adjust your preferences, please visit your user page and log in to change your settings."
   }, {
      "body": "Subject: September Shoptalk - Various Topics\nDear Sir/Madam,\nI must admit, I'm feeling a bit 'fuzzy' this month as animal rights issues tend to weigh heavily on me. This reminded me of Robin Williams' stance on nude scenes in movies as he shared with Entertainment Weekly. Speaking of iconic figures, Johnny Unitas was twice named the National Football League's Most Valuable Player and led Baltimore to victory in Super Bowl V - a significant milestone in modern football history, played as it was on artificial turf. Richard Burkard's observation about Unitas' death being announced by the Baltimore Ravens rather than the Colts, who now play in Indianapolis, raises an interesting point about historical legacy. The vice president, Dick Cheney, is currently residing at a confidential location for security reasons. The Bush administration aims to keep him out of reach from potential subpoenas. Lastly, Jeb Bush's daughter, Noelle, has found herself in legal trouble again. As a child, her father would often read her the bedtime story 'Goldilocks and the Three Bears', and it seems that she may have encountered three strikes herself.\nBest Regards,"
    }, {
     "body": "You are subscribed to the Perl Review newsletter, which was posted by 'pudge' on Tuesday, September. If you wish to unsubscribe from this and other messages from 'Use Perl', or modify your subscription preferences, please visit your user page where you can log in and make changes."
   }, {
      "body": "Pudge has posted about subscribing to The Perl Review newsletter. It is planned to release four print magazines per year if there are enough subscription pledges. You can now sign up for a subscription on their website. If they receive enough pledges, the plan is to produce these magazines in print. This story is copyrighted by Pudge, all rights reserved. To stop receiving this and other messages from Use Perl, or to add more messages or change your preferences, please visit your user page and make the necessary changes there."
   }, {
    "body": "Paul Crosbie's email regarding William Knowles' subject: Revamp of Virgin's Latest Airliner - 'Claudia Nine':\n\nAfter passengers discovered that the tiny cabin on the Airbus was an ideal spot for joining the Mile High Club, the airplane is undergoing renovations. The plane, named after model Claudia Schiffer, features a mother and baby room equipped with a plastic changing table. However, couples have been misusing it by sneaking in for quick encounters. Virgin has replaced the table multiple times, despite the aircraft only being in service for a few weeks. Airbus has been requested to reinforce the table due to the frequent damages. German engineers responsible for the jet's interior were initially puzzled by the problem. They didn't anticipate this use of the table. The humor was not lost on them. The cost of reinforcing the tables is estimated to be around a certain amount. A Virgin spokesperson stated that those determined to join the Mile High Club will find ways, despite the lack of comforts. While we encourage couples to enjoy themselves, we discourage such activities due to air regulations. The new Airbus, with the teasing slogan 'Mine is bigger than yours', is currently used on flights to the Far East and US."
   }, {
       "body": "Did you know that you can determine, based on a person's skin, whether they are sexually active or not? Scientific research indicates that when women engage in lovemaking, their bodies produce more estrogen, which makes hair shine and the skin smooth and radiant. Gentle, relaxed lovemaking reduces your chances of suffering from dermatitis, skin rashes, and blemishes. The sweat produced during lovemaking helps cleanse pores and gives your skin a healthy glow. Lovemaking can help burn calories accumulated during that romantic dinner. Lovemaking is one of the safest physical activities you can engage in, as it stretches and tones almost every muscle in the body. It's more enjoyable than swimming laps, and you don't need any special equipment. Lovemaking has been found to act as an instant cure for mild depression, releasing endorphins into the bloodstream that create a feeling of euphoria and promote wellbeing. The more lovemaking you engage in, the greater the quantities of pheromones your body releases, which can drive the opposite sex crazy. Lovemaking is the safest and most effective tranquilizer available; it's times more effective than Valium. Kissing each day can help keep dental problems at bay as it encourages saliva to wash food from the teeth and neutralize the acid that causes decay, preventing plaque buildup. Additionally, lovemaking can alleviate headaches by releasing tension in the blood vessels in the brain. Lovemaking also functions as a natural antihistamine, helping combat allergies such as asthma and hay fever."
   }, {
      "body": "Dear Subscriber,\n\nThis is a reminder that you are currently subscribed to the 'use perl daily headline mailer'. An article titled 'How much does Perl, PHP, Java or Lisp suck', posted by pudge on Wednesday, September [year], can be found in the links provided. Please note that these links and their content are copyrighted by pudge and all rights are reserved.\n\nYou have received this message because you subscribed to it. If you wish to unsubscribe from receiving this and other messages from 'use perl', please visit your user page and change your preferences there. Alternatively, if you'd like to add more messages or adjust your settings, you can also do so through your user page."
    }, {
      "body": "Dear Subscriber,\n\nA few days ago, Pudge posted an article titled 'How Much Does Perl, PHP, Java or Lisp Suck?' on Use Perl Daily Newsletter. This topic was first introduced by Don Marti with the OSSucksRuleMeter and later updated by Jon Orwant and Dan Brian with some natural language processing.\n\nPerl Review creates attractive visuals based on searches from Altavista and Google. The findings suggest that not many people think PHP or Lisp suck, while a large number believe C and Java suck. Perl is generally considered somewhere in the middle. The question now is: Does Perl still suck as much as it used to, or has PHP surpassed it significantly? Discuss this interesting story.\n\nIf you wish to unsubscribe from Use Perl Daily Newsletter or change your preferences, please visit your user page and log in. There, you can modify your settings accordingly.\n\nBest regards,\nUse Perl Team"
   }, {
      "body": "This is to inform you that PerlQt Daily Headline Mailer, version posted by Ziggy on Thursday, has been released. This email is sent due to your subscription to this service. If you wish to stop receiving emails from us or would like to subscribe to more or modify your preferences, please visit your user page for login and changes. You can manage your settings from there."
   }, {
      "body": "A new version of Perlqt, a tool for developing UIs from XML using Perl, has been released. This was posted by Ziggy on Thursday September tools. It appears that this new version includes a Perl version for the development of UIs. For more details, visit <https://dot> (note: replace '.' with the actual link). Copyright Pudge, all rights reserved. If you'd like to stop receiving messages from us or to add/change your preferences, please go to your user page and log in to change your settings."
   }, {
      "body": "You are receiving this email due to your subscription to it. This message is about using Perl daily headline maileryapc and venues posted by km on Sunday's news, under copyright 'pudge', all rights reserved. If you wish to unsubscribe from this and other messages from us, or add more messages or change your preferences, please visit your user page and log in to modify your settings."
   }, {
   "body": "The Perl Daily Newsletter is requesting your attention for a call for venues posted by 'km' on Sunday, September [year] for the YAPC conference in America. Please remember to review the requirements listed in the Venue module on CPAN and contact the organizers of past YAPC events. The Perl Foundation plans to announce the venue in November. This story is copyrighted by Pudge, all rights reserved. If you no longer wish to receive messages from Use Perl or wish to modify your subscription preferences, please visit your user page where you can log in and change your settings."
   }, {
    "body": "This week's Perl daily headline mailer for September has been posted by Rafael on Monday, September. It summarizes the recent 'Perl Monger Cull' as mentioned by Ziggy also on Monday, September. Please note that this news is subject to copyright by Pudge; all rights reserved. This email has been sent to you because you are subscribed to it. To stop receiving this and other messages from us, or to add more messages, or change your preferences, please visit your user page. You can log in and adjust your settings from there."
   }, {
    "body": "This week's Perl daily newsletter discusses 'The Great Perl Monger Cull of September', which was posted by Rafael on Monday, September. The article summarizes the past week, highlighting that a significant number of Perl mongers appear to be European and have either moved to Europe or were otherwise unavailable. Interestingly, the number of bug reports remained at its usual average level. Ziggy's story in the news section talks about a decrease in the number of active local groups on the Mongers website over the last month. Efforts are being made to contact these groups to confirm their status. It appears that almost half of the listed groups have not responded to emails, and as a result, they have been removed from the list. If your local group still exists but is no longer listed, please let us know so we can update our records. Copyright Pudge, all rights reserved. This message is being sent to you because you are subscribed to the Perl newsletter. To stop receiving this and other messages from Perl, or to add more messages or change your preferences, please visit your user page and log in to make changes."
   }, {
    "body": "This is a reminder that you are currently subscribed to the 'Daily Headline Mailer using Perl and Applescript' newsletter, which was posted by 'pudge' on Wednesday, September [Year]. Please note that all rights are reserved for this link. If you wish to unsubscribe from receiving this and other messages from 'use perl', kindly visit your user page. From there, you can log in and adjust your preferences accordingly."
   }, {
      "body": "This email is regarding the article 'Using Perl and AppleScript with Web Services' posted by 'pudge' on Wednesday, September [links provided]. The article, titled 'AppleScript and Perl Working Together', was authored by Randal L. Schwartz and can be found on oreilly.net. If you wish to unsubscribe from this and other messages from Use Perl, please visit your user page where you can change your preferences. To add more messages or modify your settings, log in and navigate to your user page."
   }, {
    "body": "This email is about the Perl Daily Headline Mailer, which Rafael posted on Monday, September. The summaries are copyrighted by Pudge, all rights reserved. You have received this message because you subscribed to it. To stop receiving this and other messages from us, please go to your user page and change your preferences there. If you want to add more messages or modify your preferences, you can do so from your user page as well."
   }, {
      "body": "This week's Perl Daily Newsletter has been posted on September. Rafael shared some summaries, making it a nice and engaging week with many discussions on various intriguing topics. The newsletter includes tales of strange bugs, fixes, and error messages. As always, the ongoing efforts to improve Perl continue. Feel free to share your thoughts about this story. Remember, copyright Pudge - all rights reserved. You are receiving this message because you subscribed to it on Use Perl. To stop receiving this and other messages from Use Perl or to modify/add more messages or change your preferences, please visit your user page. You can log in and alter your preferences from there."
   }, {
    "body": "The South Florida Perl Mongers Group has announced its first social meeting, to be held at Duck Tavern in Boca Raton, FL on Tuesday, October [date] at [time]. For updated news and events regarding South Florida PM, please stay tuned. This announcement was posted by Ziggy on Tuesday, October [date]. If you wish to unsubscribe or change your preferences for this service, please visit your user page and modify your settings."
   }, {
    "body": "This is a daily headline email from Perl, announcing South Florida PM posts. This particular post was made by Ziggy on Tuesday October [X]. The content of this mail and other future mails are copyrighted by Pudge, all rights reserved. If you wish to stop receiving these emails or modify/add more emails to your subscription or change your preferences, please visit your user page and log in to make the necessary changes."
   }, {
           "body": "Dear Chris,\n\nI wanted to share an intimate account of my life that's been weighing heavily on me. Growing up, if I weren't a boy, I wouldn't have had anything to play with. A girl recently contacted me and invited me over, but nobody was home during our encounter. My girlfriend often wants to talk to me; the other night she called from a hotel. One day, I came home early from work and saw a man jogging naked. He explained that I arrived home early, which made him feel compelled to do so. It's been a tough day.\n\nI woke up this morning, my shirt button fell off, and the handle of my briefcase broke. I'm afraid to use the bathroom. I was an ugly kid when I played in the sandbox; the cat would cover me. I could sense my parents' disdain for me. My bath toys were a toaster and radio. I was such an ugly baby that my mother never breastfed me; she told me she only liked me as a friend.\n\nI feel so ugly, even my father carries around a picture of the child who came with his wallet when I was born. The doctor entered the waiting room and apologized to my father, saying they did everything they could but I pulled through.\n\nMy mother suffered from morning sickness after I was born. I remember the time I was kidnapped, and they sent a piece of my finger to my father; he demanded more proof. Once when I was lost, I asked a policeman for help finding my parents, and he replied that he didn't know if we would ever find them.\n\nMy wife has forced me to join a bridge club, and I plan to jump off next Tuesday. I worked in a pet shop, and people would often ask how big I'd get. I went to see my doctor because I had swallowed a bottle of sleeping pills. He suggested having a few drinks and getting some rest.\n\nWith my old man, I get no respect. I asked him how I could get my kite in the air, and he told me to run off a cliff. We have a dog we call Egypt because in every room, he leaves a pyramid. His favorite bone is lodged in my arm.\n\nLast year, they wanted to make me the poster boy for birth control. My uncle's dying wish was to have me sitting in his lap; he was in the electric chair.\n\nSincerely,\n[Your Name]"
   }, {
    "body": "This email is regarding the 'perl daily headline mailermailing list'. Gnat has posted about a Judo movie being available on Wednesday, October. He also announced a news conference presentation of the same Judo movie on Wednesday, October. Please note that the news copyright is reserved by 'pudge' (all rights reserved). You have received this message because you are subscribed to it. To stop receiving this and other messages from us, please visit your user page and adjust your preferences. You can log in and change your preferences there."
   }, {
    "body": "The Judo movie, which was available for viewing at a conference presentation, is now available on perlorg. This is courtesy of David Wheeler who recorded Mark Jason Dominuss' session. The Judo presentation itself can be found online at perlorg. We appreciate David's efforts in recording this at OSC. The story will feature the Judo movie that was posted by gnat on Wednesday, October news. If you have any comments or discussions about this story, please feel free to do so. Note that this message is copyrighted by Pudge. All rights reserved. To stop receiving messages from usperl or to add more messages or change your preferences, please go to your user page and log in to adjust your settings."
   }, {
    "body": "Monty Solomon's new PC doesn't run Windows; instead, it operates on a Linux-based system called Lindows. This budget-friendly computer is available exclusively through Walmart's online store and challenges the dominance of established tech giants. As technology writer Matthew Fordahl points out, it has been decades since a new Atari or Commodore Vic could be had for less than these outdated relics were worth even in their heyday. The Microtel, with its Lindows operating system, offers a fresh alternative for consumers seeking to break away from the Microsoft monopoly."
   }, {
     "body": "A man, somewhat intoxicated, began talking to a young woman at a bar after several drinks. He proposed they buy their own bottle and retreat to his motel room, which she accepted without hesitation. The man then asked, 'By the way, how old are you?' She replied shyly, 'I'm thirteen.' The man was taken aback, exclaiming, 'My god girl! Put your clothes back on right now and leave here immediately! Are you crazy?' As she left, the girl smiled, leaving behind the remark, 'Superstitious, huh?'"
   }, {
     "body": "Gary, Nev, and Bianconi, regarding BC's history: Eat this root. This root is considered pagan. Say this prayer. This prayer is seen as superstition. Drink this potion. This potion is likened to snake oil. Swallow this pill. This pill is deemed ineffective. Take this antibiotic. This antibiotic is synthetic. Here, eat this root."
   }, {
    "body": "A security vulnerability has been found in the Perl 'safe' module. The issue arises when a 'safe compartment' has already been utilized, as there is no guarantee that it remains safe since code executed within the compartment can alter its operation mask. Consequently, programs that use a 'safe compartment' only once are not vulnerable to this bug. Below you will find the fixes for this issue. This story continues, discuss this story. Copyright Pudge - All rights reserved. You have received this message because you subscribed to it via Perl. To stop receiving such messages from us or to add more messages or modify your preferences, please visit your user page where you can log in and change your settings."
   }, {
       "body": "You are being emailed about installing Perl on macOS X, as this was posted by 'pudge' on Thursday, August [Year]. The latest release of Apple's operating system, macOS X Jaguar, surprisingly includes a relatively old version of Perl. In an article targeted at developers, I will guide you through the process of installing Perl on your macOS X system and provide a brief introduction to CPAN. Here is a quick look at this story; copyright 'pudge', all rights reserved. To stop receiving emails from Use Perl or to change your preferences, please visit your user page where you can log in and make changes."
   }, {
      "body": "The email reads: Four friends were golfing, and the first one said he had promised his wife that he would paint the entire outside of the house just to go golfing. The second one mentioned a remodeled kitchen for his wife, while the third said he had agreed to build a new deck. The fourth friend was surprised when asked what promise he made to his wife - he replied that he didn't make any promise because he simply set an alarm clock, woke his wife up and asked her if it was the golf course or intercourse, and she chose the golf course by asking him to wear a sweater."
   }, {
           "body": "To Nev, Dull, Mike Olson, Jim Frew, and Mark Mooney, \n\nRegarding your previous lawsuits against tobacco companies for causing lung cancer and fast food places for contributing to obesity, I presume I could file a lawsuit against Budweiser for the perceived unattractiveness of the women I've been with."
           }, {
    "body": "I have begun referring to the suggested action against Iraq as 'Desert Storm.' It seems reminiscent of a Microsoft product – expensive, many people are unsure about it, and there's a good chance it won't succeed. Kevin G Barkes"
   }, {
    "body": "You are receiving this email due to your subscription. The headline for Tuesday, October includes an article about 'The Perl Journal on the Ropes' posted by 'pudge', and another about 'Parrot with Pumpkin' posted by 'km'. Note that the links in the articles are copyrighted by 'pudge'. To stop receiving these and other messages from Use Perl, or to modify your subscriptions or preferences, please visit your user page. From there, you can log in and change your settings."
   }, {
      "body": "The Perl Daily Newsletter for this week features an article titled 'Passing the Parrot - Pumpkin' from km, posted on Tuesday, October [date]. In this post, Jeff Goff, the current Release Manager and Keys and Source caretaker, is passing on his role to Steve Fink who has agreed to take up the position. Everyone is welcome to extend a warm greeting to Steve! \n\nUnfortunately, The Perl Journal appears to be in critical condition as per an article by 'pudge' also posted on Tuesday, October [date]. Time is running out and we need your help. If you wish for The Perl Journal to continue its journey as the premier source for Perl coverage, please subscribe immediately! With a nominal cost of just cents per day, you can access top-notch Perl content anywhere. We require more subscribers to move forward with this endeavor. \n\nThis story is copyrighted by 'pudge' and all rights are reserved.\n\nYou have received this message because you are a subscriber of Use Perl. To stop receiving this and other messages from us, or to modify your preferences, please visit your User Page on our website where you can log in and change your settings."
   }, {
    "body": "The October edition of our foundation newsletter, posted by Pudge on Tuesday, is now available. This newsletter features an interview with Tim Maher, the winner of White Camel. If you wish to stop receiving these and other messages from us, or adjust your preferences, please visit your user page where you can log in and make changes."
   }, {
     "body": "Shelley found the content on FOAF this weekend to be a group of people experimenting with new tools. However, she's curious about how FOAF assists in aggregation. The inclusion of the author with each piece is clear, but she questions the need for additional information such as college and personal details like 'Seth's example'. She stated that she only knew you from your posts to this list, and after finding your website through your email address (burningbirdnet), she's still unclear about who you are, what projects you're involved in, whom you know, and why you contribute here. If there were a FOAF button on the feed from this channel, she could easily learn more about you, but as it stands, she's struggling to fully understand."
   }, {
    "body": "Dear [Recipient],\nJeremy from Yahoo Finance is providing a beta RSS feed for every stock. Here are the links for [Yahoo Finance Stock Feed] and [Thanks to Jon for the tip, nice job Jon!]. It's interesting to note that Microsoft doesn't appear very strongly in the web log world. I had an intriguing conversation about this with John Montgomery, whom I first met during our collaboration on SOAP in the late 90s. Web log software was one of the key reasons we were drawn to SOAP. Although we didn't connect back then, it's a small world! Looking forward to catching up again."
   }, {
      "body": "I have completed most of the development on my RDF interface for Python, which is called Tramp. If you are not using RDF or Python, feel free to skip this message. Due to issues with rdflib's organization at present, this new library abstraction might be a better option. It supports reading and writing values, along with unit tests, all while maintaining the familiar 'Tramp' flavor you've grown accustomed to. However, it also comes with an entire page of reasons why you should consider it, especially if RDF/XML has been giving you trouble or if you want to write Python code that is both standards-compatible and easy to work with. This library may solve the problems you have with dealing with data in a standardized way. As a bonus, if you can figure out why it's called 'Tramp', I will reward you!"
   }, {
    "body": "When can we expect someone to develop audio fonts? It seems long overdue."
    }, {
    "body": "I have received a very gracious invitation, and I truly hope to accept it. However, I feel somewhat conflicted as I believe others may deserve it more than me. The next few weeks are quite busy with Edward Tufte and Members Night in Chicago (Fri – Berkeley Bookmobile SF), Hoshana Rabba, Shemini Atzeret, Simchat Torah Jewish holidays, and possibly a need for accommodation in Santa Clara. I am also looking into the Bernstein's oral argument in crypto export San Francisco, and the DITTOUES arrival in DC as well as Lessig's oral argument in Eldred DC."
   }, {
    "body": "Meeting scheduled for Monday, September GMTNY Time with reporters who have blogs."
    }, {
    "body": "I am sending you Dave Winer's books that are sweet."
   }, {
     "body": "Synthesiser is an open-source project that enables users to incorporate their own footage, alternative audio, subtitles, and more into any DVD. This empowers individuals to create customized content such as improved subtitles, editlists for highlight reels of favorite movies, and more. However, it's important to note that this tool is considered illegal under the DMCA due to its capability to bypass the copyright protection mechanisms in pre-recorded DVDs."
   },